from argparse import Namespace
from collections import defaultdict
from logging import Logger
import math
from multiprocessing import Pool
import random
from typing import Callable, Dict, List, Tuple, Union, Set, FrozenSet

import numpy as np
from torch.utils.data.dataset import Dataset
from rdkit import Chem
from tqdm import tqdm

from .scaler import StandardScaler
from chemprop.features import get_features_func

class MoleculeDatapoint:
    def __init__(self,
                 line: List[str],
                 args: Namespace = None,
                 features: np.ndarray = None,
                 use_compound_names: bool = False):
        """
        Initializes a MoleculeDatapoint.

        :param line: A list of strings generated by separating a line in a data CSV file by comma.
        :param args: Argument Namespace.
        :param features: A numpy array containing additional features (ex. Morgan fingerprint).
        :param use_compound_names: Whether the data CSV includes the compound name on each line.
        """
        if args is not None:
            self.features_generator = args.features_generator
            self.args = args
        else:
            self.features_generator = self.args = None

        if features is not None and self.features_generator is not None:
            raise ValueError('Currently cannot provide both loaded features and a features generator.')

        self.features = features

        if use_compound_names:
            self.compound_name = line[0]  # str
            line = line[1:]
        else:
            self.compound_name = None

        self.smiles = line[0]  # str
        self.mol = Chem.MolFromSmiles(self.smiles)

        # Generate additional features if given a generator
        if self.features_generator is not None:
            self.features = []

            for fg in self.features_generator:
                features_func = get_features_func(fg, args)
                if self.mol is not None and self.mol.GetNumHeavyAtoms() > 0:
                    self.features.extend(features_func(self.mol))

            self.features = np.array(self.features)

        # Fix nans in features
        if self.features is not None:
            replace_token = 0
            self.features = np.where(np.isnan(self.features), replace_token, self.features)

        # Create targets
        self.task_targets = [float(x) if x != '' else None for x in line[1:]]
        self.recreate_targets()

    def set_features(self, features: np.ndarray):
        self.features = features
        self.recreate_targets()
    
    def num_tasks(self):
        return len(self.targets) if self.targets is not None else 1

    def recreate_targets(self):
        self.targets = self.task_targets

    def set_targets(self, targets: List[float]):
        self.targets = targets

class MoleculeDataset(Dataset):
    def __init__(self, data: List[MoleculeDatapoint]):
        self.data = data
        self.args = self.data[0].args if len(self.data) > 0 else None
        self.scaler = None

    def compound_names(self) -> List[str]:
        if len(self.data) == 0 or self.data[0].compound_name is None:
            return None

        return [d.compound_name for d in self.data]

    def smiles(self) -> List[str]:
        return [d.smiles for d in self.data]
    
    def mols(self) -> List[str]:
        return [d.mol for d in self.data]

    def features(self) -> List[np.ndarray]:
        if len(self.data) == 0 or self.data[0].features is None:
            return None

        return [d.features for d in self.data]

    def targets(self, task_idx: int = None) -> Union[List[List[float]],
                               List[List[float]],
                               List[int],
                               Dict[str, Union[List[np.ndarray], List[int]]]]:

        targets = [d.targets for d in self.data]

        if task_idx is not None:
            targets = [t[task_idx] for t in targets]

        return targets

    def num_tasks(self) -> int:
        return self.data[0].num_tasks() if len(self.data) > 0 else None

    def features_size(self) -> int:
        return len(self.data[0].features) if len(self.data) > 0 and self.data[0].features is not None else None

    def shuffle(self, seed: int = None):
        if seed is not None:
            random.seed(seed)
        random.shuffle(self.data)
    
    def normalize_features(self, scaler: StandardScaler = None, replace_nan_token: int = 0) -> StandardScaler:
        if len(self.data) == 0 or self.data[0].features is None:
            return None

        if scaler is not None:
            self.scaler = scaler

        elif self.scaler is None:
            features = np.vstack([d.features for d in self.data])
            self.scaler = StandardScaler(replace_nan_token=replace_nan_token)
            self.scaler.fit(features)

        for d in self.data:
            d.set_features(self.scaler.transform(d.features.reshape(1, -1))[0])

        return self.scaler
    
    def set_targets(self, targets: List[List[float]]):
        assert len(self.data) == len(targets) # assume user kept them aligned
        for i in range(len(self.data)):
            self.data[i].set_targets(targets[i])

    def sort(self, key: Callable):
        self.data.sort(key=key)

    def __len__(self) -> int:
        return len(self.data)

    def __getitem__(self, item) -> Union[MoleculeDatapoint, List[MoleculeDatapoint]]:
        return self.data[item]
