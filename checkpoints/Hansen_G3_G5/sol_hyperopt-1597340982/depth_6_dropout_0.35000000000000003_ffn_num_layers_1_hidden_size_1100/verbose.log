Fold 0
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.35000000000000003,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 1100,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1100,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.35000000000000003_ffn_num_layers_1_hidden_size_1100/fold_0',
 'save_smiles_splits': True,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total scaffolds = 195 | train scaffolds = 91 | val scaffolds = 66 | test scaffolds = 38
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.35000000000000003, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1100, bias=False)
      (W_h): Linear(in_features=1100, out_features=1100, bias=False)
      (W_o): Linear(in_features=1233, out_features=1100, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.35000000000000003, inplace=False)
    (1): Linear(in_features=1104, out_features=1, bias=True)
  )
)
Number of parameters = 2,730,205
Moving model to cuda
Epoch 0
Loss = 1.9301e-02, PNorm = 50.2373, GNorm = 4.1269, lr_0 = 3.6053e-04
Validation rmse = 1.691129
Epoch 1
Loss = 1.0109e-02, PNorm = 50.2694, GNorm = 3.7770, lr_0 = 6.2105e-04
Loss = 8.8376e-03, PNorm = 50.3203, GNorm = 2.8299, lr_0 = 8.5789e-04
Validation rmse = 1.396499
Epoch 2
Loss = 4.7119e-03, PNorm = 50.3755, GNorm = 1.4800, lr_0 = 9.8284e-04
Loss = 5.6686e-03, PNorm = 50.4148, GNorm = 6.7531, lr_0 = 9.4120e-04
Validation rmse = 1.969253
Epoch 3
Loss = 7.0838e-03, PNorm = 50.4507, GNorm = 5.1002, lr_0 = 8.9744e-04
Loss = 6.1982e-03, PNorm = 50.4865, GNorm = 2.9286, lr_0 = 8.5943e-04
Validation rmse = 1.347784
Epoch 4
Loss = 5.2587e-03, PNorm = 50.5119, GNorm = 3.3105, lr_0 = 8.2303e-04
Loss = 3.3468e-03, PNorm = 50.5327, GNorm = 1.4713, lr_0 = 7.8816e-04
Validation rmse = 1.505256
Epoch 5
Loss = 2.6386e-03, PNorm = 50.5495, GNorm = 1.8712, lr_0 = 7.5478e-04
Loss = 2.9158e-03, PNorm = 50.5639, GNorm = 2.2350, lr_0 = 7.2281e-04
Validation rmse = 1.462714
Epoch 6
Loss = 2.4034e-03, PNorm = 50.5812, GNorm = 0.9878, lr_0 = 6.8920e-04
Loss = 2.5025e-03, PNorm = 50.5949, GNorm = 0.6888, lr_0 = 6.6001e-04
Validation rmse = 1.410629
Epoch 7
Loss = 3.3378e-03, PNorm = 50.6076, GNorm = 4.6534, lr_0 = 6.3205e-04
Loss = 2.5003e-03, PNorm = 50.6228, GNorm = 1.2031, lr_0 = 6.0528e-04
Validation rmse = 1.190967
Epoch 8
Loss = 2.5507e-03, PNorm = 50.6394, GNorm = 1.5690, lr_0 = 5.7714e-04
Loss = 2.1487e-03, PNorm = 50.6525, GNorm = 1.0417, lr_0 = 5.5269e-04
Validation rmse = 1.323030
Epoch 9
Loss = 2.2075e-03, PNorm = 50.6647, GNorm = 4.6603, lr_0 = 5.2928e-04
Loss = 2.3664e-03, PNorm = 50.6803, GNorm = 1.3000, lr_0 = 5.0686e-04
Validation rmse = 1.256096
Epoch 10
Loss = 2.1694e-03, PNorm = 50.6910, GNorm = 2.3260, lr_0 = 4.8539e-04
Loss = 2.3272e-03, PNorm = 50.7039, GNorm = 0.7474, lr_0 = 4.6483e-04
Validation rmse = 1.081284
Epoch 11
Loss = 1.5281e-03, PNorm = 50.7151, GNorm = 0.8605, lr_0 = 4.4322e-04
Loss = 1.9750e-03, PNorm = 50.7230, GNorm = 1.1709, lr_0 = 4.2444e-04
Validation rmse = 1.135392
Epoch 12
Loss = 1.9273e-03, PNorm = 50.7311, GNorm = 0.8050, lr_0 = 4.0646e-04
Loss = 2.1978e-03, PNorm = 50.7388, GNorm = 1.2904, lr_0 = 3.8925e-04
Validation rmse = 1.163231
Epoch 13
Loss = 2.1057e-03, PNorm = 50.7490, GNorm = 0.5394, lr_0 = 3.7276e-04
Loss = 2.3326e-03, PNorm = 50.7585, GNorm = 2.1445, lr_0 = 3.5697e-04
Validation rmse = 1.265362
Epoch 14
Loss = 1.9901e-03, PNorm = 50.7681, GNorm = 2.1842, lr_0 = 3.4037e-04
Loss = 1.9128e-03, PNorm = 50.7766, GNorm = 1.8589, lr_0 = 3.2596e-04
Validation rmse = 1.079145
Epoch 15
Loss = 1.4070e-03, PNorm = 50.7822, GNorm = 0.8664, lr_0 = 3.1215e-04
Loss = 1.5847e-03, PNorm = 50.7868, GNorm = 1.6178, lr_0 = 2.9893e-04
Validation rmse = 1.117537
Epoch 16
Loss = 1.6531e-03, PNorm = 50.7916, GNorm = 1.8036, lr_0 = 2.8503e-04
Loss = 1.6277e-03, PNorm = 50.7971, GNorm = 0.5829, lr_0 = 2.7295e-04
Validation rmse = 1.095197
Epoch 17
Loss = 1.4452e-03, PNorm = 50.8015, GNorm = 1.4452, lr_0 = 2.6139e-04
Loss = 1.5882e-03, PNorm = 50.8068, GNorm = 0.9820, lr_0 = 2.5032e-04
Validation rmse = 1.065093
Epoch 18
Loss = 1.2356e-03, PNorm = 50.8099, GNorm = 0.9202, lr_0 = 2.3972e-04
Loss = 1.5376e-03, PNorm = 50.8136, GNorm = 1.1382, lr_0 = 2.2956e-04
Validation rmse = 1.034234
Epoch 19
Loss = 1.3911e-03, PNorm = 50.8183, GNorm = 0.9156, lr_0 = 2.1889e-04
Loss = 1.6488e-03, PNorm = 50.8207, GNorm = 0.8741, lr_0 = 2.0962e-04
Validation rmse = 1.035542
Epoch 20
Loss = 1.4321e-03, PNorm = 50.8253, GNorm = 0.8487, lr_0 = 2.0074e-04
Loss = 1.6195e-03, PNorm = 50.8275, GNorm = 2.4759, lr_0 = 1.9224e-04
Validation rmse = 1.043544
Epoch 21
Loss = 1.5060e-03, PNorm = 50.8316, GNorm = 1.3252, lr_0 = 1.8409e-04
Loss = 1.5091e-03, PNorm = 50.8354, GNorm = 0.6181, lr_0 = 1.7630e-04
Validation rmse = 1.010708
Epoch 22
Loss = 1.3394e-03, PNorm = 50.8406, GNorm = 1.6672, lr_0 = 1.6810e-04
Loss = 1.6143e-03, PNorm = 50.8424, GNorm = 0.7418, lr_0 = 1.6098e-04
Validation rmse = 1.036494
Epoch 23
Loss = 1.4599e-03, PNorm = 50.8457, GNorm = 1.0394, lr_0 = 1.5416e-04
Loss = 1.2656e-03, PNorm = 50.8481, GNorm = 0.9481, lr_0 = 1.4763e-04
Loss = 2.3793e-03, PNorm = 50.8484, GNorm = 1.8346, lr_0 = 1.4699e-04
Validation rmse = 1.000800
Epoch 24
Loss = 1.3604e-03, PNorm = 50.8508, GNorm = 1.5697, lr_0 = 1.4077e-04
Loss = 1.3349e-03, PNorm = 50.8531, GNorm = 0.5342, lr_0 = 1.3480e-04
Validation rmse = 1.037682
Epoch 25
Loss = 1.3542e-03, PNorm = 50.8548, GNorm = 0.9506, lr_0 = 1.2909e-04
Loss = 1.3245e-03, PNorm = 50.8570, GNorm = 0.8298, lr_0 = 1.2362e-04
Validation rmse = 1.048031
Epoch 26
Loss = 1.3759e-03, PNorm = 50.8585, GNorm = 2.1312, lr_0 = 1.1839e-04
Validation rmse = 1.044912
Epoch 27
Loss = 1.0072e-03, PNorm = 50.8610, GNorm = 1.8561, lr_0 = 1.1288e-04
Loss = 1.2680e-03, PNorm = 50.8628, GNorm = 0.8055, lr_0 = 1.0810e-04
Validation rmse = 1.015495
Epoch 28
Loss = 1.7611e-03, PNorm = 50.8644, GNorm = 0.7141, lr_0 = 1.0352e-04
Loss = 1.2820e-03, PNorm = 50.8667, GNorm = 0.5631, lr_0 = 1.0000e-04
Validation rmse = 1.065191
Epoch 29
Loss = 1.5262e-03, PNorm = 50.8688, GNorm = 1.5859, lr_0 = 1.0000e-04
Loss = 1.4314e-03, PNorm = 50.8708, GNorm = 0.6341, lr_0 = 1.0000e-04
Validation rmse = 1.047666
Model 0 best validation rmse = 1.000800 on epoch 23
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 0.983831
Ensemble test rmse = 0.983831
Fold 1
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.35000000000000003,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1100,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1100,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.35000000000000003_ffn_num_layers_1_hidden_size_1100/fold_1',
 'save_smiles_splits': True,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total scaffolds = 195 | train scaffolds = 76 | val scaffolds = 60 | test scaffolds = 59
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.35000000000000003, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1100, bias=False)
      (W_h): Linear(in_features=1100, out_features=1100, bias=False)
      (W_o): Linear(in_features=1233, out_features=1100, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.35000000000000003, inplace=False)
    (1): Linear(in_features=1104, out_features=1, bias=True)
  )
)
Number of parameters = 2,730,205
Moving model to cuda
Epoch 0
Loss = 1.8412e-02, PNorm = 50.2378, GNorm = 11.5289, lr_0 = 3.6053e-04
Validation rmse = 1.751332
Epoch 1
Loss = 1.1045e-02, PNorm = 50.2697, GNorm = 3.5836, lr_0 = 6.2105e-04
Loss = 9.0132e-03, PNorm = 50.3189, GNorm = 9.0015, lr_0 = 8.5789e-04
Validation rmse = 1.715896
Epoch 2
Loss = 1.0464e-02, PNorm = 50.3770, GNorm = 5.3115, lr_0 = 9.8284e-04
Loss = 5.9577e-03, PNorm = 50.4255, GNorm = 3.7993, lr_0 = 9.4120e-04
Validation rmse = 1.695585
Epoch 3
Loss = 5.0855e-03, PNorm = 50.4603, GNorm = 1.0400, lr_0 = 8.9744e-04
Loss = 4.9318e-03, PNorm = 50.4858, GNorm = 4.6047, lr_0 = 8.5943e-04
Validation rmse = 1.403943
Epoch 4
Loss = 3.2231e-03, PNorm = 50.5068, GNorm = 1.2578, lr_0 = 8.2303e-04
Loss = 3.6269e-03, PNorm = 50.5278, GNorm = 0.9120, lr_0 = 7.8816e-04
Validation rmse = 1.407892
Epoch 5
Loss = 3.4500e-03, PNorm = 50.5458, GNorm = 2.2186, lr_0 = 7.5478e-04
Loss = 3.1621e-03, PNorm = 50.5646, GNorm = 1.7799, lr_0 = 7.2281e-04
Validation rmse = 1.374732
Epoch 6
Loss = 3.1663e-03, PNorm = 50.5818, GNorm = 1.2635, lr_0 = 6.8920e-04
Loss = 2.8250e-03, PNorm = 50.6023, GNorm = 1.6128, lr_0 = 6.6001e-04
Validation rmse = 1.633442
Epoch 7
Loss = 3.2894e-03, PNorm = 50.6175, GNorm = 1.7567, lr_0 = 6.3205e-04
Loss = 3.0030e-03, PNorm = 50.6329, GNorm = 2.9546, lr_0 = 6.0528e-04
Validation rmse = 1.287231
Epoch 8
Loss = 2.5477e-03, PNorm = 50.6499, GNorm = 1.6989, lr_0 = 5.7714e-04
Loss = 2.1813e-03, PNorm = 50.6648, GNorm = 1.5399, lr_0 = 5.5269e-04
Validation rmse = 1.306738
Epoch 9
Loss = 1.8761e-03, PNorm = 50.6779, GNorm = 1.2029, lr_0 = 5.2928e-04
Loss = 1.9887e-03, PNorm = 50.6876, GNorm = 0.6683, lr_0 = 5.0686e-04
Validation rmse = 1.202608
Epoch 10
Loss = 1.9187e-03, PNorm = 50.6975, GNorm = 1.0753, lr_0 = 4.8539e-04
Loss = 1.6590e-03, PNorm = 50.7065, GNorm = 1.2171, lr_0 = 4.6483e-04
Validation rmse = 1.054032
Epoch 11
Loss = 2.1711e-03, PNorm = 50.7175, GNorm = 2.9790, lr_0 = 4.4322e-04
Loss = 2.1071e-03, PNorm = 50.7262, GNorm = 3.8352, lr_0 = 4.2444e-04
Validation rmse = 1.228194
Epoch 12
Loss = 1.5777e-03, PNorm = 50.7358, GNorm = 0.6308, lr_0 = 4.0646e-04
Loss = 1.9855e-03, PNorm = 50.7436, GNorm = 2.3925, lr_0 = 3.8925e-04
Validation rmse = 1.258335
Epoch 13
Loss = 2.2754e-03, PNorm = 50.7511, GNorm = 1.1927, lr_0 = 3.7276e-04
Loss = 1.7652e-03, PNorm = 50.7582, GNorm = 1.1753, lr_0 = 3.5697e-04
Validation rmse = 1.203049
Epoch 14
Loss = 1.5966e-03, PNorm = 50.7667, GNorm = 2.1384, lr_0 = 3.4037e-04
Loss = 1.9159e-03, PNorm = 50.7733, GNorm = 1.2814, lr_0 = 3.2596e-04
Validation rmse = 1.220311
Epoch 15
Loss = 1.9525e-03, PNorm = 50.7779, GNorm = 0.8680, lr_0 = 3.1215e-04
Loss = 1.5310e-03, PNorm = 50.7850, GNorm = 1.1709, lr_0 = 2.9893e-04
Validation rmse = 1.097209
Epoch 16
Loss = 1.2577e-03, PNorm = 50.7902, GNorm = 1.1019, lr_0 = 2.8503e-04
Loss = 1.6025e-03, PNorm = 50.7944, GNorm = 1.2622, lr_0 = 2.7295e-04
Validation rmse = 1.161378
Epoch 17
Loss = 1.4856e-03, PNorm = 50.7996, GNorm = 1.8530, lr_0 = 2.6139e-04
Loss = 1.5213e-03, PNorm = 50.8035, GNorm = 1.0878, lr_0 = 2.5032e-04
Validation rmse = 1.103291
Epoch 18
Loss = 1.6324e-03, PNorm = 50.8077, GNorm = 1.5016, lr_0 = 2.3972e-04
Loss = 1.5100e-03, PNorm = 50.8111, GNorm = 2.5792, lr_0 = 2.2956e-04
Validation rmse = 1.211859
Epoch 19
Loss = 1.2693e-03, PNorm = 50.8149, GNorm = 2.6849, lr_0 = 2.1889e-04
Loss = 1.6830e-03, PNorm = 50.8178, GNorm = 0.7968, lr_0 = 2.0962e-04
Validation rmse = 1.163971
Epoch 20
Loss = 1.2679e-03, PNorm = 50.8213, GNorm = 0.6606, lr_0 = 2.0074e-04
Loss = 1.6112e-03, PNorm = 50.8253, GNorm = 0.5877, lr_0 = 1.9224e-04
Validation rmse = 1.254698
Epoch 21
Loss = 1.4357e-03, PNorm = 50.8285, GNorm = 1.7701, lr_0 = 1.8409e-04
Loss = 1.5226e-03, PNorm = 50.8311, GNorm = 1.3484, lr_0 = 1.7630e-04
Validation rmse = 1.218014
Epoch 22
Loss = 1.4057e-03, PNorm = 50.8342, GNorm = 1.5662, lr_0 = 1.6810e-04
Loss = 1.3407e-03, PNorm = 50.8364, GNorm = 2.3875, lr_0 = 1.6098e-04
Validation rmse = 1.124017
Epoch 23
Loss = 1.3728e-03, PNorm = 50.8394, GNorm = 0.7172, lr_0 = 1.5416e-04
Loss = 1.4050e-03, PNorm = 50.8412, GNorm = 1.1499, lr_0 = 1.4763e-04
Loss = 1.4410e-03, PNorm = 50.8415, GNorm = 1.2890, lr_0 = 1.4699e-04
Validation rmse = 1.109633
Epoch 24
Loss = 1.6148e-03, PNorm = 50.8445, GNorm = 1.3455, lr_0 = 1.4077e-04
Loss = 1.3014e-03, PNorm = 50.8465, GNorm = 1.6314, lr_0 = 1.3480e-04
Validation rmse = 1.230849
Epoch 25
Loss = 1.3049e-03, PNorm = 50.8495, GNorm = 1.2977, lr_0 = 1.2909e-04
Loss = 1.4110e-03, PNorm = 50.8513, GNorm = 1.2451, lr_0 = 1.2362e-04
Validation rmse = 1.144437
Epoch 26
Loss = 1.1833e-03, PNorm = 50.8540, GNorm = 1.0940, lr_0 = 1.1839e-04
Validation rmse = 1.278458
Epoch 27
Loss = 1.7600e-03, PNorm = 50.8556, GNorm = 2.6799, lr_0 = 1.1288e-04
Loss = 1.3223e-03, PNorm = 50.8579, GNorm = 1.7067, lr_0 = 1.0810e-04
Validation rmse = 1.198503
Epoch 28
Loss = 1.0730e-03, PNorm = 50.8594, GNorm = 0.4796, lr_0 = 1.0352e-04
Loss = 1.3771e-03, PNorm = 50.8617, GNorm = 0.7953, lr_0 = 1.0000e-04
Validation rmse = 1.191966
Epoch 29
Loss = 9.7372e-04, PNorm = 50.8635, GNorm = 0.6205, lr_0 = 1.0000e-04
Loss = 1.4400e-03, PNorm = 50.8665, GNorm = 1.8276, lr_0 = 1.0000e-04
Validation rmse = 1.185032
Model 0 best validation rmse = 1.054032 on epoch 10
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.128564
Ensemble test rmse = 1.128564
Fold 2
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.35000000000000003,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1100,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1100,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.35000000000000003_ffn_num_layers_1_hidden_size_1100/fold_2',
 'save_smiles_splits': True,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total scaffolds = 195 | train scaffolds = 55 | val scaffolds = 64 | test scaffolds = 76
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.35000000000000003, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1100, bias=False)
      (W_h): Linear(in_features=1100, out_features=1100, bias=False)
      (W_o): Linear(in_features=1233, out_features=1100, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.35000000000000003, inplace=False)
    (1): Linear(in_features=1104, out_features=1, bias=True)
  )
)
Number of parameters = 2,730,205
Moving model to cuda
Epoch 0
Loss = 1.5682e-02, PNorm = 50.2416, GNorm = 9.8934, lr_0 = 3.6053e-04
Validation rmse = 1.591599
Epoch 1
Loss = 5.9644e-03, PNorm = 50.2792, GNorm = 2.4220, lr_0 = 6.2105e-04
Loss = 8.5006e-03, PNorm = 50.3297, GNorm = 3.8761, lr_0 = 8.5789e-04
Validation rmse = 1.404879
Epoch 2
Loss = 6.6707e-03, PNorm = 50.3875, GNorm = 2.4162, lr_0 = 9.8284e-04
Loss = 5.6452e-03, PNorm = 50.4363, GNorm = 3.9491, lr_0 = 9.4120e-04
Validation rmse = 1.471606
Epoch 3
Loss = 4.4883e-03, PNorm = 50.4763, GNorm = 2.4889, lr_0 = 8.9744e-04
Loss = 4.0347e-03, PNorm = 50.5039, GNorm = 3.6915, lr_0 = 8.5943e-04
Validation rmse = 1.326334
Epoch 4
Loss = 3.4590e-03, PNorm = 50.5297, GNorm = 2.0432, lr_0 = 8.2303e-04
Loss = 4.6098e-03, PNorm = 50.5624, GNorm = 3.4530, lr_0 = 7.8816e-04
Validation rmse = 1.500762
Epoch 5
Loss = 3.5399e-03, PNorm = 50.5881, GNorm = 1.6664, lr_0 = 7.5478e-04
Loss = 3.0346e-03, PNorm = 50.6075, GNorm = 1.7454, lr_0 = 7.2281e-04
Validation rmse = 1.287999
Epoch 6
Loss = 2.5177e-03, PNorm = 50.6296, GNorm = 0.8918, lr_0 = 6.8920e-04
Loss = 2.5659e-03, PNorm = 50.6489, GNorm = 1.2160, lr_0 = 6.6001e-04
Validation rmse = 1.332286
Epoch 7
Loss = 3.1937e-03, PNorm = 50.6657, GNorm = 3.5309, lr_0 = 6.3205e-04
Loss = 2.2884e-03, PNorm = 50.6813, GNorm = 1.2020, lr_0 = 6.0528e-04
Validation rmse = 1.225525
Epoch 8
Loss = 3.0547e-03, PNorm = 50.6999, GNorm = 1.7476, lr_0 = 5.7714e-04
Loss = 2.4610e-03, PNorm = 50.7187, GNorm = 0.8305, lr_0 = 5.5269e-04
Validation rmse = 1.282695
Epoch 9
Loss = 1.9558e-03, PNorm = 50.7337, GNorm = 1.7471, lr_0 = 5.2928e-04
Loss = 2.0489e-03, PNorm = 50.7480, GNorm = 1.1445, lr_0 = 5.0686e-04
Validation rmse = 1.231473
Epoch 10
Loss = 2.0378e-03, PNorm = 50.7589, GNorm = 2.4095, lr_0 = 4.8539e-04
Loss = 2.0656e-03, PNorm = 50.7718, GNorm = 1.7870, lr_0 = 4.6483e-04
Validation rmse = 1.213106
Epoch 11
Loss = 2.2868e-03, PNorm = 50.7842, GNorm = 1.1864, lr_0 = 4.4322e-04
Loss = 2.4436e-03, PNorm = 50.7956, GNorm = 2.1678, lr_0 = 4.2444e-04
Validation rmse = 1.240660
Epoch 12
Loss = 2.1264e-03, PNorm = 50.8088, GNorm = 1.1742, lr_0 = 4.0646e-04
Loss = 1.7692e-03, PNorm = 50.8186, GNorm = 1.6338, lr_0 = 3.8925e-04
Validation rmse = 1.336948
Epoch 13
Loss = 2.3818e-03, PNorm = 50.8291, GNorm = 1.2461, lr_0 = 3.7276e-04
Loss = 1.9819e-03, PNorm = 50.8379, GNorm = 1.2931, lr_0 = 3.5697e-04
Validation rmse = 1.258207
Epoch 14
Loss = 1.9490e-03, PNorm = 50.8475, GNorm = 1.4067, lr_0 = 3.4037e-04
Loss = 1.8320e-03, PNorm = 50.8541, GNorm = 2.0189, lr_0 = 3.2596e-04
Validation rmse = 1.165215
Epoch 15
Loss = 1.7744e-03, PNorm = 50.8626, GNorm = 1.7510, lr_0 = 3.1215e-04
Loss = 1.6874e-03, PNorm = 50.8690, GNorm = 1.1647, lr_0 = 2.9893e-04
Validation rmse = 1.197793
Epoch 16
Loss = 1.6323e-03, PNorm = 50.8759, GNorm = 1.5242, lr_0 = 2.8503e-04
Loss = 1.8648e-03, PNorm = 50.8819, GNorm = 2.1419, lr_0 = 2.7295e-04
Validation rmse = 1.211132
Epoch 17
Loss = 1.6285e-03, PNorm = 50.8884, GNorm = 2.8255, lr_0 = 2.6139e-04
Loss = 1.6394e-03, PNorm = 50.8940, GNorm = 3.6274, lr_0 = 2.5032e-04
Validation rmse = 1.156036
Epoch 18
Loss = 1.8009e-03, PNorm = 50.9014, GNorm = 1.3885, lr_0 = 2.3972e-04
Loss = 1.7161e-03, PNorm = 50.9064, GNorm = 1.1254, lr_0 = 2.2956e-04
Validation rmse = 1.137634
Epoch 19
Loss = 1.9982e-03, PNorm = 50.9109, GNorm = 2.0114, lr_0 = 2.1889e-04
Loss = 1.5368e-03, PNorm = 50.9172, GNorm = 1.0086, lr_0 = 2.0962e-04
Validation rmse = 1.161209
Epoch 20
Loss = 1.4055e-03, PNorm = 50.9202, GNorm = 0.8511, lr_0 = 2.0074e-04
Loss = 1.5730e-03, PNorm = 50.9242, GNorm = 1.0823, lr_0 = 1.9224e-04
Validation rmse = 1.183925
Epoch 21
Loss = 1.5851e-03, PNorm = 50.9270, GNorm = 1.3527, lr_0 = 1.8409e-04
Loss = 1.6131e-03, PNorm = 50.9307, GNorm = 1.2605, lr_0 = 1.7630e-04
Validation rmse = 1.135499
Epoch 22
Loss = 1.5296e-03, PNorm = 50.9345, GNorm = 0.7691, lr_0 = 1.6810e-04
Loss = 1.3164e-03, PNorm = 50.9379, GNorm = 0.5959, lr_0 = 1.6098e-04
Validation rmse = 1.157520
Epoch 23
Loss = 1.1974e-03, PNorm = 50.9409, GNorm = 2.1795, lr_0 = 1.5416e-04
Loss = 1.5742e-03, PNorm = 50.9438, GNorm = 1.6694, lr_0 = 1.4763e-04
Loss = 3.6210e-03, PNorm = 50.9440, GNorm = 1.9759, lr_0 = 1.4699e-04
Validation rmse = 1.237396
Epoch 24
Loss = 1.3826e-03, PNorm = 50.9464, GNorm = 2.5083, lr_0 = 1.4077e-04
Loss = 1.5813e-03, PNorm = 50.9482, GNorm = 0.8339, lr_0 = 1.3480e-04
Validation rmse = 1.116813
Epoch 25
Loss = 1.7183e-03, PNorm = 50.9504, GNorm = 0.5224, lr_0 = 1.2909e-04
Loss = 1.1404e-03, PNorm = 50.9524, GNorm = 1.7641, lr_0 = 1.2362e-04
Validation rmse = 1.167209
Epoch 26
Loss = 1.3244e-03, PNorm = 50.9551, GNorm = 0.7297, lr_0 = 1.1839e-04
Validation rmse = 1.180572
Epoch 27
Loss = 9.0059e-04, PNorm = 50.9575, GNorm = 0.6311, lr_0 = 1.1288e-04
Loss = 1.2840e-03, PNorm = 50.9595, GNorm = 1.4614, lr_0 = 1.0810e-04
Validation rmse = 1.143855
Epoch 28
Loss = 1.1705e-03, PNorm = 50.9613, GNorm = 1.6315, lr_0 = 1.0352e-04
Loss = 1.2980e-03, PNorm = 50.9639, GNorm = 0.9501, lr_0 = 1.0000e-04
Validation rmse = 1.140597
Epoch 29
Loss = 1.5389e-03, PNorm = 50.9659, GNorm = 1.3023, lr_0 = 1.0000e-04
Loss = 1.4025e-03, PNorm = 50.9675, GNorm = 1.4605, lr_0 = 1.0000e-04
Validation rmse = 1.164174
Model 0 best validation rmse = 1.116813 on epoch 24
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.092923
Ensemble test rmse = 1.092923
Fold 3
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.35000000000000003,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1100,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1100,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.35000000000000003_ffn_num_layers_1_hidden_size_1100/fold_3',
 'save_smiles_splits': True,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total scaffolds = 195 | train scaffolds = 80 | val scaffolds = 54 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.35000000000000003, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1100, bias=False)
      (W_h): Linear(in_features=1100, out_features=1100, bias=False)
      (W_o): Linear(in_features=1233, out_features=1100, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.35000000000000003, inplace=False)
    (1): Linear(in_features=1104, out_features=1, bias=True)
  )
)
Number of parameters = 2,730,205
Moving model to cuda
Epoch 0
Loss = 2.1773e-02, PNorm = 50.2379, GNorm = 27.0640, lr_0 = 3.6053e-04
Validation rmse = 1.842282
Epoch 1
Loss = 1.6131e-02, PNorm = 50.2706, GNorm = 8.9024, lr_0 = 6.2105e-04
Loss = 1.1484e-02, PNorm = 50.3255, GNorm = 6.5956, lr_0 = 8.5789e-04
Validation rmse = 1.739103
Epoch 2
Loss = 7.9561e-03, PNorm = 50.3790, GNorm = 2.2791, lr_0 = 9.8284e-04
Loss = 6.1510e-03, PNorm = 50.4167, GNorm = 3.5221, lr_0 = 9.4120e-04
Validation rmse = 1.543125
Epoch 3
Loss = 5.3194e-03, PNorm = 50.4509, GNorm = 1.6485, lr_0 = 8.9744e-04
Loss = 4.9008e-03, PNorm = 50.4707, GNorm = 1.6277, lr_0 = 8.5943e-04
Validation rmse = 1.395598
Epoch 4
Loss = 2.7904e-03, PNorm = 50.4938, GNorm = 1.1660, lr_0 = 8.2303e-04
Loss = 4.1183e-03, PNorm = 50.5156, GNorm = 2.2614, lr_0 = 7.8816e-04
Validation rmse = 1.385415
Epoch 5
Loss = 4.9713e-03, PNorm = 50.5338, GNorm = 4.6253, lr_0 = 7.5478e-04
Loss = 3.3418e-03, PNorm = 50.5560, GNorm = 0.7576, lr_0 = 7.2281e-04
Validation rmse = 1.451187
Epoch 6
Loss = 3.0169e-03, PNorm = 50.5773, GNorm = 1.0141, lr_0 = 6.8920e-04
Loss = 2.9188e-03, PNorm = 50.5912, GNorm = 2.4353, lr_0 = 6.6001e-04
Validation rmse = 1.353204
Epoch 7
Loss = 1.7911e-03, PNorm = 50.6059, GNorm = 0.8863, lr_0 = 6.3205e-04
Loss = 2.0854e-03, PNorm = 50.6157, GNorm = 1.0874, lr_0 = 6.0528e-04
Validation rmse = 1.221187
Epoch 8
Loss = 2.4822e-03, PNorm = 50.6300, GNorm = 1.1683, lr_0 = 5.7714e-04
Loss = 2.0344e-03, PNorm = 50.6436, GNorm = 2.1606, lr_0 = 5.5269e-04
Validation rmse = 1.344073
Epoch 9
Loss = 2.1578e-03, PNorm = 50.6541, GNorm = 1.1754, lr_0 = 5.2928e-04
Loss = 2.1462e-03, PNorm = 50.6655, GNorm = 1.8664, lr_0 = 5.0686e-04
Validation rmse = 1.229668
Epoch 10
Loss = 1.9245e-03, PNorm = 50.6775, GNorm = 1.8442, lr_0 = 4.8539e-04
Loss = 1.9116e-03, PNorm = 50.6884, GNorm = 1.1524, lr_0 = 4.6483e-04
Validation rmse = 1.206676
Epoch 11
Loss = 1.8043e-03, PNorm = 50.7003, GNorm = 2.0544, lr_0 = 4.4322e-04
Loss = 2.1239e-03, PNorm = 50.7096, GNorm = 0.8556, lr_0 = 4.2444e-04
Validation rmse = 1.094894
Epoch 12
Loss = 2.0456e-03, PNorm = 50.7209, GNorm = 4.8205, lr_0 = 4.0646e-04
Loss = 1.6881e-03, PNorm = 50.7308, GNorm = 1.3028, lr_0 = 3.8925e-04
Validation rmse = 1.324681
Epoch 13
Loss = 1.5033e-03, PNorm = 50.7392, GNorm = 1.7163, lr_0 = 3.7276e-04
Loss = 1.6181e-03, PNorm = 50.7456, GNorm = 1.6883, lr_0 = 3.5697e-04
Validation rmse = 1.135237
Epoch 14
Loss = 1.8683e-03, PNorm = 50.7520, GNorm = 4.5972, lr_0 = 3.4037e-04
Loss = 1.6954e-03, PNorm = 50.7590, GNorm = 0.9186, lr_0 = 3.2596e-04
Validation rmse = 1.179493
Epoch 15
Loss = 1.8173e-03, PNorm = 50.7675, GNorm = 3.2587, lr_0 = 3.1215e-04
Loss = 1.8174e-03, PNorm = 50.7729, GNorm = 2.3505, lr_0 = 2.9893e-04
Validation rmse = 1.237007
Epoch 16
Loss = 1.7926e-03, PNorm = 50.7802, GNorm = 1.6685, lr_0 = 2.8503e-04
Loss = 1.7942e-03, PNorm = 50.7881, GNorm = 0.5214, lr_0 = 2.7295e-04
Validation rmse = 1.077616
Epoch 17
Loss = 1.3376e-03, PNorm = 50.7926, GNorm = 1.1324, lr_0 = 2.6139e-04
Loss = 1.5571e-03, PNorm = 50.7985, GNorm = 0.8135, lr_0 = 2.5032e-04
Validation rmse = 1.170389
Epoch 18
Loss = 1.4309e-03, PNorm = 50.8021, GNorm = 1.1604, lr_0 = 2.3972e-04
Loss = 1.4138e-03, PNorm = 50.8061, GNorm = 0.6426, lr_0 = 2.2956e-04
Validation rmse = 1.104158
Epoch 19
Loss = 1.6426e-03, PNorm = 50.8105, GNorm = 1.3416, lr_0 = 2.1889e-04
Loss = 1.3831e-03, PNorm = 50.8157, GNorm = 0.8176, lr_0 = 2.0962e-04
Validation rmse = 1.122553
Epoch 20
Loss = 1.2279e-03, PNorm = 50.8167, GNorm = 0.6664, lr_0 = 2.0074e-04
Loss = 1.3814e-03, PNorm = 50.8201, GNorm = 1.4311, lr_0 = 1.9224e-04
Validation rmse = 1.156901
Epoch 21
Loss = 1.1886e-03, PNorm = 50.8232, GNorm = 0.5540, lr_0 = 1.8409e-04
Loss = 1.2947e-03, PNorm = 50.8264, GNorm = 1.4413, lr_0 = 1.7630e-04
Validation rmse = 1.169079
Epoch 22
Loss = 1.3954e-03, PNorm = 50.8292, GNorm = 1.4062, lr_0 = 1.6810e-04
Loss = 1.2958e-03, PNorm = 50.8330, GNorm = 1.3757, lr_0 = 1.6098e-04
Validation rmse = 1.180489
Epoch 23
Loss = 1.2107e-03, PNorm = 50.8347, GNorm = 1.1114, lr_0 = 1.5416e-04
Loss = 1.2896e-03, PNorm = 50.8379, GNorm = 1.9238, lr_0 = 1.4763e-04
Loss = 2.1526e-03, PNorm = 50.8381, GNorm = 1.4822, lr_0 = 1.4699e-04
Validation rmse = 1.146271
Epoch 24
Loss = 1.2284e-03, PNorm = 50.8397, GNorm = 0.6730, lr_0 = 1.4077e-04
Loss = 1.3036e-03, PNorm = 50.8423, GNorm = 1.3079, lr_0 = 1.3480e-04
Validation rmse = 1.136338
Epoch 25
Loss = 1.1764e-03, PNorm = 50.8441, GNorm = 0.6987, lr_0 = 1.2909e-04
Loss = 1.2680e-03, PNorm = 50.8465, GNorm = 2.8633, lr_0 = 1.2362e-04
Validation rmse = 1.187672
Epoch 26
Loss = 1.2913e-03, PNorm = 50.8477, GNorm = 0.9309, lr_0 = 1.1839e-04
Validation rmse = 1.230223
Epoch 27
Loss = 1.8714e-03, PNorm = 50.8497, GNorm = 1.1730, lr_0 = 1.1288e-04
Loss = 1.1587e-03, PNorm = 50.8520, GNorm = 0.5990, lr_0 = 1.0810e-04
Validation rmse = 1.098637
Epoch 28
Loss = 1.2891e-03, PNorm = 50.8533, GNorm = 1.7217, lr_0 = 1.0352e-04
Loss = 1.1118e-03, PNorm = 50.8550, GNorm = 0.4503, lr_0 = 1.0000e-04
Validation rmse = 1.215082
Epoch 29
Loss = 1.1566e-03, PNorm = 50.8569, GNorm = 0.9201, lr_0 = 1.0000e-04
Loss = 1.0893e-03, PNorm = 50.8586, GNorm = 0.8465, lr_0 = 1.0000e-04
Validation rmse = 1.128828
Model 0 best validation rmse = 1.077616 on epoch 16
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.122548
Ensemble test rmse = 1.122548
Fold 4
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.35000000000000003,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1100,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1100,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.35000000000000003_ffn_num_layers_1_hidden_size_1100/fold_4',
 'save_smiles_splits': True,
 'seed': 4,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 4
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 49 | test scaffolds = 62
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.35000000000000003, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1100, bias=False)
      (W_h): Linear(in_features=1100, out_features=1100, bias=False)
      (W_o): Linear(in_features=1233, out_features=1100, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.35000000000000003, inplace=False)
    (1): Linear(in_features=1104, out_features=1, bias=True)
  )
)
Number of parameters = 2,730,205
Moving model to cuda
Epoch 0
Loss = 2.1696e-02, PNorm = 50.2375, GNorm = 4.1160, lr_0 = 3.6053e-04
Validation rmse = 1.385728
Epoch 1
Loss = 1.3084e-02, PNorm = 50.2692, GNorm = 4.0374, lr_0 = 6.2105e-04
Loss = 8.0917e-03, PNorm = 50.3193, GNorm = 4.1198, lr_0 = 8.5789e-04
Validation rmse = 1.427862
Epoch 2
Loss = 8.3382e-03, PNorm = 50.3697, GNorm = 4.2158, lr_0 = 9.8284e-04
Loss = 8.1278e-03, PNorm = 50.4186, GNorm = 1.6030, lr_0 = 9.4120e-04
Validation rmse = 1.645980
Epoch 3
Loss = 5.6228e-03, PNorm = 50.4625, GNorm = 2.1026, lr_0 = 8.9744e-04
Loss = 4.2124e-03, PNorm = 50.4908, GNorm = 1.3585, lr_0 = 8.5943e-04
Validation rmse = 1.601003
Epoch 4
Loss = 3.8127e-03, PNorm = 50.5102, GNorm = 2.6222, lr_0 = 8.2303e-04
Loss = 3.4227e-03, PNorm = 50.5286, GNorm = 6.2318, lr_0 = 7.8816e-04
Validation rmse = 1.571641
Epoch 5
Loss = 4.1934e-03, PNorm = 50.5452, GNorm = 4.2588, lr_0 = 7.5478e-04
Loss = 3.9453e-03, PNorm = 50.5654, GNorm = 1.6680, lr_0 = 7.2281e-04
Validation rmse = 1.093297
Epoch 6
Loss = 3.1470e-03, PNorm = 50.5824, GNorm = 3.7686, lr_0 = 6.8920e-04
Loss = 3.5529e-03, PNorm = 50.5981, GNorm = 1.2371, lr_0 = 6.6001e-04
Validation rmse = 1.322333
Epoch 7
Loss = 2.3166e-03, PNorm = 50.6163, GNorm = 1.9539, lr_0 = 6.3205e-04
Loss = 3.5430e-03, PNorm = 50.6307, GNorm = 1.7776, lr_0 = 6.0528e-04
Validation rmse = 1.684655
Epoch 8
Loss = 2.3842e-03, PNorm = 50.6457, GNorm = 1.2575, lr_0 = 5.7714e-04
Loss = 2.4978e-03, PNorm = 50.6577, GNorm = 1.0753, lr_0 = 5.5269e-04
Validation rmse = 1.118471
Epoch 9
Loss = 2.0806e-03, PNorm = 50.6700, GNorm = 1.5127, lr_0 = 5.2928e-04
Loss = 2.2877e-03, PNorm = 50.6818, GNorm = 0.8137, lr_0 = 5.0686e-04
Validation rmse = 1.240684
Epoch 10
Loss = 2.1455e-03, PNorm = 50.6916, GNorm = 1.5660, lr_0 = 4.8539e-04
Loss = 2.1851e-03, PNorm = 50.7017, GNorm = 0.8877, lr_0 = 4.6483e-04
Validation rmse = 1.308253
Epoch 11
Loss = 2.3177e-03, PNorm = 50.7111, GNorm = 1.1077, lr_0 = 4.4322e-04
Loss = 1.9461e-03, PNorm = 50.7203, GNorm = 1.3035, lr_0 = 4.2444e-04
Validation rmse = 1.364601
Epoch 12
Loss = 1.7144e-03, PNorm = 50.7269, GNorm = 0.6317, lr_0 = 4.0646e-04
Loss = 1.7765e-03, PNorm = 50.7335, GNorm = 0.9085, lr_0 = 3.8925e-04
Validation rmse = 1.164530
Epoch 13
Loss = 1.3881e-03, PNorm = 50.7400, GNorm = 0.7884, lr_0 = 3.7276e-04
Loss = 1.8917e-03, PNorm = 50.7476, GNorm = 1.0399, lr_0 = 3.5697e-04
Validation rmse = 1.085123
Epoch 14
Loss = 1.7190e-03, PNorm = 50.7534, GNorm = 2.5589, lr_0 = 3.4037e-04
Loss = 1.7085e-03, PNorm = 50.7596, GNorm = 0.9906, lr_0 = 3.2596e-04
Validation rmse = 1.086398
Epoch 15
Loss = 1.3360e-03, PNorm = 50.7648, GNorm = 0.5859, lr_0 = 3.1215e-04
Loss = 1.7580e-03, PNorm = 50.7688, GNorm = 1.8145, lr_0 = 2.9893e-04
Validation rmse = 1.198849
Epoch 16
Loss = 1.5637e-03, PNorm = 50.7741, GNorm = 1.9430, lr_0 = 2.8503e-04
Loss = 1.9607e-03, PNorm = 50.7785, GNorm = 0.7161, lr_0 = 2.7295e-04
Validation rmse = 1.110100
Epoch 17
Loss = 1.6121e-03, PNorm = 50.7843, GNorm = 1.1166, lr_0 = 2.6139e-04
Loss = 1.8017e-03, PNorm = 50.7872, GNorm = 1.3074, lr_0 = 2.5032e-04
Validation rmse = 1.258626
Epoch 18
Loss = 1.8376e-03, PNorm = 50.7929, GNorm = 1.3724, lr_0 = 2.3972e-04
Loss = 1.6685e-03, PNorm = 50.7968, GNorm = 1.6163, lr_0 = 2.2956e-04
Validation rmse = 1.172982
Epoch 19
Loss = 1.5273e-03, PNorm = 50.8007, GNorm = 0.9107, lr_0 = 2.1889e-04
Loss = 1.6793e-03, PNorm = 50.8051, GNorm = 1.3812, lr_0 = 2.0962e-04
Validation rmse = 1.329051
Epoch 20
Loss = 1.5897e-03, PNorm = 50.8092, GNorm = 1.0905, lr_0 = 2.0074e-04
Loss = 1.3979e-03, PNorm = 50.8122, GNorm = 2.1257, lr_0 = 1.9224e-04
Validation rmse = 1.366208
Epoch 21
Loss = 1.5014e-03, PNorm = 50.8153, GNorm = 1.1201, lr_0 = 1.8409e-04
Loss = 1.5658e-03, PNorm = 50.8186, GNorm = 1.6095, lr_0 = 1.7630e-04
Validation rmse = 1.182078
Epoch 22
Loss = 1.3601e-03, PNorm = 50.8222, GNorm = 1.2028, lr_0 = 1.6810e-04
Loss = 1.5595e-03, PNorm = 50.8244, GNorm = 0.5073, lr_0 = 1.6098e-04
Validation rmse = 1.193869
Epoch 23
Loss = 1.4268e-03, PNorm = 50.8269, GNorm = 0.8244, lr_0 = 1.5416e-04
Loss = 1.3311e-03, PNorm = 50.8290, GNorm = 1.3025, lr_0 = 1.4763e-04
Loss = 1.7339e-03, PNorm = 50.8293, GNorm = 1.3420, lr_0 = 1.4699e-04
Validation rmse = 1.125912
Epoch 24
Loss = 1.2918e-03, PNorm = 50.8314, GNorm = 0.7668, lr_0 = 1.4077e-04
Loss = 1.3747e-03, PNorm = 50.8333, GNorm = 1.0087, lr_0 = 1.3480e-04
Validation rmse = 1.236458
Epoch 25
Loss = 1.2015e-03, PNorm = 50.8355, GNorm = 0.6926, lr_0 = 1.2909e-04
Loss = 1.5928e-03, PNorm = 50.8374, GNorm = 1.7900, lr_0 = 1.2362e-04
Validation rmse = 1.142931
Epoch 26
Loss = 1.2256e-03, PNorm = 50.8389, GNorm = 0.6453, lr_0 = 1.1839e-04
Validation rmse = 1.107874
Epoch 27
Loss = 9.1983e-04, PNorm = 50.8415, GNorm = 0.7780, lr_0 = 1.1288e-04
Loss = 1.1616e-03, PNorm = 50.8421, GNorm = 1.4647, lr_0 = 1.0810e-04
Validation rmse = 1.068634
Epoch 28
Loss = 9.6671e-04, PNorm = 50.8437, GNorm = 1.5012, lr_0 = 1.0352e-04
Loss = 1.2767e-03, PNorm = 50.8453, GNorm = 0.6687, lr_0 = 1.0000e-04
Validation rmse = 1.241109
Epoch 29
Loss = 1.0500e-03, PNorm = 50.8464, GNorm = 0.8571, lr_0 = 1.0000e-04
Loss = 1.3974e-03, PNorm = 50.8481, GNorm = 1.7798, lr_0 = 1.0000e-04
Validation rmse = 1.056563
Model 0 best validation rmse = 1.056563 on epoch 29
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.203772
Ensemble test rmse = 1.203772
Fold 5
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.35000000000000003,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1100,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1100,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.35000000000000003_ffn_num_layers_1_hidden_size_1100/fold_5',
 'save_smiles_splits': True,
 'seed': 5,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 5
Total scaffolds = 195 | train scaffolds = 94 | val scaffolds = 55 | test scaffolds = 46
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.35000000000000003, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1100, bias=False)
      (W_h): Linear(in_features=1100, out_features=1100, bias=False)
      (W_o): Linear(in_features=1233, out_features=1100, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.35000000000000003, inplace=False)
    (1): Linear(in_features=1104, out_features=1, bias=True)
  )
)
Number of parameters = 2,730,205
Moving model to cuda
Epoch 0
Loss = 2.1053e-02, PNorm = 50.2372, GNorm = 7.4371, lr_0 = 3.6053e-04
Validation rmse = 2.009773
Epoch 1
Loss = 1.0238e-02, PNorm = 50.2709, GNorm = 4.1108, lr_0 = 6.2105e-04
Loss = 6.2895e-03, PNorm = 50.3152, GNorm = 2.2048, lr_0 = 8.5789e-04
Validation rmse = 1.884028
Epoch 2
Loss = 7.4988e-03, PNorm = 50.3675, GNorm = 4.1611, lr_0 = 9.8284e-04
Loss = 5.9321e-03, PNorm = 50.4149, GNorm = 1.5353, lr_0 = 9.4120e-04
Validation rmse = 1.991980
Epoch 3
Loss = 6.1873e-03, PNorm = 50.4523, GNorm = 1.7931, lr_0 = 8.9744e-04
Loss = 5.3911e-03, PNorm = 50.4881, GNorm = 1.2832, lr_0 = 8.5943e-04
Validation rmse = 1.521510
Epoch 4
Loss = 3.2143e-03, PNorm = 50.5077, GNorm = 1.6223, lr_0 = 8.2303e-04
Loss = 3.5042e-03, PNorm = 50.5258, GNorm = 2.8030, lr_0 = 7.8816e-04
Validation rmse = 1.434526
Epoch 5
Loss = 3.0152e-03, PNorm = 50.5454, GNorm = 3.2636, lr_0 = 7.5478e-04
Loss = 2.7754e-03, PNorm = 50.5620, GNorm = 0.9309, lr_0 = 7.2281e-04
Validation rmse = 1.307314
Epoch 6
Loss = 3.6696e-03, PNorm = 50.5792, GNorm = 1.9471, lr_0 = 6.8920e-04
Loss = 3.2567e-03, PNorm = 50.5988, GNorm = 1.1755, lr_0 = 6.6001e-04
Validation rmse = 1.387878
Epoch 7
Loss = 2.6246e-03, PNorm = 50.6131, GNorm = 1.2718, lr_0 = 6.3205e-04
Loss = 2.3537e-03, PNorm = 50.6302, GNorm = 0.9174, lr_0 = 6.0528e-04
Validation rmse = 1.211912
Epoch 8
Loss = 2.0556e-03, PNorm = 50.6433, GNorm = 1.8556, lr_0 = 5.7714e-04
Loss = 2.7540e-03, PNorm = 50.6581, GNorm = 4.4438, lr_0 = 5.5269e-04
Validation rmse = 1.245728
Epoch 9
Loss = 2.6700e-03, PNorm = 50.6724, GNorm = 1.0936, lr_0 = 5.2928e-04
Loss = 2.5236e-03, PNorm = 50.6871, GNorm = 1.1426, lr_0 = 5.0686e-04
Validation rmse = 1.244568
Epoch 10
Loss = 2.0539e-03, PNorm = 50.7004, GNorm = 1.4905, lr_0 = 4.8539e-04
Loss = 2.3279e-03, PNorm = 50.7120, GNorm = 3.1374, lr_0 = 4.6483e-04
Validation rmse = 1.354321
Epoch 11
Loss = 1.7239e-03, PNorm = 50.7256, GNorm = 1.1882, lr_0 = 4.4322e-04
Loss = 1.8551e-03, PNorm = 50.7374, GNorm = 1.7097, lr_0 = 4.2444e-04
Validation rmse = 1.134663
Epoch 12
Loss = 1.7846e-03, PNorm = 50.7462, GNorm = 1.5938, lr_0 = 4.0646e-04
Loss = 1.9636e-03, PNorm = 50.7562, GNorm = 0.9170, lr_0 = 3.8925e-04
Validation rmse = 1.395931
Epoch 13
Loss = 2.0182e-03, PNorm = 50.7656, GNorm = 3.2682, lr_0 = 3.7276e-04
Loss = 1.9951e-03, PNorm = 50.7728, GNorm = 1.7993, lr_0 = 3.5697e-04
Validation rmse = 1.335093
Epoch 14
Loss = 2.2851e-03, PNorm = 50.7817, GNorm = 0.8398, lr_0 = 3.4037e-04
Loss = 1.6665e-03, PNorm = 50.7890, GNorm = 0.6212, lr_0 = 3.2596e-04
Validation rmse = 1.199314
Epoch 15
Loss = 1.7411e-03, PNorm = 50.7961, GNorm = 1.0715, lr_0 = 3.1215e-04
Loss = 1.6644e-03, PNorm = 50.8028, GNorm = 0.7181, lr_0 = 2.9893e-04
Validation rmse = 1.120389
Epoch 16
Loss = 1.5391e-03, PNorm = 50.8090, GNorm = 1.2716, lr_0 = 2.8503e-04
Loss = 1.7845e-03, PNorm = 50.8153, GNorm = 1.1278, lr_0 = 2.7295e-04
Validation rmse = 1.241933
Epoch 17
Loss = 1.7765e-03, PNorm = 50.8224, GNorm = 1.5982, lr_0 = 2.6139e-04
Loss = 1.6574e-03, PNorm = 50.8261, GNorm = 0.6846, lr_0 = 2.5032e-04
Validation rmse = 1.157218
Epoch 18
Loss = 1.6902e-03, PNorm = 50.8309, GNorm = 1.6375, lr_0 = 2.3972e-04
Loss = 1.5363e-03, PNorm = 50.8371, GNorm = 1.0704, lr_0 = 2.2956e-04
Validation rmse = 1.148034
Epoch 19
Loss = 1.5295e-03, PNorm = 50.8412, GNorm = 1.0953, lr_0 = 2.1889e-04
Loss = 1.7439e-03, PNorm = 50.8463, GNorm = 0.7941, lr_0 = 2.0962e-04
Validation rmse = 1.132769
Epoch 20
Loss = 1.8247e-03, PNorm = 50.8519, GNorm = 1.0359, lr_0 = 2.0074e-04
Loss = 1.5920e-03, PNorm = 50.8558, GNorm = 1.8033, lr_0 = 1.9224e-04
Validation rmse = 1.107347
Epoch 21
Loss = 1.4025e-03, PNorm = 50.8589, GNorm = 1.6689, lr_0 = 1.8409e-04
Loss = 1.5727e-03, PNorm = 50.8628, GNorm = 1.9371, lr_0 = 1.7630e-04
Validation rmse = 1.198450
Epoch 22
Loss = 1.3528e-03, PNorm = 50.8656, GNorm = 0.7916, lr_0 = 1.6810e-04
Loss = 1.5295e-03, PNorm = 50.8700, GNorm = 0.7195, lr_0 = 1.6098e-04
Validation rmse = 1.102533
Epoch 23
Loss = 1.5081e-03, PNorm = 50.8732, GNorm = 1.3242, lr_0 = 1.5416e-04
Loss = 1.3395e-03, PNorm = 50.8759, GNorm = 0.7827, lr_0 = 1.4763e-04
Loss = 9.7712e-04, PNorm = 50.8761, GNorm = 0.7819, lr_0 = 1.4699e-04
Validation rmse = 1.215426
Epoch 24
Loss = 1.3372e-03, PNorm = 50.8779, GNorm = 0.7919, lr_0 = 1.4077e-04
Loss = 1.5220e-03, PNorm = 50.8803, GNorm = 1.0723, lr_0 = 1.3480e-04
Validation rmse = 1.257093
Epoch 25
Loss = 1.3673e-03, PNorm = 50.8831, GNorm = 1.5717, lr_0 = 1.2909e-04
Loss = 1.6081e-03, PNorm = 50.8850, GNorm = 1.9043, lr_0 = 1.2362e-04
Validation rmse = 1.209624
Epoch 26
Loss = 1.4063e-03, PNorm = 50.8881, GNorm = 1.6633, lr_0 = 1.1839e-04
Validation rmse = 1.125504
Epoch 27
Loss = 1.4400e-03, PNorm = 50.8905, GNorm = 0.9087, lr_0 = 1.1288e-04
Loss = 1.1575e-03, PNorm = 50.8925, GNorm = 0.9696, lr_0 = 1.0810e-04
Validation rmse = 1.063987
Epoch 28
Loss = 9.1720e-04, PNorm = 50.8950, GNorm = 0.7029, lr_0 = 1.0352e-04
Loss = 1.4760e-03, PNorm = 50.8964, GNorm = 1.3998, lr_0 = 1.0000e-04
Validation rmse = 1.053495
Epoch 29
Loss = 1.1099e-03, PNorm = 50.8986, GNorm = 0.6721, lr_0 = 1.0000e-04
Loss = 1.2867e-03, PNorm = 50.9010, GNorm = 0.6585, lr_0 = 1.0000e-04
Validation rmse = 1.171510
Model 0 best validation rmse = 1.053495 on epoch 28
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.158542
Ensemble test rmse = 1.158542
Fold 6
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.35000000000000003,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1100,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1100,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.35000000000000003_ffn_num_layers_1_hidden_size_1100/fold_6',
 'save_smiles_splits': True,
 'seed': 6,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 6
Total scaffolds = 195 | train scaffolds = 64 | val scaffolds = 68 | test scaffolds = 63
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.35000000000000003, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1100, bias=False)
      (W_h): Linear(in_features=1100, out_features=1100, bias=False)
      (W_o): Linear(in_features=1233, out_features=1100, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.35000000000000003, inplace=False)
    (1): Linear(in_features=1104, out_features=1, bias=True)
  )
)
Number of parameters = 2,730,205
Moving model to cuda
Epoch 0
Loss = 2.0075e-02, PNorm = 50.2383, GNorm = 13.1948, lr_0 = 3.6053e-04
Validation rmse = 1.799998
Epoch 1
Loss = 1.0386e-02, PNorm = 50.2708, GNorm = 3.4626, lr_0 = 6.2105e-04
Loss = 8.2506e-03, PNorm = 50.3218, GNorm = 6.5041, lr_0 = 8.5789e-04
Validation rmse = 1.983628
Epoch 2
Loss = 7.6064e-03, PNorm = 50.3726, GNorm = 2.9472, lr_0 = 9.8284e-04
Loss = 6.1527e-03, PNorm = 50.4208, GNorm = 2.6989, lr_0 = 9.4120e-04
Validation rmse = 1.466573
Epoch 3
Loss = 3.3403e-03, PNorm = 50.4558, GNorm = 2.6645, lr_0 = 8.9744e-04
Loss = 4.0186e-03, PNorm = 50.4805, GNorm = 4.6862, lr_0 = 8.5943e-04
Validation rmse = 1.373833
Epoch 4
Loss = 3.3972e-03, PNorm = 50.5017, GNorm = 2.9294, lr_0 = 8.2303e-04
Loss = 4.0201e-03, PNorm = 50.5294, GNorm = 2.9085, lr_0 = 7.8816e-04
Validation rmse = 1.356752
Epoch 5
Loss = 3.5370e-03, PNorm = 50.5492, GNorm = 1.7375, lr_0 = 7.5478e-04
Loss = 3.3903e-03, PNorm = 50.5688, GNorm = 2.1522, lr_0 = 7.2281e-04
Validation rmse = 1.605482
Epoch 6
Loss = 3.3517e-03, PNorm = 50.5890, GNorm = 4.4385, lr_0 = 6.8920e-04
Loss = 3.0321e-03, PNorm = 50.6092, GNorm = 1.7750, lr_0 = 6.6001e-04
Validation rmse = 1.304282
Epoch 7
Loss = 2.7541e-03, PNorm = 50.6242, GNorm = 2.9076, lr_0 = 6.3205e-04
Loss = 2.3336e-03, PNorm = 50.6356, GNorm = 1.0058, lr_0 = 6.0528e-04
Validation rmse = 1.266049
Epoch 8
Loss = 2.3524e-03, PNorm = 50.6491, GNorm = 1.0511, lr_0 = 5.7714e-04
Loss = 3.1375e-03, PNorm = 50.6651, GNorm = 2.6453, lr_0 = 5.5269e-04
Validation rmse = 1.683543
Epoch 9
Loss = 2.9774e-03, PNorm = 50.6795, GNorm = 2.3607, lr_0 = 5.2928e-04
Loss = 2.2967e-03, PNorm = 50.6957, GNorm = 0.8139, lr_0 = 5.0686e-04
Validation rmse = 1.267399
Epoch 10
Loss = 2.1020e-03, PNorm = 50.7110, GNorm = 1.3730, lr_0 = 4.8539e-04
Loss = 1.7752e-03, PNorm = 50.7215, GNorm = 0.6788, lr_0 = 4.6483e-04
Validation rmse = 1.187286
Epoch 11
Loss = 1.7966e-03, PNorm = 50.7331, GNorm = 0.5629, lr_0 = 4.4322e-04
Loss = 1.8100e-03, PNorm = 50.7432, GNorm = 1.2181, lr_0 = 4.2444e-04
Validation rmse = 1.127726
Epoch 12
Loss = 1.6791e-03, PNorm = 50.7525, GNorm = 1.6927, lr_0 = 4.0646e-04
Loss = 1.7621e-03, PNorm = 50.7613, GNorm = 1.7545, lr_0 = 3.8925e-04
Validation rmse = 1.219387
Epoch 13
Loss = 1.6159e-03, PNorm = 50.7699, GNorm = 0.8119, lr_0 = 3.7276e-04
Loss = 1.5328e-03, PNorm = 50.7791, GNorm = 2.2138, lr_0 = 3.5697e-04
Validation rmse = 1.377698
Epoch 14
Loss = 1.5523e-03, PNorm = 50.7861, GNorm = 0.8610, lr_0 = 3.4037e-04
Loss = 1.7743e-03, PNorm = 50.7933, GNorm = 0.9048, lr_0 = 3.2596e-04
Validation rmse = 1.154153
Epoch 15
Loss = 1.4774e-03, PNorm = 50.8013, GNorm = 1.3867, lr_0 = 3.1215e-04
Loss = 1.7024e-03, PNorm = 50.8078, GNorm = 2.5076, lr_0 = 2.9893e-04
Validation rmse = 1.299481
Epoch 16
Loss = 1.5019e-03, PNorm = 50.8160, GNorm = 1.1033, lr_0 = 2.8503e-04
Loss = 1.4852e-03, PNorm = 50.8208, GNorm = 3.8700, lr_0 = 2.7295e-04
Validation rmse = 1.407207
Epoch 17
Loss = 1.6130e-03, PNorm = 50.8262, GNorm = 0.8063, lr_0 = 2.6139e-04
Loss = 1.6903e-03, PNorm = 50.8296, GNorm = 1.9301, lr_0 = 2.5032e-04
Validation rmse = 1.330998
Epoch 18
Loss = 2.1373e-03, PNorm = 50.8361, GNorm = 1.1148, lr_0 = 2.3972e-04
Loss = 1.8009e-03, PNorm = 50.8426, GNorm = 1.2301, lr_0 = 2.2956e-04
Validation rmse = 1.118670
Epoch 19
Loss = 1.5865e-03, PNorm = 50.8490, GNorm = 1.2220, lr_0 = 2.1889e-04
Loss = 1.4358e-03, PNorm = 50.8544, GNorm = 0.8903, lr_0 = 2.0962e-04
Validation rmse = 1.261951
Epoch 20
Loss = 1.3573e-03, PNorm = 50.8572, GNorm = 0.7712, lr_0 = 2.0074e-04
Loss = 1.3881e-03, PNorm = 50.8612, GNorm = 0.4830, lr_0 = 1.9224e-04
Validation rmse = 1.218398
Epoch 21
Loss = 1.3134e-03, PNorm = 50.8654, GNorm = 1.3763, lr_0 = 1.8409e-04
Loss = 1.4254e-03, PNorm = 50.8682, GNorm = 0.8877, lr_0 = 1.7630e-04
Validation rmse = 1.239794
Epoch 22
Loss = 1.3713e-03, PNorm = 50.8710, GNorm = 0.7599, lr_0 = 1.6810e-04
Loss = 1.3331e-03, PNorm = 50.8736, GNorm = 1.1202, lr_0 = 1.6098e-04
Validation rmse = 1.164088
Epoch 23
Loss = 1.3777e-03, PNorm = 50.8757, GNorm = 0.8445, lr_0 = 1.5416e-04
Loss = 1.1669e-03, PNorm = 50.8783, GNorm = 0.9647, lr_0 = 1.4763e-04
Loss = 2.7349e-03, PNorm = 50.8785, GNorm = 1.6174, lr_0 = 1.4699e-04
Validation rmse = 1.200588
Epoch 24
Loss = 1.2681e-03, PNorm = 50.8821, GNorm = 1.0882, lr_0 = 1.4077e-04
Loss = 1.1995e-03, PNorm = 50.8851, GNorm = 0.9449, lr_0 = 1.3480e-04
Validation rmse = 1.222647
Epoch 25
Loss = 1.2444e-03, PNorm = 50.8868, GNorm = 1.9195, lr_0 = 1.2909e-04
Loss = 1.2588e-03, PNorm = 50.8890, GNorm = 1.6584, lr_0 = 1.2362e-04
Validation rmse = 1.128988
Epoch 26
Loss = 1.2558e-03, PNorm = 50.8898, GNorm = 0.5238, lr_0 = 1.1839e-04
Validation rmse = 1.201594
Epoch 27
Loss = 1.1843e-03, PNorm = 50.8922, GNorm = 0.6394, lr_0 = 1.1288e-04
Loss = 1.1297e-03, PNorm = 50.8935, GNorm = 0.6301, lr_0 = 1.0810e-04
Validation rmse = 1.140706
Epoch 28
Loss = 9.6499e-04, PNorm = 50.8958, GNorm = 1.1466, lr_0 = 1.0352e-04
Loss = 1.2042e-03, PNorm = 50.8963, GNorm = 0.7855, lr_0 = 1.0000e-04
Validation rmse = 1.225882
Epoch 29
Loss = 1.2426e-03, PNorm = 50.8980, GNorm = 1.9901, lr_0 = 1.0000e-04
Loss = 1.1848e-03, PNorm = 50.9003, GNorm = 0.8353, lr_0 = 1.0000e-04
Validation rmse = 1.219130
Model 0 best validation rmse = 1.118670 on epoch 18
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.029708
Ensemble test rmse = 1.029708
Fold 7
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.35000000000000003,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1100,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1100,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.35000000000000003_ffn_num_layers_1_hidden_size_1100/fold_7',
 'save_smiles_splits': True,
 'seed': 7,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 7
Total scaffolds = 195 | train scaffolds = 69 | val scaffolds = 65 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.35000000000000003, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1100, bias=False)
      (W_h): Linear(in_features=1100, out_features=1100, bias=False)
      (W_o): Linear(in_features=1233, out_features=1100, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.35000000000000003, inplace=False)
    (1): Linear(in_features=1104, out_features=1, bias=True)
  )
)
Number of parameters = 2,730,205
Moving model to cuda
Epoch 0
Loss = 1.9325e-02, PNorm = 50.2388, GNorm = 10.3575, lr_0 = 3.6053e-04
Validation rmse = 2.018176
Epoch 1
Loss = 1.2819e-02, PNorm = 50.2747, GNorm = 4.7181, lr_0 = 6.2105e-04
Loss = 8.9428e-03, PNorm = 50.3254, GNorm = 8.5450, lr_0 = 8.5789e-04
Validation rmse = 1.711153
Epoch 2
Loss = 9.5988e-03, PNorm = 50.3875, GNorm = 3.8211, lr_0 = 9.8284e-04
Loss = 6.9913e-03, PNorm = 50.4372, GNorm = 6.0671, lr_0 = 9.4120e-04
Validation rmse = 2.338514
Epoch 3
Loss = 4.6191e-03, PNorm = 50.4738, GNorm = 1.8517, lr_0 = 8.9744e-04
Loss = 5.4087e-03, PNorm = 50.5031, GNorm = 5.2027, lr_0 = 8.5943e-04
Validation rmse = 1.838773
Epoch 4
Loss = 3.6825e-03, PNorm = 50.5227, GNorm = 1.7109, lr_0 = 8.2303e-04
Loss = 3.5072e-03, PNorm = 50.5426, GNorm = 1.2140, lr_0 = 7.8816e-04
Validation rmse = 1.644067
Epoch 5
Loss = 3.0068e-03, PNorm = 50.5622, GNorm = 1.0133, lr_0 = 7.5478e-04
Loss = 2.4859e-03, PNorm = 50.5800, GNorm = 1.5829, lr_0 = 7.2281e-04
Validation rmse = 1.785157
Epoch 6
Loss = 4.6259e-03, PNorm = 50.6013, GNorm = 5.3842, lr_0 = 6.8920e-04
Loss = 4.1467e-03, PNorm = 50.6258, GNorm = 3.0445, lr_0 = 6.6001e-04
Validation rmse = 2.008212
Epoch 7
Loss = 3.1849e-03, PNorm = 50.6484, GNorm = 2.3463, lr_0 = 6.3205e-04
Loss = 3.4184e-03, PNorm = 50.6675, GNorm = 1.9416, lr_0 = 6.0528e-04
Validation rmse = 1.592051
Epoch 8
Loss = 2.8436e-03, PNorm = 50.6886, GNorm = 1.7851, lr_0 = 5.7714e-04
Loss = 2.8640e-03, PNorm = 50.7053, GNorm = 1.8164, lr_0 = 5.5269e-04
Validation rmse = 1.439280
Epoch 9
Loss = 2.5893e-03, PNorm = 50.7191, GNorm = 1.8866, lr_0 = 5.2928e-04
Loss = 2.4283e-03, PNorm = 50.7346, GNorm = 2.5827, lr_0 = 5.0686e-04
Validation rmse = 1.756051
Epoch 10
Loss = 2.4887e-03, PNorm = 50.7464, GNorm = 3.0559, lr_0 = 4.8539e-04
Loss = 2.0740e-03, PNorm = 50.7584, GNorm = 1.0671, lr_0 = 4.6483e-04
Validation rmse = 1.483466
Epoch 11
Loss = 1.8341e-03, PNorm = 50.7706, GNorm = 0.8093, lr_0 = 4.4322e-04
Loss = 1.8793e-03, PNorm = 50.7789, GNorm = 0.7670, lr_0 = 4.2444e-04
Validation rmse = 1.492549
Epoch 12
Loss = 1.7082e-03, PNorm = 50.7864, GNorm = 0.7549, lr_0 = 4.0646e-04
Loss = 1.6943e-03, PNorm = 50.7946, GNorm = 1.4257, lr_0 = 3.8925e-04
Validation rmse = 1.327297
Epoch 13
Loss = 2.5051e-03, PNorm = 50.8032, GNorm = 2.3854, lr_0 = 3.7276e-04
Loss = 2.1766e-03, PNorm = 50.8129, GNorm = 1.7903, lr_0 = 3.5697e-04
Validation rmse = 1.446992
Epoch 14
Loss = 1.7134e-03, PNorm = 50.8203, GNorm = 1.0291, lr_0 = 3.4037e-04
Loss = 1.6838e-03, PNorm = 50.8281, GNorm = 1.4085, lr_0 = 3.2596e-04
Validation rmse = 1.454550
Epoch 15
Loss = 1.7701e-03, PNorm = 50.8337, GNorm = 2.1059, lr_0 = 3.1215e-04
Loss = 1.8567e-03, PNorm = 50.8410, GNorm = 1.9499, lr_0 = 2.9893e-04
Validation rmse = 1.637524
Epoch 16
Loss = 1.6719e-03, PNorm = 50.8474, GNorm = 0.7171, lr_0 = 2.8503e-04
Loss = 1.6193e-03, PNorm = 50.8511, GNorm = 0.7184, lr_0 = 2.7295e-04
Validation rmse = 1.712907
Epoch 17
Loss = 1.5970e-03, PNorm = 50.8566, GNorm = 0.5800, lr_0 = 2.6139e-04
Loss = 1.8072e-03, PNorm = 50.8608, GNorm = 0.9567, lr_0 = 2.5032e-04
Validation rmse = 1.496318
Epoch 18
Loss = 1.2369e-03, PNorm = 50.8660, GNorm = 0.6405, lr_0 = 2.3972e-04
Loss = 1.5976e-03, PNorm = 50.8704, GNorm = 0.4739, lr_0 = 2.2956e-04
Validation rmse = 1.520617
Epoch 19
Loss = 1.5871e-03, PNorm = 50.8745, GNorm = 1.0940, lr_0 = 2.1889e-04
Loss = 1.4039e-03, PNorm = 50.8783, GNorm = 0.7029, lr_0 = 2.0962e-04
Validation rmse = 1.461531
Epoch 20
Loss = 1.6200e-03, PNorm = 50.8821, GNorm = 0.8348, lr_0 = 2.0074e-04
Loss = 1.2209e-03, PNorm = 50.8856, GNorm = 0.6178, lr_0 = 1.9224e-04
Validation rmse = 1.563877
Epoch 21
Loss = 1.4152e-03, PNorm = 50.8896, GNorm = 1.2083, lr_0 = 1.8409e-04
Loss = 1.5262e-03, PNorm = 50.8936, GNorm = 0.9723, lr_0 = 1.7630e-04
Validation rmse = 1.661667
Epoch 22
Loss = 1.4592e-03, PNorm = 50.8956, GNorm = 2.5668, lr_0 = 1.6810e-04
Loss = 1.4234e-03, PNorm = 50.8991, GNorm = 1.8399, lr_0 = 1.6098e-04
Validation rmse = 1.496184
Epoch 23
Loss = 1.3077e-03, PNorm = 50.9026, GNorm = 1.2815, lr_0 = 1.5416e-04
Loss = 1.2693e-03, PNorm = 50.9051, GNorm = 0.7227, lr_0 = 1.4763e-04
Loss = 2.2682e-03, PNorm = 50.9053, GNorm = 2.4177, lr_0 = 1.4699e-04
Validation rmse = 1.495866
Epoch 24
Loss = 1.3646e-03, PNorm = 50.9075, GNorm = 1.3774, lr_0 = 1.4077e-04
Loss = 1.5466e-03, PNorm = 50.9105, GNorm = 1.0435, lr_0 = 1.3480e-04
Validation rmse = 1.377691
Epoch 25
Loss = 1.3129e-03, PNorm = 50.9123, GNorm = 1.2366, lr_0 = 1.2909e-04
Loss = 1.6018e-03, PNorm = 50.9157, GNorm = 1.4458, lr_0 = 1.2362e-04
Validation rmse = 1.579146
Epoch 26
Loss = 1.2162e-03, PNorm = 50.9174, GNorm = 1.3685, lr_0 = 1.1839e-04
Validation rmse = 1.486880
Epoch 27
Loss = 1.1272e-03, PNorm = 50.9198, GNorm = 1.5713, lr_0 = 1.1288e-04
Loss = 1.2177e-03, PNorm = 50.9223, GNorm = 1.7052, lr_0 = 1.0810e-04
Validation rmse = 1.572784
Epoch 28
Loss = 1.2065e-03, PNorm = 50.9237, GNorm = 1.3711, lr_0 = 1.0352e-04
Loss = 1.2032e-03, PNorm = 50.9261, GNorm = 1.4754, lr_0 = 1.0000e-04
Validation rmse = 1.474216
Epoch 29
Loss = 1.4475e-03, PNorm = 50.9280, GNorm = 1.0085, lr_0 = 1.0000e-04
Loss = 1.1787e-03, PNorm = 50.9291, GNorm = 1.4811, lr_0 = 1.0000e-04
Validation rmse = 1.514488
Model 0 best validation rmse = 1.327297 on epoch 12
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.037311
Ensemble test rmse = 1.037311
Fold 8
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.35000000000000003,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1100,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1100,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.35000000000000003_ffn_num_layers_1_hidden_size_1100/fold_8',
 'save_smiles_splits': True,
 'seed': 8,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 8
Total scaffolds = 195 | train scaffolds = 75 | val scaffolds = 42 | test scaffolds = 78
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.35000000000000003, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1100, bias=False)
      (W_h): Linear(in_features=1100, out_features=1100, bias=False)
      (W_o): Linear(in_features=1233, out_features=1100, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.35000000000000003, inplace=False)
    (1): Linear(in_features=1104, out_features=1, bias=True)
  )
)
Number of parameters = 2,730,205
Moving model to cuda
Epoch 0
Loss = 1.9786e-02, PNorm = 50.2373, GNorm = 7.5551, lr_0 = 3.6053e-04
Validation rmse = 2.148718
Epoch 1
Loss = 1.0079e-02, PNorm = 50.2726, GNorm = 5.0795, lr_0 = 6.2105e-04
Loss = 7.8341e-03, PNorm = 50.3231, GNorm = 5.8645, lr_0 = 8.5789e-04
Validation rmse = 1.568066
Epoch 2
Loss = 8.2645e-03, PNorm = 50.3757, GNorm = 6.7085, lr_0 = 9.8284e-04
Loss = 4.5676e-03, PNorm = 50.4203, GNorm = 1.0861, lr_0 = 9.4120e-04
Validation rmse = 1.570368
Epoch 3
Loss = 4.5687e-03, PNorm = 50.4524, GNorm = 2.7689, lr_0 = 8.9744e-04
Loss = 3.9861e-03, PNorm = 50.4823, GNorm = 4.0671, lr_0 = 8.5943e-04
Validation rmse = 1.660372
Epoch 4
Loss = 3.6755e-03, PNorm = 50.5047, GNorm = 2.5575, lr_0 = 8.2303e-04
Loss = 3.0589e-03, PNorm = 50.5234, GNorm = 4.1094, lr_0 = 7.8816e-04
Validation rmse = 1.258280
Epoch 5
Loss = 1.9366e-03, PNorm = 50.5409, GNorm = 1.4215, lr_0 = 7.5478e-04
Loss = 3.0279e-03, PNorm = 50.5585, GNorm = 3.3502, lr_0 = 7.2281e-04
Validation rmse = 1.310884
Epoch 6
Loss = 2.3583e-03, PNorm = 50.5759, GNorm = 3.4301, lr_0 = 6.8920e-04
Loss = 2.5066e-03, PNorm = 50.5918, GNorm = 1.6038, lr_0 = 6.6001e-04
Validation rmse = 1.517342
Epoch 7
Loss = 3.0252e-03, PNorm = 50.6081, GNorm = 4.0649, lr_0 = 6.3205e-04
Loss = 2.7080e-03, PNorm = 50.6261, GNorm = 1.9467, lr_0 = 6.0528e-04
Validation rmse = 1.473718
Epoch 8
Loss = 2.7023e-03, PNorm = 50.6420, GNorm = 2.4190, lr_0 = 5.7714e-04
Loss = 2.0162e-03, PNorm = 50.6549, GNorm = 2.4754, lr_0 = 5.5269e-04
Validation rmse = 1.385484
Epoch 9
Loss = 1.7398e-03, PNorm = 50.6711, GNorm = 2.0552, lr_0 = 5.2928e-04
Loss = 1.8263e-03, PNorm = 50.6832, GNorm = 2.0620, lr_0 = 5.0686e-04
Validation rmse = 1.188865
Epoch 10
Loss = 1.4473e-03, PNorm = 50.6941, GNorm = 1.0977, lr_0 = 4.8539e-04
Loss = 1.8340e-03, PNorm = 50.7071, GNorm = 0.9696, lr_0 = 4.6483e-04
Validation rmse = 1.261243
Epoch 11
Loss = 2.0883e-03, PNorm = 50.7176, GNorm = 1.9629, lr_0 = 4.4322e-04
Loss = 1.6569e-03, PNorm = 50.7269, GNorm = 2.6277, lr_0 = 4.2444e-04
Validation rmse = 1.159580
Epoch 12
Loss = 1.7721e-03, PNorm = 50.7372, GNorm = 1.2265, lr_0 = 4.0646e-04
Loss = 1.5473e-03, PNorm = 50.7472, GNorm = 0.8670, lr_0 = 3.8925e-04
Validation rmse = 1.172061
Epoch 13
Loss = 1.3891e-03, PNorm = 50.7553, GNorm = 0.8175, lr_0 = 3.7276e-04
Loss = 1.5730e-03, PNorm = 50.7629, GNorm = 1.2485, lr_0 = 3.5697e-04
Validation rmse = 1.094845
Epoch 14
Loss = 1.4244e-03, PNorm = 50.7725, GNorm = 0.6942, lr_0 = 3.4037e-04
Loss = 1.5492e-03, PNorm = 50.7788, GNorm = 2.0383, lr_0 = 3.2596e-04
Validation rmse = 1.201015
Epoch 15
Loss = 1.6269e-03, PNorm = 50.7834, GNorm = 4.2899, lr_0 = 3.1215e-04
Loss = 1.6816e-03, PNorm = 50.7889, GNorm = 1.3033, lr_0 = 2.9893e-04
Validation rmse = 1.244965
Epoch 16
Loss = 1.3134e-03, PNorm = 50.7964, GNorm = 0.6908, lr_0 = 2.8503e-04
Loss = 1.5261e-03, PNorm = 50.8025, GNorm = 0.7043, lr_0 = 2.7295e-04
Validation rmse = 1.166550
Epoch 17
Loss = 1.4495e-03, PNorm = 50.8064, GNorm = 0.5742, lr_0 = 2.6139e-04
Loss = 1.6042e-03, PNorm = 50.8122, GNorm = 1.1336, lr_0 = 2.5032e-04
Validation rmse = 1.402929
Epoch 18
Loss = 1.6454e-03, PNorm = 50.8165, GNorm = 0.8630, lr_0 = 2.3972e-04
Loss = 1.3959e-03, PNorm = 50.8213, GNorm = 1.0284, lr_0 = 2.2956e-04
Validation rmse = 1.195541
Epoch 19
Loss = 1.3740e-03, PNorm = 50.8260, GNorm = 1.1133, lr_0 = 2.1889e-04
Loss = 1.4349e-03, PNorm = 50.8288, GNorm = 0.7114, lr_0 = 2.0962e-04
Validation rmse = 1.178249
Epoch 20
Loss = 1.2719e-03, PNorm = 50.8334, GNorm = 0.4935, lr_0 = 2.0074e-04
Loss = 1.5573e-03, PNorm = 50.8371, GNorm = 0.9312, lr_0 = 1.9224e-04
Validation rmse = 1.138621
Epoch 21
Loss = 1.3692e-03, PNorm = 50.8415, GNorm = 1.4467, lr_0 = 1.8409e-04
Loss = 1.3969e-03, PNorm = 50.8458, GNorm = 1.1077, lr_0 = 1.7630e-04
Validation rmse = 1.114163
Epoch 22
Loss = 1.2352e-03, PNorm = 50.8494, GNorm = 0.5421, lr_0 = 1.6810e-04
Loss = 1.4039e-03, PNorm = 50.8523, GNorm = 1.8674, lr_0 = 1.6098e-04
Validation rmse = 1.165338
Epoch 23
Loss = 1.2756e-03, PNorm = 50.8552, GNorm = 1.1190, lr_0 = 1.5416e-04
Loss = 1.2313e-03, PNorm = 50.8577, GNorm = 1.1845, lr_0 = 1.4763e-04
Loss = 1.7911e-03, PNorm = 50.8578, GNorm = 1.6438, lr_0 = 1.4699e-04
Validation rmse = 1.238232
Epoch 24
Loss = 1.1013e-03, PNorm = 50.8596, GNorm = 0.6641, lr_0 = 1.4077e-04
Loss = 1.4243e-03, PNorm = 50.8625, GNorm = 0.9473, lr_0 = 1.3480e-04
Validation rmse = 1.169965
Epoch 25
Loss = 1.2475e-03, PNorm = 50.8640, GNorm = 1.1138, lr_0 = 1.2909e-04
Loss = 1.2597e-03, PNorm = 50.8667, GNorm = 1.4777, lr_0 = 1.2362e-04
Validation rmse = 1.199739
Epoch 26
Loss = 1.4036e-03, PNorm = 50.8691, GNorm = 1.1808, lr_0 = 1.1839e-04
Validation rmse = 1.214719
Epoch 27
Loss = 2.2229e-03, PNorm = 50.8713, GNorm = 2.1790, lr_0 = 1.1288e-04
Loss = 1.1599e-03, PNorm = 50.8730, GNorm = 2.1797, lr_0 = 1.0810e-04
Validation rmse = 1.199149
Epoch 28
Loss = 1.0002e-03, PNorm = 50.8748, GNorm = 0.6316, lr_0 = 1.0352e-04
Loss = 1.3129e-03, PNorm = 50.8758, GNorm = 1.3645, lr_0 = 1.0000e-04
Validation rmse = 1.245525
Epoch 29
Loss = 1.2641e-03, PNorm = 50.8788, GNorm = 0.8085, lr_0 = 1.0000e-04
Loss = 1.0969e-03, PNorm = 50.8803, GNorm = 1.1860, lr_0 = 1.0000e-04
Validation rmse = 1.182725
Model 0 best validation rmse = 1.094845 on epoch 13
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.149209
Ensemble test rmse = 1.149209
Fold 9
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.35000000000000003,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1100,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1100,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.35000000000000003_ffn_num_layers_1_hidden_size_1100/fold_9',
 'save_smiles_splits': True,
 'seed': 9,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 9
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 58 | test scaffolds = 53
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.35000000000000003, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1100, bias=False)
      (W_h): Linear(in_features=1100, out_features=1100, bias=False)
      (W_o): Linear(in_features=1233, out_features=1100, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.35000000000000003, inplace=False)
    (1): Linear(in_features=1104, out_features=1, bias=True)
  )
)
Number of parameters = 2,730,205
Moving model to cuda
Epoch 0
Loss = 2.4182e-02, PNorm = 50.2359, GNorm = 9.9312, lr_0 = 3.6053e-04
Validation rmse = 1.691811
Epoch 1
Loss = 7.5457e-03, PNorm = 50.2680, GNorm = 3.0280, lr_0 = 6.2105e-04
Loss = 8.3462e-03, PNorm = 50.3136, GNorm = 4.9812, lr_0 = 8.5789e-04
Validation rmse = 1.703856
Epoch 2
Loss = 6.8788e-03, PNorm = 50.3646, GNorm = 4.0036, lr_0 = 9.8284e-04
Loss = 7.2975e-03, PNorm = 50.4064, GNorm = 3.8181, lr_0 = 9.4120e-04
Validation rmse = 1.465421
Epoch 3
Loss = 6.9227e-03, PNorm = 50.4473, GNorm = 4.0618, lr_0 = 8.9744e-04
Loss = 5.1813e-03, PNorm = 50.4781, GNorm = 1.2337, lr_0 = 8.5943e-04
Validation rmse = 1.508347
Epoch 4
Loss = 6.0662e-03, PNorm = 50.4968, GNorm = 7.3358, lr_0 = 8.2303e-04
Loss = 3.8028e-03, PNorm = 50.5174, GNorm = 1.5805, lr_0 = 7.8816e-04
Validation rmse = 1.509783
Epoch 5
Loss = 3.0920e-03, PNorm = 50.5330, GNorm = 0.9210, lr_0 = 7.5478e-04
Loss = 3.2561e-03, PNorm = 50.5495, GNorm = 2.3260, lr_0 = 7.2281e-04
Validation rmse = 1.314528
Epoch 6
Loss = 3.8969e-03, PNorm = 50.5656, GNorm = 1.6453, lr_0 = 6.8920e-04
Loss = 2.9385e-03, PNorm = 50.5799, GNorm = 1.7196, lr_0 = 6.6001e-04
Validation rmse = 1.200751
Epoch 7
Loss = 2.8491e-03, PNorm = 50.5963, GNorm = 1.1253, lr_0 = 6.3205e-04
Loss = 2.5123e-03, PNorm = 50.6099, GNorm = 1.6125, lr_0 = 6.0528e-04
Validation rmse = 1.098336
Epoch 8
Loss = 2.5436e-03, PNorm = 50.6231, GNorm = 1.2070, lr_0 = 5.7714e-04
Loss = 2.5240e-03, PNorm = 50.6358, GNorm = 1.5076, lr_0 = 5.5269e-04
Validation rmse = 1.190963
Epoch 9
Loss = 2.7954e-03, PNorm = 50.6494, GNorm = 3.4627, lr_0 = 5.2928e-04
Loss = 2.0759e-03, PNorm = 50.6625, GNorm = 0.9691, lr_0 = 5.0686e-04
Validation rmse = 1.113012
Epoch 10
Loss = 2.5940e-03, PNorm = 50.6733, GNorm = 2.3117, lr_0 = 4.8539e-04
Loss = 2.2443e-03, PNorm = 50.6855, GNorm = 1.1053, lr_0 = 4.6483e-04
Validation rmse = 1.156840
Epoch 11
Loss = 2.4650e-03, PNorm = 50.6963, GNorm = 0.6361, lr_0 = 4.4322e-04
Loss = 2.2502e-03, PNorm = 50.7088, GNorm = 1.9667, lr_0 = 4.2444e-04
Validation rmse = 1.179876
Epoch 12
Loss = 1.8251e-03, PNorm = 50.7194, GNorm = 1.0825, lr_0 = 4.0646e-04
Loss = 2.0559e-03, PNorm = 50.7277, GNorm = 1.2939, lr_0 = 3.8925e-04
Validation rmse = 1.045524
Epoch 13
Loss = 1.6436e-03, PNorm = 50.7347, GNorm = 0.9079, lr_0 = 3.7276e-04
Loss = 1.8868e-03, PNorm = 50.7416, GNorm = 1.9309, lr_0 = 3.5697e-04
Validation rmse = 1.112901
Epoch 14
Loss = 2.0720e-03, PNorm = 50.7500, GNorm = 2.0446, lr_0 = 3.4037e-04
Loss = 1.7430e-03, PNorm = 50.7561, GNorm = 1.1415, lr_0 = 3.2596e-04
Validation rmse = 1.126900
Epoch 15
Loss = 1.4877e-03, PNorm = 50.7612, GNorm = 0.6813, lr_0 = 3.1215e-04
Loss = 1.8968e-03, PNorm = 50.7659, GNorm = 1.2562, lr_0 = 2.9893e-04
Validation rmse = 1.120338
Epoch 16
Loss = 1.8962e-03, PNorm = 50.7729, GNorm = 2.2442, lr_0 = 2.8503e-04
Loss = 1.6435e-03, PNorm = 50.7782, GNorm = 0.9352, lr_0 = 2.7295e-04
Validation rmse = 1.017731
Epoch 17
Loss = 1.6958e-03, PNorm = 50.7836, GNorm = 0.8204, lr_0 = 2.6139e-04
Loss = 1.8630e-03, PNorm = 50.7872, GNorm = 1.3447, lr_0 = 2.5032e-04
Validation rmse = 1.090349
Epoch 18
Loss = 1.4184e-03, PNorm = 50.7920, GNorm = 0.5796, lr_0 = 2.3972e-04
Loss = 1.9522e-03, PNorm = 50.7958, GNorm = 1.1524, lr_0 = 2.2956e-04
Validation rmse = 1.004824
Epoch 19
Loss = 1.6577e-03, PNorm = 50.7993, GNorm = 1.6612, lr_0 = 2.1889e-04
Loss = 1.7489e-03, PNorm = 50.8038, GNorm = 1.0658, lr_0 = 2.0962e-04
Validation rmse = 1.234077
Epoch 20
Loss = 1.8725e-03, PNorm = 50.8087, GNorm = 1.1205, lr_0 = 2.0074e-04
Loss = 1.4784e-03, PNorm = 50.8116, GNorm = 1.2093, lr_0 = 1.9224e-04
Validation rmse = 1.105074
Epoch 21
Loss = 1.3962e-03, PNorm = 50.8151, GNorm = 2.0041, lr_0 = 1.8409e-04
Loss = 1.7047e-03, PNorm = 50.8177, GNorm = 0.9563, lr_0 = 1.7630e-04
Validation rmse = 1.012936
Epoch 22
Loss = 1.6304e-03, PNorm = 50.8210, GNorm = 2.0461, lr_0 = 1.6810e-04
Loss = 1.5589e-03, PNorm = 50.8237, GNorm = 2.0092, lr_0 = 1.6098e-04
Validation rmse = 1.013612
Epoch 23
Loss = 1.3810e-03, PNorm = 50.8255, GNorm = 0.7207, lr_0 = 1.5416e-04
Loss = 1.6499e-03, PNorm = 50.8285, GNorm = 0.7995, lr_0 = 1.4763e-04
Loss = 2.8246e-03, PNorm = 50.8288, GNorm = 1.2957, lr_0 = 1.4699e-04
Validation rmse = 1.038817
Epoch 24
Loss = 1.5535e-03, PNorm = 50.8313, GNorm = 0.8155, lr_0 = 1.4077e-04
Loss = 1.5499e-03, PNorm = 50.8329, GNorm = 1.8960, lr_0 = 1.3480e-04
Validation rmse = 1.007841
Epoch 25
Loss = 1.4797e-03, PNorm = 50.8350, GNorm = 1.0766, lr_0 = 1.2909e-04
Loss = 1.4548e-03, PNorm = 50.8371, GNorm = 0.9368, lr_0 = 1.2362e-04
Validation rmse = 1.006800
Epoch 26
Loss = 1.4254e-03, PNorm = 50.8391, GNorm = 0.7498, lr_0 = 1.1839e-04
Validation rmse = 0.986348
Epoch 27
Loss = 1.0724e-03, PNorm = 50.8415, GNorm = 0.8464, lr_0 = 1.1288e-04
Loss = 1.4144e-03, PNorm = 50.8422, GNorm = 2.3310, lr_0 = 1.0810e-04
Validation rmse = 1.002976
Epoch 28
Loss = 1.3226e-03, PNorm = 50.8437, GNorm = 0.9547, lr_0 = 1.0352e-04
Loss = 1.3629e-03, PNorm = 50.8454, GNorm = 0.6931, lr_0 = 1.0000e-04
Validation rmse = 0.956534
Epoch 29
Loss = 1.4086e-03, PNorm = 50.8475, GNorm = 1.1691, lr_0 = 1.0000e-04
Loss = 1.2947e-03, PNorm = 50.8491, GNorm = 0.6734, lr_0 = 1.0000e-04
Validation rmse = 0.987808
Model 0 best validation rmse = 0.956534 on epoch 28
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.341752
Ensemble test rmse = 1.341752
10-fold cross validation
	Seed 0 ==> test rmse = 0.983831
	Seed 1 ==> test rmse = 1.128564
	Seed 2 ==> test rmse = 1.092923
	Seed 3 ==> test rmse = 1.122548
	Seed 4 ==> test rmse = 1.203772
	Seed 5 ==> test rmse = 1.158542
	Seed 6 ==> test rmse = 1.029708
	Seed 7 ==> test rmse = 1.037311
	Seed 8 ==> test rmse = 1.149209
	Seed 9 ==> test rmse = 1.341752
Overall test rmse = 1.124816 +/- 0.096251
Elapsed time = 0:07:06
Fold 0
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 1700,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1700,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.25_ffn_num_layers_1_hidden_size_1700/fold_0',
 'save_smiles_splits': True,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total scaffolds = 195 | train scaffolds = 91 | val scaffolds = 66 | test scaffolds = 38
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1700, bias=False)
      (W_h): Linear(in_features=1700, out_features=1700, bias=False)
      (W_o): Linear(in_features=1833, out_features=1700, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=1704, out_features=1, bias=True)
  )
)
Number of parameters = 6,259,405
Moving model to cuda
Epoch 0
Loss = 1.5598e-02, PNorm = 61.1156, GNorm = 6.1181, lr_0 = 3.6053e-04
Validation rmse = 2.901872
Epoch 1
Loss = 9.7448e-03, PNorm = 61.1898, GNorm = 9.6221, lr_0 = 6.2105e-04
Loss = 9.1499e-03, PNorm = 61.2839, GNorm = 4.1034, lr_0 = 8.5789e-04
Validation rmse = 1.668078
Epoch 2
Loss = 4.3996e-03, PNorm = 61.3888, GNorm = 1.0874, lr_0 = 9.8284e-04
Loss = 4.1168e-03, PNorm = 61.4645, GNorm = 1.3621, lr_0 = 9.4120e-04
Validation rmse = 2.227030
Epoch 3
Loss = 6.1255e-03, PNorm = 61.5250, GNorm = 2.9804, lr_0 = 8.9744e-04
Loss = 3.9613e-03, PNorm = 61.5799, GNorm = 1.7172, lr_0 = 8.5943e-04
Validation rmse = 1.268100
Epoch 4
Loss = 4.5687e-03, PNorm = 61.6188, GNorm = 1.8085, lr_0 = 8.2303e-04
Loss = 2.7957e-03, PNorm = 61.6560, GNorm = 3.8155, lr_0 = 7.8816e-04
Validation rmse = 1.354030
Epoch 5
Loss = 2.5748e-03, PNorm = 61.6874, GNorm = 2.2869, lr_0 = 7.5478e-04
Loss = 2.3977e-03, PNorm = 61.7150, GNorm = 1.4402, lr_0 = 7.2281e-04
Validation rmse = 1.392214
Epoch 6
Loss = 2.0241e-03, PNorm = 61.7490, GNorm = 1.0829, lr_0 = 6.8920e-04
Loss = 2.0919e-03, PNorm = 61.7723, GNorm = 1.0914, lr_0 = 6.6001e-04
Validation rmse = 1.431178
Epoch 7
Loss = 3.0227e-03, PNorm = 61.7971, GNorm = 1.6132, lr_0 = 6.3205e-04
Loss = 2.3067e-03, PNorm = 61.8241, GNorm = 0.8259, lr_0 = 6.0528e-04
Validation rmse = 1.051502
Epoch 8
Loss = 2.1582e-03, PNorm = 61.8536, GNorm = 1.4744, lr_0 = 5.7714e-04
Loss = 1.8305e-03, PNorm = 61.8774, GNorm = 0.6211, lr_0 = 5.5269e-04
Validation rmse = 1.194062
Epoch 9
Loss = 1.9800e-03, PNorm = 61.8971, GNorm = 3.1675, lr_0 = 5.2928e-04
Loss = 1.8642e-03, PNorm = 61.9179, GNorm = 0.7345, lr_0 = 5.0686e-04
Validation rmse = 1.155650
Epoch 10
Loss = 1.7630e-03, PNorm = 61.9311, GNorm = 2.6935, lr_0 = 4.8539e-04
Loss = 1.8293e-03, PNorm = 61.9482, GNorm = 0.8294, lr_0 = 4.6483e-04
Validation rmse = 1.065741
Epoch 11
Loss = 1.2758e-03, PNorm = 61.9650, GNorm = 0.6690, lr_0 = 4.4322e-04
Loss = 1.5432e-03, PNorm = 61.9786, GNorm = 1.5990, lr_0 = 4.2444e-04
Validation rmse = 1.054993
Epoch 12
Loss = 1.6103e-03, PNorm = 61.9900, GNorm = 0.6809, lr_0 = 4.0646e-04
Loss = 1.3796e-03, PNorm = 62.0001, GNorm = 0.3663, lr_0 = 3.8925e-04
Validation rmse = 1.032436
Epoch 13
Loss = 1.2382e-03, PNorm = 62.0124, GNorm = 0.5762, lr_0 = 3.7276e-04
Loss = 2.0774e-03, PNorm = 62.0247, GNorm = 1.7356, lr_0 = 3.5697e-04
Validation rmse = 1.170434
Epoch 14
Loss = 1.5307e-03, PNorm = 62.0412, GNorm = 1.3714, lr_0 = 3.4037e-04
Loss = 1.5495e-03, PNorm = 62.0566, GNorm = 0.8711, lr_0 = 3.2596e-04
Validation rmse = 1.046663
Epoch 15
Loss = 1.4624e-03, PNorm = 62.0654, GNorm = 0.5231, lr_0 = 3.1215e-04
Loss = 1.3887e-03, PNorm = 62.0764, GNorm = 2.0721, lr_0 = 2.9893e-04
Validation rmse = 1.128195
Epoch 16
Loss = 1.3166e-03, PNorm = 62.0856, GNorm = 1.2711, lr_0 = 2.8503e-04
Loss = 1.1936e-03, PNorm = 62.0943, GNorm = 0.5151, lr_0 = 2.7295e-04
Validation rmse = 1.036604
Epoch 17
Loss = 1.1377e-03, PNorm = 62.1035, GNorm = 1.6474, lr_0 = 2.6139e-04
Loss = 1.3451e-03, PNorm = 62.1140, GNorm = 1.2193, lr_0 = 2.5032e-04
Validation rmse = 1.009389
Epoch 18
Loss = 8.5694e-04, PNorm = 62.1230, GNorm = 0.4145, lr_0 = 2.3972e-04
Loss = 1.1770e-03, PNorm = 62.1314, GNorm = 0.7761, lr_0 = 2.2956e-04
Validation rmse = 1.024317
Epoch 19
Loss = 1.1090e-03, PNorm = 62.1403, GNorm = 1.1411, lr_0 = 2.1889e-04
Loss = 1.3716e-03, PNorm = 62.1465, GNorm = 0.4552, lr_0 = 2.0962e-04
Validation rmse = 1.114666
Epoch 20
Loss = 1.2184e-03, PNorm = 62.1532, GNorm = 0.4889, lr_0 = 2.0074e-04
Loss = 1.1755e-03, PNorm = 62.1606, GNorm = 0.7029, lr_0 = 1.9224e-04
Validation rmse = 1.045446
Epoch 21
Loss = 1.1642e-03, PNorm = 62.1670, GNorm = 1.1067, lr_0 = 1.8409e-04
Loss = 1.2652e-03, PNorm = 62.1744, GNorm = 0.5962, lr_0 = 1.7630e-04
Validation rmse = 1.059083
Epoch 22
Loss = 8.9835e-04, PNorm = 62.1827, GNorm = 0.8769, lr_0 = 1.6810e-04
Loss = 1.2978e-03, PNorm = 62.1881, GNorm = 0.8592, lr_0 = 1.6098e-04
Validation rmse = 0.992870
Epoch 23
Loss = 1.0916e-03, PNorm = 62.1934, GNorm = 0.7704, lr_0 = 1.5416e-04
Loss = 1.0626e-03, PNorm = 62.1999, GNorm = 0.6688, lr_0 = 1.4763e-04
Loss = 1.6593e-03, PNorm = 62.2005, GNorm = 0.9419, lr_0 = 1.4699e-04
Validation rmse = 1.053550
Epoch 24
Loss = 1.1975e-03, PNorm = 62.2033, GNorm = 1.0964, lr_0 = 1.4077e-04
Loss = 1.0709e-03, PNorm = 62.2095, GNorm = 0.8690, lr_0 = 1.3480e-04
Validation rmse = 1.028225
Epoch 25
Loss = 1.0983e-03, PNorm = 62.2146, GNorm = 1.3183, lr_0 = 1.2909e-04
Loss = 1.0127e-03, PNorm = 62.2194, GNorm = 0.6257, lr_0 = 1.2362e-04
Validation rmse = 1.053773
Epoch 26
Loss = 1.0070e-03, PNorm = 62.2240, GNorm = 0.9877, lr_0 = 1.1839e-04
Validation rmse = 1.006144
Epoch 27
Loss = 5.6275e-04, PNorm = 62.2278, GNorm = 0.6391, lr_0 = 1.1288e-04
Loss = 1.0808e-03, PNorm = 62.2312, GNorm = 0.9134, lr_0 = 1.0810e-04
Validation rmse = 1.020716
Epoch 28
Loss = 1.4784e-03, PNorm = 62.2353, GNorm = 0.5650, lr_0 = 1.0352e-04
Loss = 9.4832e-04, PNorm = 62.2404, GNorm = 0.4031, lr_0 = 1.0000e-04
Validation rmse = 0.993485
Epoch 29
Loss = 1.0141e-03, PNorm = 62.2445, GNorm = 0.8515, lr_0 = 1.0000e-04
Loss = 1.1009e-03, PNorm = 62.2495, GNorm = 0.5100, lr_0 = 1.0000e-04
Validation rmse = 1.067897
Model 0 best validation rmse = 0.992870 on epoch 22
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 0.868482
Ensemble test rmse = 0.868482
Fold 1
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1700,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1700,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.25_ffn_num_layers_1_hidden_size_1700/fold_1',
 'save_smiles_splits': True,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total scaffolds = 195 | train scaffolds = 76 | val scaffolds = 60 | test scaffolds = 59
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1700, bias=False)
      (W_h): Linear(in_features=1700, out_features=1700, bias=False)
      (W_o): Linear(in_features=1833, out_features=1700, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=1704, out_features=1, bias=True)
  )
)
Number of parameters = 6,259,405
Moving model to cuda
Epoch 0
Loss = 1.8614e-02, PNorm = 61.1125, GNorm = 2.9580, lr_0 = 3.6053e-04
Validation rmse = 1.899442
Epoch 1
Loss = 7.4805e-03, PNorm = 61.1863, GNorm = 6.1232, lr_0 = 6.2105e-04
Loss = 7.4687e-03, PNorm = 61.2761, GNorm = 4.2753, lr_0 = 8.5789e-04
Validation rmse = 1.456368
Epoch 2
Loss = 5.6957e-03, PNorm = 61.3793, GNorm = 1.5017, lr_0 = 9.8284e-04
Loss = 4.5971e-03, PNorm = 61.4556, GNorm = 3.2815, lr_0 = 9.4120e-04
Validation rmse = 1.373682
Epoch 3
Loss = 4.5063e-03, PNorm = 61.5192, GNorm = 1.4321, lr_0 = 8.9744e-04
Loss = 3.8615e-03, PNorm = 61.5706, GNorm = 1.3568, lr_0 = 8.5943e-04
Validation rmse = 1.362413
Epoch 4
Loss = 2.5022e-03, PNorm = 61.6135, GNorm = 0.7802, lr_0 = 8.2303e-04
Loss = 2.6494e-03, PNorm = 61.6538, GNorm = 2.8272, lr_0 = 7.8816e-04
Validation rmse = 1.334634
Epoch 5
Loss = 2.3562e-03, PNorm = 61.6806, GNorm = 2.9935, lr_0 = 7.5478e-04
Loss = 2.9050e-03, PNorm = 61.7117, GNorm = 1.7390, lr_0 = 7.2281e-04
Validation rmse = 1.238887
Epoch 6
Loss = 2.1549e-03, PNorm = 61.7422, GNorm = 1.3128, lr_0 = 6.8920e-04
Loss = 2.2091e-03, PNorm = 61.7716, GNorm = 1.3830, lr_0 = 6.6001e-04
Validation rmse = 1.296149
Epoch 7
Loss = 1.8559e-03, PNorm = 61.7958, GNorm = 1.2462, lr_0 = 6.3205e-04
Loss = 2.3309e-03, PNorm = 61.8181, GNorm = 1.4267, lr_0 = 6.0528e-04
Validation rmse = 1.106923
Epoch 8
Loss = 1.7546e-03, PNorm = 61.8432, GNorm = 0.7065, lr_0 = 5.7714e-04
Loss = 1.7164e-03, PNorm = 61.8576, GNorm = 2.7659, lr_0 = 5.5269e-04
Validation rmse = 1.227098
Epoch 9
Loss = 2.0248e-03, PNorm = 61.8730, GNorm = 1.9752, lr_0 = 5.2928e-04
Loss = 1.9839e-03, PNorm = 61.8923, GNorm = 1.8568, lr_0 = 5.0686e-04
Validation rmse = 1.241090
Epoch 10
Loss = 1.6256e-03, PNorm = 61.9140, GNorm = 1.7487, lr_0 = 4.8539e-04
Loss = 1.4618e-03, PNorm = 61.9304, GNorm = 0.8455, lr_0 = 4.6483e-04
Validation rmse = 1.051678
Epoch 11
Loss = 1.8318e-03, PNorm = 61.9443, GNorm = 2.1722, lr_0 = 4.4322e-04
Loss = 1.5804e-03, PNorm = 61.9548, GNorm = 2.3176, lr_0 = 4.2444e-04
Validation rmse = 1.095241
Epoch 12
Loss = 1.1834e-03, PNorm = 61.9697, GNorm = 0.6452, lr_0 = 4.0646e-04
Loss = 1.5637e-03, PNorm = 61.9795, GNorm = 0.7803, lr_0 = 3.8925e-04
Validation rmse = 1.192484
Epoch 13
Loss = 1.9868e-03, PNorm = 61.9908, GNorm = 2.4049, lr_0 = 3.7276e-04
Loss = 1.7034e-03, PNorm = 62.0069, GNorm = 0.5798, lr_0 = 3.5697e-04
Validation rmse = 1.038600
Epoch 14
Loss = 1.4913e-03, PNorm = 62.0221, GNorm = 1.9210, lr_0 = 3.4037e-04
Loss = 1.7459e-03, PNorm = 62.0364, GNorm = 0.7909, lr_0 = 3.2596e-04
Validation rmse = 1.085420
Epoch 15
Loss = 1.7862e-03, PNorm = 62.0460, GNorm = 1.4729, lr_0 = 3.1215e-04
Loss = 1.3081e-03, PNorm = 62.0599, GNorm = 0.3575, lr_0 = 2.9893e-04
Validation rmse = 1.035463
Epoch 16
Loss = 1.0918e-03, PNorm = 62.0697, GNorm = 1.0097, lr_0 = 2.8503e-04
Loss = 1.4794e-03, PNorm = 62.0774, GNorm = 1.5696, lr_0 = 2.7295e-04
Validation rmse = 1.050967
Epoch 17
Loss = 1.1865e-03, PNorm = 62.0865, GNorm = 1.7621, lr_0 = 2.6139e-04
Loss = 1.2655e-03, PNorm = 62.0945, GNorm = 0.8000, lr_0 = 2.5032e-04
Validation rmse = 1.028729
Epoch 18
Loss = 1.2054e-03, PNorm = 62.1023, GNorm = 0.6092, lr_0 = 2.3972e-04
Loss = 1.2470e-03, PNorm = 62.1099, GNorm = 1.7614, lr_0 = 2.2956e-04
Validation rmse = 1.025385
Epoch 19
Loss = 9.3266e-04, PNorm = 62.1182, GNorm = 1.0170, lr_0 = 2.1889e-04
Loss = 1.1729e-03, PNorm = 62.1251, GNorm = 0.4737, lr_0 = 2.0962e-04
Validation rmse = 1.005581
Epoch 20
Loss = 9.4106e-04, PNorm = 62.1318, GNorm = 0.5131, lr_0 = 2.0074e-04
Loss = 1.2193e-03, PNorm = 62.1390, GNorm = 0.5649, lr_0 = 1.9224e-04
Validation rmse = 0.998998
Epoch 21
Loss = 9.2209e-04, PNorm = 62.1442, GNorm = 0.9866, lr_0 = 1.8409e-04
Loss = 1.2875e-03, PNorm = 62.1489, GNorm = 0.7588, lr_0 = 1.7630e-04
Validation rmse = 0.993166
Epoch 22
Loss = 1.2103e-03, PNorm = 62.1556, GNorm = 1.5398, lr_0 = 1.6810e-04
Loss = 1.0225e-03, PNorm = 62.1608, GNorm = 1.3897, lr_0 = 1.6098e-04
Validation rmse = 1.043110
Epoch 23
Loss = 1.1618e-03, PNorm = 62.1668, GNorm = 0.6393, lr_0 = 1.5416e-04
Loss = 1.1070e-03, PNorm = 62.1711, GNorm = 0.9780, lr_0 = 1.4763e-04
Loss = 1.2031e-03, PNorm = 62.1716, GNorm = 0.8422, lr_0 = 1.4699e-04
Validation rmse = 1.011035
Epoch 24
Loss = 1.2164e-03, PNorm = 62.1775, GNorm = 0.5823, lr_0 = 1.4077e-04
Loss = 9.9017e-04, PNorm = 62.1826, GNorm = 0.5815, lr_0 = 1.3480e-04
Validation rmse = 1.037618
Epoch 25
Loss = 9.0375e-04, PNorm = 62.1870, GNorm = 0.4248, lr_0 = 1.2909e-04
Loss = 1.1155e-03, PNorm = 62.1910, GNorm = 1.4373, lr_0 = 1.2362e-04
Validation rmse = 1.021459
Epoch 26
Loss = 1.0797e-03, PNorm = 62.1958, GNorm = 0.8096, lr_0 = 1.1839e-04
Validation rmse = 1.044196
Epoch 27
Loss = 1.1402e-03, PNorm = 62.1996, GNorm = 1.3568, lr_0 = 1.1288e-04
Loss = 9.5227e-04, PNorm = 62.2037, GNorm = 0.6305, lr_0 = 1.0810e-04
Validation rmse = 1.030948
Epoch 28
Loss = 5.8167e-04, PNorm = 62.2072, GNorm = 0.4056, lr_0 = 1.0352e-04
Loss = 9.8310e-04, PNorm = 62.2116, GNorm = 0.5259, lr_0 = 1.0000e-04
Validation rmse = 1.053572
Epoch 29
Loss = 6.1790e-04, PNorm = 62.2146, GNorm = 0.3789, lr_0 = 1.0000e-04
Loss = 9.4237e-04, PNorm = 62.2199, GNorm = 0.9293, lr_0 = 1.0000e-04
Validation rmse = 1.021707
Model 0 best validation rmse = 0.993166 on epoch 21
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.004174
Ensemble test rmse = 1.004174
Fold 2
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1700,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1700,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.25_ffn_num_layers_1_hidden_size_1700/fold_2',
 'save_smiles_splits': True,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total scaffolds = 195 | train scaffolds = 55 | val scaffolds = 64 | test scaffolds = 76
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1700, bias=False)
      (W_h): Linear(in_features=1700, out_features=1700, bias=False)
      (W_o): Linear(in_features=1833, out_features=1700, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=1704, out_features=1, bias=True)
  )
)
Number of parameters = 6,259,405
Moving model to cuda
Epoch 0
Loss = 2.5304e-02, PNorm = 61.1129, GNorm = 9.5281, lr_0 = 3.6053e-04
Validation rmse = 1.595446
Epoch 1
Loss = 8.6875e-03, PNorm = 61.1862, GNorm = 1.8750, lr_0 = 6.2105e-04
Loss = 9.9504e-03, PNorm = 61.2932, GNorm = 3.4015, lr_0 = 8.5789e-04
Validation rmse = 1.623304
Epoch 2
Loss = 8.0132e-03, PNorm = 61.3961, GNorm = 3.1724, lr_0 = 9.8284e-04
Loss = 5.7724e-03, PNorm = 61.4892, GNorm = 3.9811, lr_0 = 9.4120e-04
Validation rmse = 1.560656
Epoch 3
Loss = 5.0880e-03, PNorm = 61.5520, GNorm = 2.3346, lr_0 = 8.9744e-04
Loss = 4.1826e-03, PNorm = 61.6002, GNorm = 2.9000, lr_0 = 8.5943e-04
Validation rmse = 1.485300
Epoch 4
Loss = 3.3101e-03, PNorm = 61.6366, GNorm = 2.3338, lr_0 = 8.2303e-04
Loss = 3.5728e-03, PNorm = 61.6810, GNorm = 3.9863, lr_0 = 7.8816e-04
Validation rmse = 1.363665
Epoch 5
Loss = 2.0221e-03, PNorm = 61.7196, GNorm = 1.3402, lr_0 = 7.5478e-04
Loss = 2.9132e-03, PNorm = 61.7541, GNorm = 0.6678, lr_0 = 7.2281e-04
Validation rmse = 1.234725
Epoch 6
Loss = 1.9248e-03, PNorm = 61.7944, GNorm = 0.5082, lr_0 = 6.8920e-04
Loss = 2.4313e-03, PNorm = 61.8239, GNorm = 0.9594, lr_0 = 6.6001e-04
Validation rmse = 1.287989
Epoch 7
Loss = 3.3635e-03, PNorm = 61.8531, GNorm = 4.5644, lr_0 = 6.3205e-04
Loss = 1.8765e-03, PNorm = 61.8830, GNorm = 0.7392, lr_0 = 6.0528e-04
Validation rmse = 1.361113
Epoch 8
Loss = 2.6654e-03, PNorm = 61.9133, GNorm = 1.9342, lr_0 = 5.7714e-04
Loss = 2.1405e-03, PNorm = 61.9408, GNorm = 0.5153, lr_0 = 5.5269e-04
Validation rmse = 1.231682
Epoch 9
Loss = 1.5973e-03, PNorm = 61.9591, GNorm = 0.7038, lr_0 = 5.2928e-04
Loss = 1.7114e-03, PNorm = 61.9821, GNorm = 0.6760, lr_0 = 5.0686e-04
Validation rmse = 1.194691
Epoch 10
Loss = 1.7693e-03, PNorm = 61.9982, GNorm = 0.7693, lr_0 = 4.8539e-04
Loss = 1.5544e-03, PNorm = 62.0152, GNorm = 0.4068, lr_0 = 4.6483e-04
Validation rmse = 1.191482
Epoch 11
Loss = 1.9815e-03, PNorm = 62.0365, GNorm = 0.4156, lr_0 = 4.4322e-04
Loss = 1.9930e-03, PNorm = 62.0562, GNorm = 1.6160, lr_0 = 4.2444e-04
Validation rmse = 1.134291
Epoch 12
Loss = 1.7627e-03, PNorm = 62.0747, GNorm = 0.7330, lr_0 = 4.0646e-04
Loss = 1.7345e-03, PNorm = 62.0891, GNorm = 1.2710, lr_0 = 3.8925e-04
Validation rmse = 1.194624
Epoch 13
Loss = 1.9942e-03, PNorm = 62.1026, GNorm = 0.9948, lr_0 = 3.7276e-04
Loss = 1.5633e-03, PNorm = 62.1154, GNorm = 0.6296, lr_0 = 3.5697e-04
Validation rmse = 1.184819
Epoch 14
Loss = 1.9282e-03, PNorm = 62.1305, GNorm = 1.3721, lr_0 = 3.4037e-04
Loss = 1.4512e-03, PNorm = 62.1431, GNorm = 0.5741, lr_0 = 3.2596e-04
Validation rmse = 1.218596
Epoch 15
Loss = 1.4055e-03, PNorm = 62.1553, GNorm = 1.3940, lr_0 = 3.1215e-04
Loss = 1.4238e-03, PNorm = 62.1654, GNorm = 0.9741, lr_0 = 2.9893e-04
Validation rmse = 1.166415
Epoch 16
Loss = 1.3581e-03, PNorm = 62.1766, GNorm = 1.1631, lr_0 = 2.8503e-04
Loss = 1.4331e-03, PNorm = 62.1842, GNorm = 1.8304, lr_0 = 2.7295e-04
Validation rmse = 1.129639
Epoch 17
Loss = 1.3440e-03, PNorm = 62.1941, GNorm = 1.9647, lr_0 = 2.6139e-04
Loss = 1.4936e-03, PNorm = 62.2028, GNorm = 1.5012, lr_0 = 2.5032e-04
Validation rmse = 1.226110
Epoch 18
Loss = 1.4171e-03, PNorm = 62.2137, GNorm = 0.5210, lr_0 = 2.3972e-04
Loss = 1.3445e-03, PNorm = 62.2220, GNorm = 0.5485, lr_0 = 2.2956e-04
Validation rmse = 1.142588
Epoch 19
Loss = 1.6229e-03, PNorm = 62.2311, GNorm = 1.5873, lr_0 = 2.1889e-04
Loss = 1.2776e-03, PNorm = 62.2413, GNorm = 0.8991, lr_0 = 2.0962e-04
Validation rmse = 1.111057
Epoch 20
Loss = 1.1468e-03, PNorm = 62.2458, GNorm = 0.7633, lr_0 = 2.0074e-04
Loss = 1.2458e-03, PNorm = 62.2541, GNorm = 1.1658, lr_0 = 1.9224e-04
Validation rmse = 1.126225
Epoch 21
Loss = 1.2910e-03, PNorm = 62.2596, GNorm = 1.2488, lr_0 = 1.8409e-04
Loss = 1.2633e-03, PNorm = 62.2658, GNorm = 0.9046, lr_0 = 1.7630e-04
Validation rmse = 1.186041
Epoch 22
Loss = 1.2864e-03, PNorm = 62.2730, GNorm = 0.8702, lr_0 = 1.6810e-04
Loss = 1.0582e-03, PNorm = 62.2794, GNorm = 0.5098, lr_0 = 1.6098e-04
Validation rmse = 1.110442
Epoch 23
Loss = 9.6911e-04, PNorm = 62.2858, GNorm = 1.5215, lr_0 = 1.5416e-04
Loss = 1.3179e-03, PNorm = 62.2916, GNorm = 0.5504, lr_0 = 1.4763e-04
Loss = 3.3773e-03, PNorm = 62.2919, GNorm = 1.5485, lr_0 = 1.4699e-04
Validation rmse = 1.113195
Epoch 24
Loss = 1.0305e-03, PNorm = 62.2972, GNorm = 2.0175, lr_0 = 1.4077e-04
Loss = 1.2980e-03, PNorm = 62.3014, GNorm = 0.6223, lr_0 = 1.3480e-04
Validation rmse = 1.157017
Epoch 25
Loss = 1.3215e-03, PNorm = 62.3070, GNorm = 0.4454, lr_0 = 1.2909e-04
Loss = 9.9256e-04, PNorm = 62.3117, GNorm = 1.0562, lr_0 = 1.2362e-04
Validation rmse = 1.100771
Epoch 26
Loss = 1.2486e-03, PNorm = 62.3170, GNorm = 0.6370, lr_0 = 1.1839e-04
Validation rmse = 1.122500
Epoch 27
Loss = 6.5631e-04, PNorm = 62.3214, GNorm = 0.3281, lr_0 = 1.1288e-04
Loss = 1.0728e-03, PNorm = 62.3255, GNorm = 0.9336, lr_0 = 1.0810e-04
Validation rmse = 1.097640
Epoch 28
Loss = 1.1547e-03, PNorm = 62.3295, GNorm = 0.6371, lr_0 = 1.0352e-04
Loss = 9.6299e-04, PNorm = 62.3338, GNorm = 0.6873, lr_0 = 1.0000e-04
Validation rmse = 1.132196
Epoch 29
Loss = 1.1991e-03, PNorm = 62.3384, GNorm = 1.0211, lr_0 = 1.0000e-04
Loss = 1.1727e-03, PNorm = 62.3417, GNorm = 1.1629, lr_0 = 1.0000e-04
Validation rmse = 1.107548
Model 0 best validation rmse = 1.097640 on epoch 27
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.067208
Ensemble test rmse = 1.067208
Fold 3
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1700,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1700,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.25_ffn_num_layers_1_hidden_size_1700/fold_3',
 'save_smiles_splits': True,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total scaffolds = 195 | train scaffolds = 80 | val scaffolds = 54 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1700, bias=False)
      (W_h): Linear(in_features=1700, out_features=1700, bias=False)
      (W_o): Linear(in_features=1833, out_features=1700, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=1704, out_features=1, bias=True)
  )
)
Number of parameters = 6,259,405
Moving model to cuda
Epoch 0
Loss = 2.4461e-02, PNorm = 61.1143, GNorm = 4.3285, lr_0 = 3.6053e-04
Validation rmse = 1.758214
Epoch 1
Loss = 7.6921e-03, PNorm = 61.1914, GNorm = 4.9907, lr_0 = 6.2105e-04
Loss = 8.3554e-03, PNorm = 61.2802, GNorm = 2.8248, lr_0 = 8.5789e-04
Validation rmse = 1.591539
Epoch 2
Loss = 4.4026e-03, PNorm = 61.3796, GNorm = 2.9023, lr_0 = 9.8284e-04
Loss = 5.4482e-03, PNorm = 61.4558, GNorm = 4.2742, lr_0 = 9.4120e-04
Validation rmse = 1.460024
Epoch 3
Loss = 4.0442e-03, PNorm = 61.5188, GNorm = 1.0190, lr_0 = 8.9744e-04
Loss = 3.1497e-03, PNorm = 61.5604, GNorm = 2.1637, lr_0 = 8.5943e-04
Validation rmse = 1.315168
Epoch 4
Loss = 2.0978e-03, PNorm = 61.5970, GNorm = 1.0555, lr_0 = 8.2303e-04
Loss = 3.1039e-03, PNorm = 61.6324, GNorm = 1.6319, lr_0 = 7.8816e-04
Validation rmse = 1.273233
Epoch 5
Loss = 2.0373e-03, PNorm = 61.6643, GNorm = 0.7940, lr_0 = 7.5478e-04
Loss = 2.2332e-03, PNorm = 61.6920, GNorm = 1.6566, lr_0 = 7.2281e-04
Validation rmse = 1.165474
Epoch 6
Loss = 2.1861e-03, PNorm = 61.7222, GNorm = 0.8194, lr_0 = 6.8920e-04
Loss = 1.9920e-03, PNorm = 61.7473, GNorm = 1.3082, lr_0 = 6.6001e-04
Validation rmse = 1.134174
Epoch 7
Loss = 1.5131e-03, PNorm = 61.7714, GNorm = 0.5335, lr_0 = 6.3205e-04
Loss = 1.6257e-03, PNorm = 61.7926, GNorm = 0.6442, lr_0 = 6.0528e-04
Validation rmse = 1.121004
Epoch 8
Loss = 1.9394e-03, PNorm = 61.8158, GNorm = 1.0202, lr_0 = 5.7714e-04
Loss = 1.4272e-03, PNorm = 61.8386, GNorm = 1.3592, lr_0 = 5.5269e-04
Validation rmse = 1.273402
Epoch 9
Loss = 1.9294e-03, PNorm = 61.8552, GNorm = 2.4317, lr_0 = 5.2928e-04
Loss = 1.5887e-03, PNorm = 61.8754, GNorm = 0.8314, lr_0 = 5.0686e-04
Validation rmse = 1.191780
Epoch 10
Loss = 1.9260e-03, PNorm = 61.8914, GNorm = 0.4641, lr_0 = 4.8539e-04
Loss = 1.6257e-03, PNorm = 61.9066, GNorm = 1.3318, lr_0 = 4.6483e-04
Validation rmse = 1.085267
Epoch 11
Loss = 1.0603e-03, PNorm = 61.9255, GNorm = 1.7583, lr_0 = 4.4322e-04
Loss = 1.5368e-03, PNorm = 61.9386, GNorm = 1.6923, lr_0 = 4.2444e-04
Validation rmse = 1.182480
Epoch 12
Loss = 1.3835e-03, PNorm = 61.9538, GNorm = 0.5633, lr_0 = 4.0646e-04
Loss = 1.2232e-03, PNorm = 61.9655, GNorm = 0.9114, lr_0 = 3.8925e-04
Validation rmse = 1.105603
Epoch 13
Loss = 1.2333e-03, PNorm = 61.9763, GNorm = 0.9286, lr_0 = 3.7276e-04
Loss = 1.2593e-03, PNorm = 61.9853, GNorm = 1.2123, lr_0 = 3.5697e-04
Validation rmse = 1.108657
Epoch 14
Loss = 1.2137e-03, PNorm = 61.9965, GNorm = 2.0958, lr_0 = 3.4037e-04
Loss = 1.1370e-03, PNorm = 62.0085, GNorm = 1.0054, lr_0 = 3.2596e-04
Validation rmse = 1.163144
Epoch 15
Loss = 1.3534e-03, PNorm = 62.0208, GNorm = 1.5002, lr_0 = 3.1215e-04
Loss = 1.2777e-03, PNorm = 62.0326, GNorm = 0.6943, lr_0 = 2.9893e-04
Validation rmse = 1.160219
Epoch 16
Loss = 1.2259e-03, PNorm = 62.0462, GNorm = 0.8806, lr_0 = 2.8503e-04
Loss = 1.2931e-03, PNorm = 62.0561, GNorm = 0.4876, lr_0 = 2.7295e-04
Validation rmse = 1.055035
Epoch 17
Loss = 8.8599e-04, PNorm = 62.0630, GNorm = 0.6820, lr_0 = 2.6139e-04
Loss = 1.1956e-03, PNorm = 62.0705, GNorm = 1.1945, lr_0 = 2.5032e-04
Validation rmse = 1.270859
Epoch 18
Loss = 1.1710e-03, PNorm = 62.0793, GNorm = 2.0915, lr_0 = 2.3972e-04
Loss = 1.0326e-03, PNorm = 62.0870, GNorm = 1.0377, lr_0 = 2.2956e-04
Validation rmse = 1.103372
Epoch 19
Loss = 1.0679e-03, PNorm = 62.0968, GNorm = 0.8766, lr_0 = 2.1889e-04
Loss = 1.1023e-03, PNorm = 62.1026, GNorm = 0.6335, lr_0 = 2.0962e-04
Validation rmse = 1.157680
Epoch 20
Loss = 1.0162e-03, PNorm = 62.1076, GNorm = 1.6186, lr_0 = 2.0074e-04
Loss = 1.1390e-03, PNorm = 62.1137, GNorm = 0.8397, lr_0 = 1.9224e-04
Validation rmse = 1.150705
Epoch 21
Loss = 8.7728e-04, PNorm = 62.1204, GNorm = 0.3194, lr_0 = 1.8409e-04
Loss = 1.0881e-03, PNorm = 62.1250, GNorm = 1.3950, lr_0 = 1.7630e-04
Validation rmse = 1.094905
Epoch 22
Loss = 1.0973e-03, PNorm = 62.1322, GNorm = 0.9026, lr_0 = 1.6810e-04
Loss = 9.1505e-04, PNorm = 62.1390, GNorm = 1.1351, lr_0 = 1.6098e-04
Validation rmse = 1.114602
Epoch 23
Loss = 8.9447e-04, PNorm = 62.1438, GNorm = 0.8446, lr_0 = 1.5416e-04
Loss = 8.3181e-04, PNorm = 62.1486, GNorm = 0.4782, lr_0 = 1.4763e-04
Loss = 1.4322e-03, PNorm = 62.1490, GNorm = 0.8081, lr_0 = 1.4699e-04
Validation rmse = 1.110906
Epoch 24
Loss = 8.9429e-04, PNorm = 62.1533, GNorm = 0.5486, lr_0 = 1.4077e-04
Loss = 8.9742e-04, PNorm = 62.1583, GNorm = 0.8497, lr_0 = 1.3480e-04
Validation rmse = 1.083001
Epoch 25
Loss = 8.7837e-04, PNorm = 62.1623, GNorm = 0.6048, lr_0 = 1.2909e-04
Loss = 9.2437e-04, PNorm = 62.1665, GNorm = 1.3666, lr_0 = 1.2362e-04
Validation rmse = 1.102506
Epoch 26
Loss = 9.2924e-04, PNorm = 62.1712, GNorm = 0.7435, lr_0 = 1.1839e-04
Validation rmse = 1.134958
Epoch 27
Loss = 1.4380e-03, PNorm = 62.1752, GNorm = 0.5354, lr_0 = 1.1288e-04
Loss = 8.3757e-04, PNorm = 62.1794, GNorm = 0.7031, lr_0 = 1.0810e-04
Validation rmse = 1.092736
Epoch 28
Loss = 6.0539e-04, PNorm = 62.1819, GNorm = 0.3800, lr_0 = 1.0352e-04
Loss = 8.5785e-04, PNorm = 62.1857, GNorm = 0.4635, lr_0 = 1.0000e-04
Validation rmse = 1.113895
Epoch 29
Loss = 9.6125e-04, PNorm = 62.1888, GNorm = 0.4376, lr_0 = 1.0000e-04
Loss = 8.1817e-04, PNorm = 62.1926, GNorm = 1.1031, lr_0 = 1.0000e-04
Validation rmse = 1.090643
Model 0 best validation rmse = 1.055035 on epoch 16
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.085986
Ensemble test rmse = 1.085986
Fold 4
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1700,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1700,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.25_ffn_num_layers_1_hidden_size_1700/fold_4',
 'save_smiles_splits': True,
 'seed': 4,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 4
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 49 | test scaffolds = 62
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1700, bias=False)
      (W_h): Linear(in_features=1700, out_features=1700, bias=False)
      (W_o): Linear(in_features=1833, out_features=1700, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=1704, out_features=1, bias=True)
  )
)
Number of parameters = 6,259,405
Moving model to cuda
Epoch 0
Loss = 2.0787e-02, PNorm = 61.1126, GNorm = 3.0529, lr_0 = 3.6053e-04
Validation rmse = 1.701211
Epoch 1
Loss = 1.2680e-02, PNorm = 61.1879, GNorm = 7.8294, lr_0 = 6.2105e-04
Loss = 7.4388e-03, PNorm = 61.2826, GNorm = 1.5275, lr_0 = 8.5789e-04
Validation rmse = 1.448766
Epoch 2
Loss = 5.9689e-03, PNorm = 61.3864, GNorm = 5.1690, lr_0 = 9.8284e-04
Loss = 6.7710e-03, PNorm = 61.4780, GNorm = 0.9945, lr_0 = 9.4120e-04
Validation rmse = 1.324892
Epoch 3
Loss = 4.4001e-03, PNorm = 61.5593, GNorm = 3.1192, lr_0 = 8.9744e-04
Loss = 4.0864e-03, PNorm = 61.6122, GNorm = 0.7211, lr_0 = 8.5943e-04
Validation rmse = 1.302241
Epoch 4
Loss = 4.2983e-03, PNorm = 61.6559, GNorm = 4.0460, lr_0 = 8.2303e-04
Loss = 2.6279e-03, PNorm = 61.6932, GNorm = 2.7167, lr_0 = 7.8816e-04
Validation rmse = 1.470171
Epoch 5
Loss = 3.0559e-03, PNorm = 61.7216, GNorm = 2.5808, lr_0 = 7.5478e-04
Loss = 2.8166e-03, PNorm = 61.7510, GNorm = 3.3605, lr_0 = 7.2281e-04
Validation rmse = 1.043185
Epoch 6
Loss = 1.8464e-03, PNorm = 61.7839, GNorm = 1.5209, lr_0 = 6.8920e-04
Loss = 2.0900e-03, PNorm = 61.8030, GNorm = 1.5017, lr_0 = 6.6001e-04
Validation rmse = 1.013807
Epoch 7
Loss = 1.4204e-03, PNorm = 61.8222, GNorm = 1.3593, lr_0 = 6.3205e-04
Loss = 2.4105e-03, PNorm = 61.8410, GNorm = 0.4123, lr_0 = 6.0528e-04
Validation rmse = 1.351380
Epoch 8
Loss = 2.0452e-03, PNorm = 61.8592, GNorm = 0.8088, lr_0 = 5.7714e-04
Loss = 1.8141e-03, PNorm = 61.8754, GNorm = 2.2404, lr_0 = 5.5269e-04
Validation rmse = 1.131949
Epoch 9
Loss = 1.4998e-03, PNorm = 61.8922, GNorm = 1.5305, lr_0 = 5.2928e-04
Loss = 1.9750e-03, PNorm = 61.9083, GNorm = 0.5498, lr_0 = 5.0686e-04
Validation rmse = 1.066042
Epoch 10
Loss = 1.8527e-03, PNorm = 61.9214, GNorm = 2.1663, lr_0 = 4.8539e-04
Loss = 1.8435e-03, PNorm = 61.9377, GNorm = 1.1622, lr_0 = 4.6483e-04
Validation rmse = 1.270006
Epoch 11
Loss = 1.8553e-03, PNorm = 61.9530, GNorm = 0.4090, lr_0 = 4.4322e-04
Loss = 1.6113e-03, PNorm = 61.9643, GNorm = 1.4059, lr_0 = 4.2444e-04
Validation rmse = 1.142146
Epoch 12
Loss = 1.2806e-03, PNorm = 61.9753, GNorm = 0.5954, lr_0 = 4.0646e-04
Loss = 1.4719e-03, PNorm = 61.9854, GNorm = 0.5889, lr_0 = 3.8925e-04
Validation rmse = 1.041754
Epoch 13
Loss = 1.2063e-03, PNorm = 61.9959, GNorm = 1.0591, lr_0 = 3.7276e-04
Loss = 1.5799e-03, PNorm = 62.0073, GNorm = 0.7892, lr_0 = 3.5697e-04
Validation rmse = 1.003584
Epoch 14
Loss = 1.4117e-03, PNorm = 62.0152, GNorm = 1.5169, lr_0 = 3.4037e-04
Loss = 1.5392e-03, PNorm = 62.0244, GNorm = 1.8105, lr_0 = 3.2596e-04
Validation rmse = 0.986055
Epoch 15
Loss = 1.2349e-03, PNorm = 62.0329, GNorm = 0.5544, lr_0 = 3.1215e-04
Loss = 1.5035e-03, PNorm = 62.0400, GNorm = 1.0673, lr_0 = 2.9893e-04
Validation rmse = 0.967068
Epoch 16
Loss = 1.1708e-03, PNorm = 62.0505, GNorm = 1.4173, lr_0 = 2.8503e-04
Loss = 1.5627e-03, PNorm = 62.0566, GNorm = 1.2871, lr_0 = 2.7295e-04
Validation rmse = 0.988809
Epoch 17
Loss = 1.1703e-03, PNorm = 62.0648, GNorm = 0.8861, lr_0 = 2.6139e-04
Loss = 1.2677e-03, PNorm = 62.0719, GNorm = 0.4685, lr_0 = 2.5032e-04
Validation rmse = 1.018207
Epoch 18
Loss = 1.4405e-03, PNorm = 62.0799, GNorm = 1.4494, lr_0 = 2.3972e-04
Loss = 1.2181e-03, PNorm = 62.0877, GNorm = 0.8298, lr_0 = 2.2956e-04
Validation rmse = 1.061430
Epoch 19
Loss = 1.3113e-03, PNorm = 62.0939, GNorm = 1.2822, lr_0 = 2.1889e-04
Loss = 1.2459e-03, PNorm = 62.1016, GNorm = 1.4823, lr_0 = 2.0962e-04
Validation rmse = 1.046010
Epoch 20
Loss = 1.2572e-03, PNorm = 62.1082, GNorm = 0.5383, lr_0 = 2.0074e-04
Loss = 1.2244e-03, PNorm = 62.1144, GNorm = 1.9755, lr_0 = 1.9224e-04
Validation rmse = 1.182456
Epoch 21
Loss = 1.0867e-03, PNorm = 62.1209, GNorm = 0.7259, lr_0 = 1.8409e-04
Loss = 1.3714e-03, PNorm = 62.1279, GNorm = 1.8502, lr_0 = 1.7630e-04
Validation rmse = 0.969361
Epoch 22
Loss = 1.0259e-03, PNorm = 62.1349, GNorm = 1.3517, lr_0 = 1.6810e-04
Loss = 1.3153e-03, PNorm = 62.1398, GNorm = 0.3667, lr_0 = 1.6098e-04
Validation rmse = 0.964020
Epoch 23
Loss = 1.1694e-03, PNorm = 62.1440, GNorm = 1.3805, lr_0 = 1.5416e-04
Loss = 1.1207e-03, PNorm = 62.1491, GNorm = 0.3319, lr_0 = 1.4763e-04
Loss = 1.4240e-03, PNorm = 62.1496, GNorm = 0.6950, lr_0 = 1.4699e-04
Validation rmse = 0.905486
Epoch 24
Loss = 1.0072e-03, PNorm = 62.1526, GNorm = 0.7024, lr_0 = 1.4077e-04
Loss = 1.2325e-03, PNorm = 62.1573, GNorm = 0.8216, lr_0 = 1.3480e-04
Validation rmse = 1.021914
Epoch 25
Loss = 1.0511e-03, PNorm = 62.1610, GNorm = 1.3104, lr_0 = 1.2909e-04
Loss = 1.2785e-03, PNorm = 62.1650, GNorm = 1.2859, lr_0 = 1.2362e-04
Validation rmse = 0.923087
Epoch 26
Loss = 1.0082e-03, PNorm = 62.1688, GNorm = 0.5227, lr_0 = 1.1839e-04
Validation rmse = 0.939457
Epoch 27
Loss = 1.1768e-03, PNorm = 62.1742, GNorm = 1.1199, lr_0 = 1.1288e-04
Loss = 8.6005e-04, PNorm = 62.1761, GNorm = 0.8767, lr_0 = 1.0810e-04
Validation rmse = 0.875895
Epoch 28
Loss = 6.5142e-04, PNorm = 62.1799, GNorm = 0.9937, lr_0 = 1.0352e-04
Loss = 9.9306e-04, PNorm = 62.1831, GNorm = 0.5757, lr_0 = 1.0000e-04
Validation rmse = 0.953546
Epoch 29
Loss = 9.0102e-04, PNorm = 62.1863, GNorm = 0.7337, lr_0 = 1.0000e-04
Loss = 1.0553e-03, PNorm = 62.1900, GNorm = 0.7783, lr_0 = 1.0000e-04
Validation rmse = 0.913626
Model 0 best validation rmse = 0.875895 on epoch 27
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.088242
Ensemble test rmse = 1.088242
Fold 5
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1700,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1700,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.25_ffn_num_layers_1_hidden_size_1700/fold_5',
 'save_smiles_splits': True,
 'seed': 5,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 5
Total scaffolds = 195 | train scaffolds = 94 | val scaffolds = 55 | test scaffolds = 46
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1700, bias=False)
      (W_h): Linear(in_features=1700, out_features=1700, bias=False)
      (W_o): Linear(in_features=1833, out_features=1700, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=1704, out_features=1, bias=True)
  )
)
Number of parameters = 6,259,405
Moving model to cuda
Epoch 0
Loss = 1.7825e-02, PNorm = 61.1171, GNorm = 23.7170, lr_0 = 3.6053e-04
Validation rmse = 2.094448
Epoch 1
Loss = 9.6586e-03, PNorm = 61.1923, GNorm = 7.2479, lr_0 = 6.2105e-04
Loss = 5.8777e-03, PNorm = 61.2834, GNorm = 2.3667, lr_0 = 8.5789e-04
Validation rmse = 1.554980
Epoch 2
Loss = 3.5060e-03, PNorm = 61.3808, GNorm = 2.5329, lr_0 = 9.8284e-04
Loss = 4.3617e-03, PNorm = 61.4598, GNorm = 3.4388, lr_0 = 9.4120e-04
Validation rmse = 1.593997
Epoch 3
Loss = 5.4798e-03, PNorm = 61.5174, GNorm = 4.4258, lr_0 = 8.9744e-04
Loss = 4.0354e-03, PNorm = 61.5726, GNorm = 2.9429, lr_0 = 8.5943e-04
Validation rmse = 1.527549
Epoch 4
Loss = 2.8054e-03, PNorm = 61.6147, GNorm = 1.8150, lr_0 = 8.2303e-04
Loss = 3.0107e-03, PNorm = 61.6603, GNorm = 1.5151, lr_0 = 7.8816e-04
Validation rmse = 1.326744
Epoch 5
Loss = 2.0670e-03, PNorm = 61.6961, GNorm = 1.1922, lr_0 = 7.5478e-04
Loss = 2.6120e-03, PNorm = 61.7229, GNorm = 1.6077, lr_0 = 7.2281e-04
Validation rmse = 1.250742
Epoch 6
Loss = 2.6216e-03, PNorm = 61.7559, GNorm = 1.3236, lr_0 = 6.8920e-04
Loss = 2.2841e-03, PNorm = 61.7888, GNorm = 4.0999, lr_0 = 6.6001e-04
Validation rmse = 1.269615
Epoch 7
Loss = 2.0984e-03, PNorm = 61.8124, GNorm = 2.5888, lr_0 = 6.3205e-04
Loss = 1.7618e-03, PNorm = 61.8374, GNorm = 0.7557, lr_0 = 6.0528e-04
Validation rmse = 1.205076
Epoch 8
Loss = 2.3097e-03, PNorm = 61.8570, GNorm = 1.5276, lr_0 = 5.7714e-04
Loss = 2.3543e-03, PNorm = 61.8819, GNorm = 3.0136, lr_0 = 5.5269e-04
Validation rmse = 1.265423
Epoch 9
Loss = 2.1278e-03, PNorm = 61.9045, GNorm = 0.6628, lr_0 = 5.2928e-04
Loss = 2.2473e-03, PNorm = 61.9287, GNorm = 1.2438, lr_0 = 5.0686e-04
Validation rmse = 1.187958
Epoch 10
Loss = 1.4578e-03, PNorm = 61.9471, GNorm = 0.7475, lr_0 = 4.8539e-04
Loss = 1.7104e-03, PNorm = 61.9646, GNorm = 1.8018, lr_0 = 4.6483e-04
Validation rmse = 1.199378
Epoch 11
Loss = 1.2667e-03, PNorm = 61.9818, GNorm = 0.5852, lr_0 = 4.4322e-04
Loss = 1.5444e-03, PNorm = 61.9977, GNorm = 1.4896, lr_0 = 4.2444e-04
Validation rmse = 1.168913
Epoch 12
Loss = 1.1628e-03, PNorm = 62.0102, GNorm = 0.8133, lr_0 = 4.0646e-04
Loss = 1.5702e-03, PNorm = 62.0235, GNorm = 0.4373, lr_0 = 3.8925e-04
Validation rmse = 1.136908
Epoch 13
Loss = 1.2234e-03, PNorm = 62.0366, GNorm = 1.2835, lr_0 = 3.7276e-04
Loss = 1.4635e-03, PNorm = 62.0467, GNorm = 0.9596, lr_0 = 3.5697e-04
Validation rmse = 1.114607
Epoch 14
Loss = 1.4833e-03, PNorm = 62.0648, GNorm = 1.1352, lr_0 = 3.4037e-04
Loss = 1.2706e-03, PNorm = 62.0785, GNorm = 1.4740, lr_0 = 3.2596e-04
Validation rmse = 1.160422
Epoch 15
Loss = 1.4086e-03, PNorm = 62.0904, GNorm = 1.1674, lr_0 = 3.1215e-04
Loss = 1.3802e-03, PNorm = 62.1030, GNorm = 0.8683, lr_0 = 2.9893e-04
Validation rmse = 1.085767
Epoch 16
Loss = 1.3132e-03, PNorm = 62.1127, GNorm = 0.4892, lr_0 = 2.8503e-04
Loss = 1.3453e-03, PNorm = 62.1243, GNorm = 0.9621, lr_0 = 2.7295e-04
Validation rmse = 1.196834
Epoch 17
Loss = 1.1966e-03, PNorm = 62.1340, GNorm = 0.6620, lr_0 = 2.6139e-04
Loss = 1.2062e-03, PNorm = 62.1418, GNorm = 0.5491, lr_0 = 2.5032e-04
Validation rmse = 1.119542
Epoch 18
Loss = 1.1304e-03, PNorm = 62.1507, GNorm = 0.6956, lr_0 = 2.3972e-04
Loss = 1.2018e-03, PNorm = 62.1607, GNorm = 1.4702, lr_0 = 2.2956e-04
Validation rmse = 1.105303
Epoch 19
Loss = 1.0403e-03, PNorm = 62.1683, GNorm = 1.2228, lr_0 = 2.1889e-04
Loss = 1.2760e-03, PNorm = 62.1780, GNorm = 0.5685, lr_0 = 2.0962e-04
Validation rmse = 1.213059
Epoch 20
Loss = 1.1513e-03, PNorm = 62.1859, GNorm = 0.7941, lr_0 = 2.0074e-04
Loss = 1.2353e-03, PNorm = 62.1941, GNorm = 0.8662, lr_0 = 1.9224e-04
Validation rmse = 1.100149
Epoch 21
Loss = 1.0149e-03, PNorm = 62.2011, GNorm = 1.3834, lr_0 = 1.8409e-04
Loss = 1.1247e-03, PNorm = 62.2082, GNorm = 1.0479, lr_0 = 1.7630e-04
Validation rmse = 1.097860
Epoch 22
Loss = 9.1221e-04, PNorm = 62.2138, GNorm = 0.4859, lr_0 = 1.6810e-04
Loss = 1.2023e-03, PNorm = 62.2206, GNorm = 0.8502, lr_0 = 1.6098e-04
Validation rmse = 1.088519
Epoch 23
Loss = 1.1490e-03, PNorm = 62.2273, GNorm = 0.9082, lr_0 = 1.5416e-04
Loss = 9.4025e-04, PNorm = 62.2320, GNorm = 0.7577, lr_0 = 1.4763e-04
Loss = 7.9938e-04, PNorm = 62.2324, GNorm = 0.3985, lr_0 = 1.4699e-04
Validation rmse = 1.122763
Epoch 24
Loss = 9.8507e-04, PNorm = 62.2373, GNorm = 1.2462, lr_0 = 1.4077e-04
Loss = 1.1367e-03, PNorm = 62.2423, GNorm = 0.8006, lr_0 = 1.3480e-04
Validation rmse = 1.172602
Epoch 25
Loss = 9.4891e-04, PNorm = 62.2469, GNorm = 0.5562, lr_0 = 1.2909e-04
Loss = 1.0644e-03, PNorm = 62.2514, GNorm = 1.1368, lr_0 = 1.2362e-04
Validation rmse = 1.095418
Epoch 26
Loss = 9.1139e-04, PNorm = 62.2559, GNorm = 0.6528, lr_0 = 1.1839e-04
Validation rmse = 1.141403
Epoch 27
Loss = 1.3704e-03, PNorm = 62.2607, GNorm = 1.1932, lr_0 = 1.1288e-04
Loss = 8.7313e-04, PNorm = 62.2658, GNorm = 0.7825, lr_0 = 1.0810e-04
Validation rmse = 1.063106
Epoch 28
Loss = 8.0188e-04, PNorm = 62.2683, GNorm = 0.6541, lr_0 = 1.0352e-04
Loss = 9.5865e-04, PNorm = 62.2721, GNorm = 1.0555, lr_0 = 1.0000e-04
Validation rmse = 1.077575
Epoch 29
Loss = 7.3830e-04, PNorm = 62.2756, GNorm = 0.6981, lr_0 = 1.0000e-04
Loss = 9.7318e-04, PNorm = 62.2793, GNorm = 0.4725, lr_0 = 1.0000e-04
Validation rmse = 1.065552
Model 0 best validation rmse = 1.063106 on epoch 27
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.161902
Ensemble test rmse = 1.161902
Fold 6
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1700,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1700,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.25_ffn_num_layers_1_hidden_size_1700/fold_6',
 'save_smiles_splits': True,
 'seed': 6,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 6
Total scaffolds = 195 | train scaffolds = 64 | val scaffolds = 68 | test scaffolds = 63
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1700, bias=False)
      (W_h): Linear(in_features=1700, out_features=1700, bias=False)
      (W_o): Linear(in_features=1833, out_features=1700, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=1704, out_features=1, bias=True)
  )
)
Number of parameters = 6,259,405
Moving model to cuda
Epoch 0
Loss = 1.7926e-02, PNorm = 61.1158, GNorm = 6.6807, lr_0 = 3.6053e-04
Validation rmse = 1.540937
Epoch 1
Loss = 9.7766e-03, PNorm = 61.1843, GNorm = 4.5135, lr_0 = 6.2105e-04
Loss = 9.4261e-03, PNorm = 61.2889, GNorm = 6.0501, lr_0 = 8.5789e-04
Validation rmse = 1.570284
Epoch 2
Loss = 5.7032e-03, PNorm = 61.4016, GNorm = 1.9637, lr_0 = 9.8284e-04
Loss = 5.2997e-03, PNorm = 61.4783, GNorm = 1.4512, lr_0 = 9.4120e-04
Validation rmse = 1.386239
Epoch 3
Loss = 2.6416e-03, PNorm = 61.5434, GNorm = 2.7107, lr_0 = 8.9744e-04
Loss = 3.1613e-03, PNorm = 61.5885, GNorm = 1.1306, lr_0 = 8.5943e-04
Validation rmse = 1.329499
Epoch 4
Loss = 2.3758e-03, PNorm = 61.6289, GNorm = 0.8328, lr_0 = 8.2303e-04
Loss = 2.6054e-03, PNorm = 61.6717, GNorm = 1.9545, lr_0 = 7.8816e-04
Validation rmse = 1.325304
Epoch 5
Loss = 2.1009e-03, PNorm = 61.7036, GNorm = 2.2356, lr_0 = 7.5478e-04
Loss = 2.2798e-03, PNorm = 61.7311, GNorm = 2.3092, lr_0 = 7.2281e-04
Validation rmse = 1.404962
Epoch 6
Loss = 1.8582e-03, PNorm = 61.7636, GNorm = 2.6795, lr_0 = 6.8920e-04
Loss = 2.0669e-03, PNorm = 61.7915, GNorm = 1.6373, lr_0 = 6.6001e-04
Validation rmse = 1.180294
Epoch 7
Loss = 2.1387e-03, PNorm = 61.8134, GNorm = 2.2385, lr_0 = 6.3205e-04
Loss = 1.7382e-03, PNorm = 61.8350, GNorm = 1.2949, lr_0 = 6.0528e-04
Validation rmse = 1.401457
Epoch 8
Loss = 2.2507e-03, PNorm = 61.8626, GNorm = 2.3658, lr_0 = 5.7714e-04
Loss = 2.2036e-03, PNorm = 61.8888, GNorm = 0.5935, lr_0 = 5.5269e-04
Validation rmse = 1.349239
Epoch 9
Loss = 1.8371e-03, PNorm = 61.9113, GNorm = 2.5550, lr_0 = 5.2928e-04
Loss = 1.6922e-03, PNorm = 61.9335, GNorm = 1.1106, lr_0 = 5.0686e-04
Validation rmse = 1.161008
Epoch 10
Loss = 1.8903e-03, PNorm = 61.9555, GNorm = 1.1899, lr_0 = 4.8539e-04
Loss = 1.3026e-03, PNorm = 61.9736, GNorm = 1.4425, lr_0 = 4.6483e-04
Validation rmse = 1.051145
Epoch 11
Loss = 1.8245e-03, PNorm = 61.9903, GNorm = 0.4783, lr_0 = 4.4322e-04
Loss = 1.3272e-03, PNorm = 62.0049, GNorm = 2.0448, lr_0 = 4.2444e-04
Validation rmse = 1.086997
Epoch 12
Loss = 1.2535e-03, PNorm = 62.0186, GNorm = 0.7656, lr_0 = 4.0646e-04
Loss = 1.4333e-03, PNorm = 62.0312, GNorm = 1.7253, lr_0 = 3.8925e-04
Validation rmse = 1.100332
Epoch 13
Loss = 1.2744e-03, PNorm = 62.0463, GNorm = 0.8851, lr_0 = 3.7276e-04
Loss = 1.2843e-03, PNorm = 62.0612, GNorm = 0.7859, lr_0 = 3.5697e-04
Validation rmse = 1.243786
Epoch 14
Loss = 1.1261e-03, PNorm = 62.0736, GNorm = 0.9180, lr_0 = 3.4037e-04
Loss = 1.4776e-03, PNorm = 62.0864, GNorm = 1.0527, lr_0 = 3.2596e-04
Validation rmse = 1.069976
Epoch 15
Loss = 1.2335e-03, PNorm = 62.0964, GNorm = 1.4579, lr_0 = 3.1215e-04
Loss = 1.2765e-03, PNorm = 62.1084, GNorm = 1.8759, lr_0 = 2.9893e-04
Validation rmse = 1.136548
Epoch 16
Loss = 1.2994e-03, PNorm = 62.1228, GNorm = 1.0477, lr_0 = 2.8503e-04
Loss = 1.2544e-03, PNorm = 62.1318, GNorm = 2.7149, lr_0 = 2.7295e-04
Validation rmse = 1.200073
Epoch 17
Loss = 1.3013e-03, PNorm = 62.1427, GNorm = 0.4807, lr_0 = 2.6139e-04
Loss = 1.4006e-03, PNorm = 62.1485, GNorm = 2.1943, lr_0 = 2.5032e-04
Validation rmse = 1.228877
Epoch 18
Loss = 1.6937e-03, PNorm = 62.1605, GNorm = 1.8637, lr_0 = 2.3972e-04
Loss = 1.3099e-03, PNorm = 62.1708, GNorm = 0.9263, lr_0 = 2.2956e-04
Validation rmse = 1.084547
Epoch 19
Loss = 1.0125e-03, PNorm = 62.1833, GNorm = 0.4881, lr_0 = 2.1889e-04
Loss = 1.1184e-03, PNorm = 62.1913, GNorm = 0.7829, lr_0 = 2.0962e-04
Validation rmse = 1.088429
Epoch 20
Loss = 1.0331e-03, PNorm = 62.1981, GNorm = 0.4919, lr_0 = 2.0074e-04
Loss = 9.6159e-04, PNorm = 62.2038, GNorm = 0.4476, lr_0 = 1.9224e-04
Validation rmse = 1.085143
Epoch 21
Loss = 9.1838e-04, PNorm = 62.2119, GNorm = 0.7710, lr_0 = 1.8409e-04
Loss = 9.5923e-04, PNorm = 62.2181, GNorm = 0.8546, lr_0 = 1.7630e-04
Validation rmse = 1.154203
Epoch 22
Loss = 1.0879e-03, PNorm = 62.2244, GNorm = 0.6284, lr_0 = 1.6810e-04
Loss = 8.6950e-04, PNorm = 62.2297, GNorm = 0.8102, lr_0 = 1.6098e-04
Validation rmse = 1.065376
Epoch 23
Loss = 9.3208e-04, PNorm = 62.2362, GNorm = 0.6311, lr_0 = 1.5416e-04
Loss = 9.6725e-04, PNorm = 62.2415, GNorm = 0.5063, lr_0 = 1.4763e-04
Loss = 2.2096e-03, PNorm = 62.2420, GNorm = 0.9844, lr_0 = 1.4699e-04
Validation rmse = 1.062857
Epoch 24
Loss = 9.8159e-04, PNorm = 62.2479, GNorm = 0.9672, lr_0 = 1.4077e-04
Loss = 9.4630e-04, PNorm = 62.2526, GNorm = 0.5595, lr_0 = 1.3480e-04
Validation rmse = 1.117757
Epoch 25
Loss = 9.0710e-04, PNorm = 62.2565, GNorm = 1.2344, lr_0 = 1.2909e-04
Loss = 9.5555e-04, PNorm = 62.2615, GNorm = 0.9278, lr_0 = 1.2362e-04
Validation rmse = 1.037079
Epoch 26
Loss = 8.6521e-04, PNorm = 62.2657, GNorm = 0.5772, lr_0 = 1.1839e-04
Validation rmse = 1.049540
Epoch 27
Loss = 1.2324e-03, PNorm = 62.2705, GNorm = 1.2335, lr_0 = 1.1288e-04
Loss = 7.9213e-04, PNorm = 62.2746, GNorm = 0.7038, lr_0 = 1.0810e-04
Validation rmse = 1.068078
Epoch 28
Loss = 8.3100e-04, PNorm = 62.2783, GNorm = 1.0368, lr_0 = 1.0352e-04
Loss = 9.4193e-04, PNorm = 62.2815, GNorm = 0.6199, lr_0 = 1.0000e-04
Validation rmse = 1.118102
Epoch 29
Loss = 9.1261e-04, PNorm = 62.2856, GNorm = 1.0780, lr_0 = 1.0000e-04
Loss = 8.8425e-04, PNorm = 62.2895, GNorm = 1.0124, lr_0 = 1.0000e-04
Validation rmse = 1.053264
Model 0 best validation rmse = 1.037079 on epoch 25
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 0.980438
Ensemble test rmse = 0.980438
Fold 7
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1700,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1700,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.25_ffn_num_layers_1_hidden_size_1700/fold_7',
 'save_smiles_splits': True,
 'seed': 7,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 7
Total scaffolds = 195 | train scaffolds = 69 | val scaffolds = 65 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1700, bias=False)
      (W_h): Linear(in_features=1700, out_features=1700, bias=False)
      (W_o): Linear(in_features=1833, out_features=1700, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=1704, out_features=1, bias=True)
  )
)
Number of parameters = 6,259,405
Moving model to cuda
Epoch 0
Loss = 1.8132e-02, PNorm = 61.1145, GNorm = 3.7025, lr_0 = 3.6053e-04
Validation rmse = 1.589882
Epoch 1
Loss = 9.2270e-03, PNorm = 61.1899, GNorm = 7.7579, lr_0 = 6.2105e-04
Loss = 8.0970e-03, PNorm = 61.2894, GNorm = 4.4836, lr_0 = 8.5789e-04
Validation rmse = 2.083600
Epoch 2
Loss = 4.8567e-03, PNorm = 61.3967, GNorm = 3.4733, lr_0 = 9.8284e-04
Loss = 4.6466e-03, PNorm = 61.4827, GNorm = 2.9154, lr_0 = 9.4120e-04
Validation rmse = 1.636817
Epoch 3
Loss = 4.7653e-03, PNorm = 61.5436, GNorm = 4.9044, lr_0 = 8.9744e-04
Loss = 4.1515e-03, PNorm = 61.6001, GNorm = 2.1395, lr_0 = 8.5943e-04
Validation rmse = 1.519407
Epoch 4
Loss = 3.2974e-03, PNorm = 61.6338, GNorm = 3.3016, lr_0 = 8.2303e-04
Loss = 3.5030e-03, PNorm = 61.6720, GNorm = 2.2723, lr_0 = 7.8816e-04
Validation rmse = 1.486789
Epoch 5
Loss = 2.3343e-03, PNorm = 61.7118, GNorm = 0.8218, lr_0 = 7.5478e-04
Loss = 2.2092e-03, PNorm = 61.7427, GNorm = 1.3293, lr_0 = 7.2281e-04
Validation rmse = 1.776718
Epoch 6
Loss = 4.5068e-03, PNorm = 61.7722, GNorm = 5.2496, lr_0 = 6.8920e-04
Loss = 3.4198e-03, PNorm = 61.8094, GNorm = 0.8310, lr_0 = 6.6001e-04
Validation rmse = 1.714689
Epoch 7
Loss = 2.3710e-03, PNorm = 61.8428, GNorm = 4.7485, lr_0 = 6.3205e-04
Loss = 3.1188e-03, PNorm = 61.8692, GNorm = 1.4140, lr_0 = 6.0528e-04
Validation rmse = 1.389521
Epoch 8
Loss = 2.0392e-03, PNorm = 61.8965, GNorm = 1.1146, lr_0 = 5.7714e-04
Loss = 2.3189e-03, PNorm = 61.9176, GNorm = 1.9378, lr_0 = 5.5269e-04
Validation rmse = 1.455826
Epoch 9
Loss = 1.8291e-03, PNorm = 61.9352, GNorm = 0.7470, lr_0 = 5.2928e-04
Loss = 1.7746e-03, PNorm = 61.9533, GNorm = 1.0025, lr_0 = 5.0686e-04
Validation rmse = 1.513493
Epoch 10
Loss = 1.9742e-03, PNorm = 61.9638, GNorm = 1.6842, lr_0 = 4.8539e-04
Loss = 1.6075e-03, PNorm = 61.9773, GNorm = 0.9519, lr_0 = 4.6483e-04
Validation rmse = 1.375036
Epoch 11
Loss = 1.5532e-03, PNorm = 61.9966, GNorm = 0.7217, lr_0 = 4.4322e-04
Loss = 1.6089e-03, PNorm = 62.0079, GNorm = 0.8962, lr_0 = 4.2444e-04
Validation rmse = 1.273210
Epoch 12
Loss = 1.4004e-03, PNorm = 62.0239, GNorm = 0.6676, lr_0 = 4.0646e-04
Loss = 1.5152e-03, PNorm = 62.0362, GNorm = 1.4353, lr_0 = 3.8925e-04
Validation rmse = 1.260293
Epoch 13
Loss = 1.9630e-03, PNorm = 62.0474, GNorm = 2.0521, lr_0 = 3.7276e-04
Loss = 1.7553e-03, PNorm = 62.0613, GNorm = 1.6136, lr_0 = 3.5697e-04
Validation rmse = 1.457282
Epoch 14
Loss = 1.5156e-03, PNorm = 62.0738, GNorm = 1.2892, lr_0 = 3.4037e-04
Loss = 1.4006e-03, PNorm = 62.0860, GNorm = 1.1873, lr_0 = 3.2596e-04
Validation rmse = 1.358388
Epoch 15
Loss = 1.2532e-03, PNorm = 62.0963, GNorm = 1.7074, lr_0 = 3.1215e-04
Loss = 1.4469e-03, PNorm = 62.1068, GNorm = 0.6068, lr_0 = 2.9893e-04
Validation rmse = 1.581791
Epoch 16
Loss = 1.4082e-03, PNorm = 62.1206, GNorm = 0.9826, lr_0 = 2.8503e-04
Loss = 1.3076e-03, PNorm = 62.1286, GNorm = 0.6591, lr_0 = 2.7295e-04
Validation rmse = 1.527445
Epoch 17
Loss = 1.2469e-03, PNorm = 62.1402, GNorm = 0.6322, lr_0 = 2.6139e-04
Loss = 1.4168e-03, PNorm = 62.1472, GNorm = 0.5377, lr_0 = 2.5032e-04
Validation rmse = 1.389617
Epoch 18
Loss = 1.0682e-03, PNorm = 62.1547, GNorm = 1.2943, lr_0 = 2.3972e-04
Loss = 1.2763e-03, PNorm = 62.1627, GNorm = 0.5325, lr_0 = 2.2956e-04
Validation rmse = 1.396679
Epoch 19
Loss = 1.2834e-03, PNorm = 62.1704, GNorm = 0.8922, lr_0 = 2.1889e-04
Loss = 1.1063e-03, PNorm = 62.1780, GNorm = 0.4830, lr_0 = 2.0962e-04
Validation rmse = 1.343806
Epoch 20
Loss = 1.3052e-03, PNorm = 62.1842, GNorm = 0.6235, lr_0 = 2.0074e-04
Loss = 1.0001e-03, PNorm = 62.1910, GNorm = 0.5163, lr_0 = 1.9224e-04
Validation rmse = 1.385071
Epoch 21
Loss = 1.1571e-03, PNorm = 62.1966, GNorm = 1.3309, lr_0 = 1.8409e-04
Loss = 1.2317e-03, PNorm = 62.2038, GNorm = 0.5347, lr_0 = 1.7630e-04
Validation rmse = 1.486720
Epoch 22
Loss = 1.2019e-03, PNorm = 62.2097, GNorm = 2.2214, lr_0 = 1.6810e-04
Loss = 1.1351e-03, PNorm = 62.2174, GNorm = 0.7447, lr_0 = 1.6098e-04
Validation rmse = 1.324417
Epoch 23
Loss = 1.1361e-03, PNorm = 62.2230, GNorm = 0.4486, lr_0 = 1.5416e-04
Loss = 1.0130e-03, PNorm = 62.2277, GNorm = 0.8899, lr_0 = 1.4763e-04
Loss = 1.8655e-03, PNorm = 62.2282, GNorm = 1.4837, lr_0 = 1.4699e-04
Validation rmse = 1.298446
Epoch 24
Loss = 1.0759e-03, PNorm = 62.2327, GNorm = 0.6743, lr_0 = 1.4077e-04
Loss = 1.2370e-03, PNorm = 62.2383, GNorm = 1.0246, lr_0 = 1.3480e-04
Validation rmse = 1.280973
Epoch 25
Loss = 1.0376e-03, PNorm = 62.2423, GNorm = 0.6202, lr_0 = 1.2909e-04
Loss = 1.1905e-03, PNorm = 62.2480, GNorm = 1.0946, lr_0 = 1.2362e-04
Validation rmse = 1.376484
Epoch 26
Loss = 1.0580e-03, PNorm = 62.2512, GNorm = 1.1992, lr_0 = 1.1839e-04
Validation rmse = 1.388099
Epoch 27
Loss = 7.3106e-04, PNorm = 62.2548, GNorm = 0.9590, lr_0 = 1.1288e-04
Loss = 8.5547e-04, PNorm = 62.2591, GNorm = 1.2741, lr_0 = 1.0810e-04
Validation rmse = 1.362857
Epoch 28
Loss = 8.4726e-04, PNorm = 62.2627, GNorm = 0.4873, lr_0 = 1.0352e-04
Loss = 9.1780e-04, PNorm = 62.2672, GNorm = 0.7728, lr_0 = 1.0000e-04
Validation rmse = 1.394870
Epoch 29
Loss = 1.3594e-03, PNorm = 62.2703, GNorm = 0.9746, lr_0 = 1.0000e-04
Loss = 8.5949e-04, PNorm = 62.2733, GNorm = 0.6356, lr_0 = 1.0000e-04
Validation rmse = 1.335369
Model 0 best validation rmse = 1.260293 on epoch 12
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.147493
Ensemble test rmse = 1.147493
Fold 8
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1700,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1700,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.25_ffn_num_layers_1_hidden_size_1700/fold_8',
 'save_smiles_splits': True,
 'seed': 8,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 8
Total scaffolds = 195 | train scaffolds = 75 | val scaffolds = 42 | test scaffolds = 78
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1700, bias=False)
      (W_h): Linear(in_features=1700, out_features=1700, bias=False)
      (W_o): Linear(in_features=1833, out_features=1700, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=1704, out_features=1, bias=True)
  )
)
Number of parameters = 6,259,405
Moving model to cuda
Epoch 0
Loss = 2.2762e-02, PNorm = 61.1126, GNorm = 3.3085, lr_0 = 3.6053e-04
Validation rmse = 2.035955
Epoch 1
Loss = 8.6383e-03, PNorm = 61.1857, GNorm = 6.3195, lr_0 = 6.2105e-04
Loss = 7.4034e-03, PNorm = 61.2783, GNorm = 1.1460, lr_0 = 8.5789e-04
Validation rmse = 1.851501
Epoch 2
Loss = 6.4011e-03, PNorm = 61.3685, GNorm = 3.5297, lr_0 = 9.8284e-04
Loss = 4.0886e-03, PNorm = 61.4466, GNorm = 2.7910, lr_0 = 9.4120e-04
Validation rmse = 1.576824
Epoch 3
Loss = 4.1527e-03, PNorm = 61.4979, GNorm = 2.3208, lr_0 = 8.9744e-04
Loss = 3.6384e-03, PNorm = 61.5401, GNorm = 4.7562, lr_0 = 8.5943e-04
Validation rmse = 1.522027
Epoch 4
Loss = 2.9988e-03, PNorm = 61.5733, GNorm = 1.3351, lr_0 = 8.2303e-04
Loss = 2.8202e-03, PNorm = 61.6003, GNorm = 2.7628, lr_0 = 7.8816e-04
Validation rmse = 1.270337
Epoch 5
Loss = 1.7888e-03, PNorm = 61.6294, GNorm = 2.3789, lr_0 = 7.5478e-04
Loss = 2.3003e-03, PNorm = 61.6582, GNorm = 0.8267, lr_0 = 7.2281e-04
Validation rmse = 1.296300
Epoch 6
Loss = 1.5829e-03, PNorm = 61.6803, GNorm = 0.9970, lr_0 = 6.8920e-04
Loss = 2.1526e-03, PNorm = 61.7002, GNorm = 2.9329, lr_0 = 6.6001e-04
Validation rmse = 1.234862
Epoch 7
Loss = 2.3155e-03, PNorm = 61.7245, GNorm = 3.7011, lr_0 = 6.3205e-04
Loss = 2.1899e-03, PNorm = 61.7477, GNorm = 1.5272, lr_0 = 6.0528e-04
Validation rmse = 1.226383
Epoch 8
Loss = 2.1616e-03, PNorm = 61.7705, GNorm = 1.6340, lr_0 = 5.7714e-04
Loss = 1.6195e-03, PNorm = 61.7882, GNorm = 3.0329, lr_0 = 5.5269e-04
Validation rmse = 1.249248
Epoch 9
Loss = 1.6115e-03, PNorm = 61.8067, GNorm = 2.8859, lr_0 = 5.2928e-04
Loss = 1.5399e-03, PNorm = 61.8266, GNorm = 0.5389, lr_0 = 5.0686e-04
Validation rmse = 1.221795
Epoch 10
Loss = 1.3405e-03, PNorm = 61.8414, GNorm = 0.8438, lr_0 = 4.8539e-04
Loss = 1.6487e-03, PNorm = 61.8547, GNorm = 0.9665, lr_0 = 4.6483e-04
Validation rmse = 1.124101
Epoch 11
Loss = 1.7838e-03, PNorm = 61.8667, GNorm = 2.2669, lr_0 = 4.4322e-04
Loss = 1.3310e-03, PNorm = 61.8782, GNorm = 0.8879, lr_0 = 4.2444e-04
Validation rmse = 1.146714
Epoch 12
Loss = 1.3293e-03, PNorm = 61.8912, GNorm = 1.7706, lr_0 = 4.0646e-04
Loss = 1.2448e-03, PNorm = 61.9036, GNorm = 0.8178, lr_0 = 3.8925e-04
Validation rmse = 1.093675
Epoch 13
Loss = 1.1267e-03, PNorm = 61.9140, GNorm = 0.7001, lr_0 = 3.7276e-04
Loss = 1.2591e-03, PNorm = 61.9242, GNorm = 0.6234, lr_0 = 3.5697e-04
Validation rmse = 1.035772
Epoch 14
Loss = 1.2741e-03, PNorm = 61.9368, GNorm = 0.5556, lr_0 = 3.4037e-04
Loss = 1.3627e-03, PNorm = 61.9456, GNorm = 2.0768, lr_0 = 3.2596e-04
Validation rmse = 1.087029
Epoch 15
Loss = 1.4204e-03, PNorm = 61.9529, GNorm = 2.3443, lr_0 = 3.1215e-04
Loss = 1.5414e-03, PNorm = 61.9641, GNorm = 0.5030, lr_0 = 2.9893e-04
Validation rmse = 1.122075
Epoch 16
Loss = 1.2433e-03, PNorm = 61.9762, GNorm = 1.0713, lr_0 = 2.8503e-04
Loss = 1.2374e-03, PNorm = 61.9865, GNorm = 0.5154, lr_0 = 2.7295e-04
Validation rmse = 1.090781
Epoch 17
Loss = 1.1308e-03, PNorm = 61.9929, GNorm = 0.6403, lr_0 = 2.6139e-04
Loss = 1.1960e-03, PNorm = 62.0030, GNorm = 0.6090, lr_0 = 2.5032e-04
Validation rmse = 1.085474
Epoch 18
Loss = 1.0733e-03, PNorm = 62.0091, GNorm = 1.0120, lr_0 = 2.3972e-04
Loss = 1.1884e-03, PNorm = 62.0144, GNorm = 1.0757, lr_0 = 2.2956e-04
Validation rmse = 1.115346
Epoch 19
Loss = 1.2661e-03, PNorm = 62.0214, GNorm = 1.3884, lr_0 = 2.1889e-04
Loss = 1.2611e-03, PNorm = 62.0262, GNorm = 0.8308, lr_0 = 2.0962e-04
Validation rmse = 1.104844
Epoch 20
Loss = 1.0790e-03, PNorm = 62.0358, GNorm = 0.4474, lr_0 = 2.0074e-04
Loss = 1.3340e-03, PNorm = 62.0413, GNorm = 0.5581, lr_0 = 1.9224e-04
Validation rmse = 1.064585
Epoch 21
Loss = 1.0568e-03, PNorm = 62.0489, GNorm = 1.6299, lr_0 = 1.8409e-04
Loss = 1.3618e-03, PNorm = 62.0557, GNorm = 1.0324, lr_0 = 1.7630e-04
Validation rmse = 1.123497
Epoch 22
Loss = 1.1568e-03, PNorm = 62.0632, GNorm = 0.6625, lr_0 = 1.6810e-04
Loss = 1.1593e-03, PNorm = 62.0690, GNorm = 1.3507, lr_0 = 1.6098e-04
Validation rmse = 1.038660
Epoch 23
Loss = 1.1036e-03, PNorm = 62.0741, GNorm = 0.8288, lr_0 = 1.5416e-04
Loss = 1.0526e-03, PNorm = 62.0788, GNorm = 0.9011, lr_0 = 1.4763e-04
Loss = 1.4371e-03, PNorm = 62.0792, GNorm = 1.6124, lr_0 = 1.4699e-04
Validation rmse = 1.086714
Epoch 24
Loss = 1.0087e-03, PNorm = 62.0831, GNorm = 0.4561, lr_0 = 1.4077e-04
Loss = 1.0334e-03, PNorm = 62.0890, GNorm = 1.0252, lr_0 = 1.3480e-04
Validation rmse = 1.058275
Epoch 25
Loss = 1.0407e-03, PNorm = 62.0928, GNorm = 0.9884, lr_0 = 1.2909e-04
Loss = 9.4020e-04, PNorm = 62.0976, GNorm = 0.8017, lr_0 = 1.2362e-04
Validation rmse = 1.046113
Epoch 26
Loss = 1.1271e-03, PNorm = 62.1022, GNorm = 0.5540, lr_0 = 1.1839e-04
Validation rmse = 1.077046
Epoch 27
Loss = 2.1678e-03, PNorm = 62.1057, GNorm = 2.4932, lr_0 = 1.1288e-04
Loss = 8.8966e-04, PNorm = 62.1088, GNorm = 1.6523, lr_0 = 1.0810e-04
Validation rmse = 1.046230
Epoch 28
Loss = 7.0983e-04, PNorm = 62.1123, GNorm = 0.4967, lr_0 = 1.0352e-04
Loss = 9.5117e-04, PNorm = 62.1146, GNorm = 1.1472, lr_0 = 1.0000e-04
Validation rmse = 1.101350
Epoch 29
Loss = 7.8414e-04, PNorm = 62.1197, GNorm = 0.6566, lr_0 = 1.0000e-04
Loss = 7.9007e-04, PNorm = 62.1226, GNorm = 0.6311, lr_0 = 1.0000e-04
Validation rmse = 1.038377
Model 0 best validation rmse = 1.035772 on epoch 13
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.122780
Ensemble test rmse = 1.122780
Fold 9
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1700,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1700,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.25_ffn_num_layers_1_hidden_size_1700/fold_9',
 'save_smiles_splits': True,
 'seed': 9,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 9
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 58 | test scaffolds = 53
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1700, bias=False)
      (W_h): Linear(in_features=1700, out_features=1700, bias=False)
      (W_o): Linear(in_features=1833, out_features=1700, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=1704, out_features=1, bias=True)
  )
)
Number of parameters = 6,259,405
Moving model to cuda
Epoch 0
Loss = 1.5833e-02, PNorm = 61.1148, GNorm = 2.9536, lr_0 = 3.6053e-04
Validation rmse = 1.799889
Epoch 1
Loss = 7.0771e-03, PNorm = 61.1881, GNorm = 5.3009, lr_0 = 6.2105e-04
Loss = 7.1675e-03, PNorm = 61.2850, GNorm = 2.3903, lr_0 = 8.5789e-04
Validation rmse = 2.097388
Epoch 2
Loss = 1.1555e-02, PNorm = 61.3862, GNorm = 7.9378, lr_0 = 9.8284e-04
Loss = 6.2214e-03, PNorm = 61.4764, GNorm = 4.7936, lr_0 = 9.4120e-04
Validation rmse = 1.879492
Epoch 3
Loss = 8.7888e-03, PNorm = 61.5514, GNorm = 5.8141, lr_0 = 8.9744e-04
Loss = 5.3102e-03, PNorm = 61.6136, GNorm = 2.2288, lr_0 = 8.5943e-04
Validation rmse = 1.269834
Epoch 4
Loss = 5.0331e-03, PNorm = 61.6592, GNorm = 5.2682, lr_0 = 8.2303e-04
Loss = 3.0669e-03, PNorm = 61.6970, GNorm = 1.5576, lr_0 = 7.8816e-04
Validation rmse = 1.238411
Epoch 5
Loss = 1.9151e-03, PNorm = 61.7275, GNorm = 0.6820, lr_0 = 7.5478e-04
Loss = 2.8749e-03, PNorm = 61.7568, GNorm = 1.0540, lr_0 = 7.2281e-04
Validation rmse = 1.085195
Epoch 6
Loss = 2.7425e-03, PNorm = 61.7850, GNorm = 1.0532, lr_0 = 6.8920e-04
Loss = 2.5634e-03, PNorm = 61.8064, GNorm = 2.7077, lr_0 = 6.6001e-04
Validation rmse = 1.157274
Epoch 7
Loss = 2.5091e-03, PNorm = 61.8285, GNorm = 1.5640, lr_0 = 6.3205e-04
Loss = 2.2854e-03, PNorm = 61.8536, GNorm = 2.0544, lr_0 = 6.0528e-04
Validation rmse = 1.113483
Epoch 8
Loss = 1.6960e-03, PNorm = 61.8752, GNorm = 0.8339, lr_0 = 5.7714e-04
Loss = 1.8982e-03, PNorm = 61.8938, GNorm = 1.1743, lr_0 = 5.5269e-04
Validation rmse = 1.055053
Epoch 9
Loss = 2.2808e-03, PNorm = 61.9142, GNorm = 3.2329, lr_0 = 5.2928e-04
Loss = 1.5492e-03, PNorm = 61.9362, GNorm = 0.7017, lr_0 = 5.0686e-04
Validation rmse = 1.016881
Epoch 10
Loss = 1.6361e-03, PNorm = 61.9512, GNorm = 0.9690, lr_0 = 4.8539e-04
Loss = 1.6917e-03, PNorm = 61.9651, GNorm = 0.9389, lr_0 = 4.6483e-04
Validation rmse = 1.026803
Epoch 11
Loss = 1.8287e-03, PNorm = 61.9818, GNorm = 0.9204, lr_0 = 4.4322e-04
Loss = 1.8517e-03, PNorm = 61.9970, GNorm = 1.7817, lr_0 = 4.2444e-04
Validation rmse = 1.054686
Epoch 12
Loss = 1.5620e-03, PNorm = 62.0115, GNorm = 0.6728, lr_0 = 4.0646e-04
Loss = 1.8469e-03, PNorm = 62.0253, GNorm = 1.3371, lr_0 = 3.8925e-04
Validation rmse = 0.957899
Epoch 13
Loss = 1.4515e-03, PNorm = 62.0370, GNorm = 1.2064, lr_0 = 3.7276e-04
Loss = 1.4743e-03, PNorm = 62.0480, GNorm = 0.8326, lr_0 = 3.5697e-04
Validation rmse = 1.036293
Epoch 14
Loss = 1.5164e-03, PNorm = 62.0635, GNorm = 1.2302, lr_0 = 3.4037e-04
Loss = 1.4135e-03, PNorm = 62.0741, GNorm = 0.5182, lr_0 = 3.2596e-04
Validation rmse = 0.950738
Epoch 15
Loss = 1.0901e-03, PNorm = 62.0829, GNorm = 0.9483, lr_0 = 3.1215e-04
Loss = 1.6016e-03, PNorm = 62.0918, GNorm = 1.5998, lr_0 = 2.9893e-04
Validation rmse = 0.931801
Epoch 16
Loss = 1.5425e-03, PNorm = 62.1029, GNorm = 1.9664, lr_0 = 2.8503e-04
Loss = 1.3753e-03, PNorm = 62.1140, GNorm = 0.7665, lr_0 = 2.7295e-04
Validation rmse = 0.955540
Epoch 17
Loss = 1.3423e-03, PNorm = 62.1239, GNorm = 0.5437, lr_0 = 2.6139e-04
Loss = 1.5355e-03, PNorm = 62.1317, GNorm = 0.9739, lr_0 = 2.5032e-04
Validation rmse = 0.928018
Epoch 18
Loss = 1.1371e-03, PNorm = 62.1424, GNorm = 0.3828, lr_0 = 2.3972e-04
Loss = 1.5221e-03, PNorm = 62.1508, GNorm = 0.8121, lr_0 = 2.2956e-04
Validation rmse = 0.883694
Epoch 19
Loss = 1.3407e-03, PNorm = 62.1576, GNorm = 0.9494, lr_0 = 2.1889e-04
Loss = 1.3770e-03, PNorm = 62.1670, GNorm = 0.6720, lr_0 = 2.0962e-04
Validation rmse = 0.981454
Epoch 20
Loss = 1.5186e-03, PNorm = 62.1755, GNorm = 0.7268, lr_0 = 2.0074e-04
Loss = 1.1890e-03, PNorm = 62.1811, GNorm = 0.9600, lr_0 = 1.9224e-04
Validation rmse = 0.914052
Epoch 21
Loss = 9.9194e-04, PNorm = 62.1864, GNorm = 0.8689, lr_0 = 1.8409e-04
Loss = 1.1248e-03, PNorm = 62.1926, GNorm = 0.6102, lr_0 = 1.7630e-04
Validation rmse = 0.918473
Epoch 22
Loss = 1.3767e-03, PNorm = 62.1982, GNorm = 1.8027, lr_0 = 1.6810e-04
Loss = 1.2690e-03, PNorm = 62.2051, GNorm = 2.0995, lr_0 = 1.6098e-04
Validation rmse = 0.905234
Epoch 23
Loss = 1.1969e-03, PNorm = 62.2104, GNorm = 1.2305, lr_0 = 1.5416e-04
Loss = 1.2604e-03, PNorm = 62.2163, GNorm = 0.6508, lr_0 = 1.4763e-04
Loss = 2.0277e-03, PNorm = 62.2170, GNorm = 0.6455, lr_0 = 1.4699e-04
Validation rmse = 0.917831
Epoch 24
Loss = 1.1553e-03, PNorm = 62.2223, GNorm = 0.9533, lr_0 = 1.4077e-04
Loss = 1.1258e-03, PNorm = 62.2277, GNorm = 0.9853, lr_0 = 1.3480e-04
Validation rmse = 0.920638
Epoch 25
Loss = 1.1561e-03, PNorm = 62.2334, GNorm = 0.6160, lr_0 = 1.2909e-04
Loss = 1.0319e-03, PNorm = 62.2380, GNorm = 0.6643, lr_0 = 1.2362e-04
Validation rmse = 0.948437
Epoch 26
Loss = 1.0230e-03, PNorm = 62.2428, GNorm = 0.6566, lr_0 = 1.1839e-04
Validation rmse = 0.888647
Epoch 27
Loss = 7.7564e-04, PNorm = 62.2485, GNorm = 0.7041, lr_0 = 1.1288e-04
Loss = 1.0476e-03, PNorm = 62.2526, GNorm = 1.4574, lr_0 = 1.0810e-04
Validation rmse = 0.894072
Epoch 28
Loss = 1.0165e-03, PNorm = 62.2568, GNorm = 0.4923, lr_0 = 1.0352e-04
Loss = 9.3821e-04, PNorm = 62.2610, GNorm = 0.4088, lr_0 = 1.0000e-04
Validation rmse = 0.896628
Epoch 29
Loss = 1.2220e-03, PNorm = 62.2655, GNorm = 0.9366, lr_0 = 1.0000e-04
Loss = 9.0621e-04, PNorm = 62.2695, GNorm = 0.8964, lr_0 = 1.0000e-04
Validation rmse = 0.887658
Model 0 best validation rmse = 0.883694 on epoch 18
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.194814
Ensemble test rmse = 1.194814
10-fold cross validation
	Seed 0 ==> test rmse = 0.868482
	Seed 1 ==> test rmse = 1.004174
	Seed 2 ==> test rmse = 1.067208
	Seed 3 ==> test rmse = 1.085986
	Seed 4 ==> test rmse = 1.088242
	Seed 5 ==> test rmse = 1.161902
	Seed 6 ==> test rmse = 0.980438
	Seed 7 ==> test rmse = 1.147493
	Seed 8 ==> test rmse = 1.122780
	Seed 9 ==> test rmse = 1.194814
Overall test rmse = 1.072152 +/- 0.092914
Elapsed time = 0:07:36
Fold 0
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 4,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 500,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 500,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_4_dropout_0.25_ffn_num_layers_2_hidden_size_500/fold_0',
 'save_smiles_splits': True,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total scaffolds = 195 | train scaffolds = 91 | val scaffolds = 66 | test scaffolds = 38
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=500, bias=False)
      (W_h): Linear(in_features=500, out_features=500, bias=False)
      (W_o): Linear(in_features=633, out_features=500, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=504, out_features=500, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=500, out_features=1, bias=True)
  )
)
Number of parameters = 893,501
Moving model to cuda
Epoch 0
Loss = 1.4140e-02, PNorm = 42.2985, GNorm = 5.4096, lr_0 = 3.6053e-04
Validation rmse = 2.080914
Epoch 1
Loss = 7.6604e-03, PNorm = 42.3208, GNorm = 6.0917, lr_0 = 6.2105e-04
Loss = 6.9374e-03, PNorm = 42.3520, GNorm = 1.5876, lr_0 = 8.5789e-04
Validation rmse = 1.412237
Epoch 2
Loss = 8.8900e-03, PNorm = 42.3871, GNorm = 3.8158, lr_0 = 9.8284e-04
Loss = 4.7427e-03, PNorm = 42.4171, GNorm = 3.0619, lr_0 = 9.4120e-04
Validation rmse = 1.060202
Epoch 3
Loss = 3.0177e-03, PNorm = 42.4475, GNorm = 0.7855, lr_0 = 8.9744e-04
Loss = 3.9099e-03, PNorm = 42.4658, GNorm = 0.6192, lr_0 = 8.5943e-04
Validation rmse = 1.108010
Epoch 4
Loss = 4.5046e-03, PNorm = 42.4897, GNorm = 1.9118, lr_0 = 8.2303e-04
Loss = 3.9739e-03, PNorm = 42.5088, GNorm = 2.0397, lr_0 = 7.8816e-04
Validation rmse = 1.019128
Epoch 5
Loss = 2.4431e-03, PNorm = 42.5269, GNorm = 1.5705, lr_0 = 7.5478e-04
Loss = 3.4739e-03, PNorm = 42.5454, GNorm = 3.0209, lr_0 = 7.2281e-04
Validation rmse = 0.963249
Epoch 6
Loss = 2.6497e-03, PNorm = 42.5630, GNorm = 1.9020, lr_0 = 6.8920e-04
Loss = 3.3006e-03, PNorm = 42.5815, GNorm = 2.5293, lr_0 = 6.6001e-04
Validation rmse = 1.037203
Epoch 7
Loss = 3.2533e-03, PNorm = 42.5982, GNorm = 3.0909, lr_0 = 6.3205e-04
Loss = 2.9109e-03, PNorm = 42.6110, GNorm = 1.6903, lr_0 = 6.0528e-04
Validation rmse = 1.015733
Epoch 8
Loss = 2.6955e-03, PNorm = 42.6273, GNorm = 0.9979, lr_0 = 5.7714e-04
Loss = 2.7652e-03, PNorm = 42.6423, GNorm = 0.5592, lr_0 = 5.5269e-04
Validation rmse = 1.164597
Epoch 9
Loss = 2.8100e-03, PNorm = 42.6544, GNorm = 1.1295, lr_0 = 5.2928e-04
Loss = 2.8759e-03, PNorm = 42.6710, GNorm = 0.8478, lr_0 = 5.0686e-04
Validation rmse = 0.940867
Epoch 10
Loss = 2.2879e-03, PNorm = 42.6819, GNorm = 2.1958, lr_0 = 4.8539e-04
Loss = 2.5164e-03, PNorm = 42.6950, GNorm = 0.7574, lr_0 = 4.6483e-04
Validation rmse = 1.053448
Epoch 11
Loss = 2.4318e-03, PNorm = 42.7078, GNorm = 0.6042, lr_0 = 4.4322e-04
Loss = 2.4007e-03, PNorm = 42.7166, GNorm = 0.6903, lr_0 = 4.2444e-04
Validation rmse = 0.967344
Epoch 12
Loss = 2.1876e-03, PNorm = 42.7281, GNorm = 1.3818, lr_0 = 4.0646e-04
Loss = 2.2908e-03, PNorm = 42.7353, GNorm = 0.6890, lr_0 = 3.8925e-04
Validation rmse = 1.049825
Epoch 13
Loss = 1.8886e-03, PNorm = 42.7426, GNorm = 0.8328, lr_0 = 3.7276e-04
Loss = 2.1959e-03, PNorm = 42.7491, GNorm = 0.6756, lr_0 = 3.5697e-04
Validation rmse = 1.081225
Epoch 14
Loss = 2.2679e-03, PNorm = 42.7574, GNorm = 0.9496, lr_0 = 3.4037e-04
Loss = 2.1168e-03, PNorm = 42.7658, GNorm = 0.8165, lr_0 = 3.2596e-04
Validation rmse = 1.121056
Epoch 15
Loss = 2.0466e-03, PNorm = 42.7728, GNorm = 0.8496, lr_0 = 3.1215e-04
Loss = 1.8360e-03, PNorm = 42.7808, GNorm = 1.7619, lr_0 = 2.9893e-04
Validation rmse = 1.282560
Epoch 16
Loss = 1.8461e-03, PNorm = 42.7885, GNorm = 1.4045, lr_0 = 2.8503e-04
Loss = 2.0336e-03, PNorm = 42.7956, GNorm = 1.1278, lr_0 = 2.7295e-04
Validation rmse = 1.033352
Epoch 17
Loss = 1.9430e-03, PNorm = 42.8010, GNorm = 0.7600, lr_0 = 2.6139e-04
Loss = 2.1101e-03, PNorm = 42.8065, GNorm = 0.7333, lr_0 = 2.5032e-04
Validation rmse = 0.984970
Epoch 18
Loss = 1.6291e-03, PNorm = 42.8104, GNorm = 0.7843, lr_0 = 2.3972e-04
Loss = 1.9265e-03, PNorm = 42.8159, GNorm = 1.1516, lr_0 = 2.2956e-04
Validation rmse = 1.236775
Epoch 19
Loss = 2.0858e-03, PNorm = 42.8232, GNorm = 2.2379, lr_0 = 2.1889e-04
Loss = 1.9213e-03, PNorm = 42.8276, GNorm = 1.6919, lr_0 = 2.0962e-04
Validation rmse = 1.042915
Epoch 20
Loss = 1.7365e-03, PNorm = 42.8333, GNorm = 1.1391, lr_0 = 2.0074e-04
Loss = 1.7251e-03, PNorm = 42.8378, GNorm = 0.9772, lr_0 = 1.9224e-04
Validation rmse = 1.052636
Epoch 21
Loss = 1.7638e-03, PNorm = 42.8409, GNorm = 1.8124, lr_0 = 1.8409e-04
Loss = 1.9851e-03, PNorm = 42.8448, GNorm = 0.9538, lr_0 = 1.7630e-04
Validation rmse = 0.953849
Epoch 22
Loss = 1.4541e-03, PNorm = 42.8499, GNorm = 0.9288, lr_0 = 1.6810e-04
Loss = 1.8909e-03, PNorm = 42.8533, GNorm = 0.8431, lr_0 = 1.6098e-04
Validation rmse = 0.946835
Epoch 23
Loss = 1.8931e-03, PNorm = 42.8558, GNorm = 1.3180, lr_0 = 1.5416e-04
Loss = 1.6531e-03, PNorm = 42.8592, GNorm = 0.6127, lr_0 = 1.4763e-04
Loss = 2.6082e-03, PNorm = 42.8596, GNorm = 1.7393, lr_0 = 1.4699e-04
Validation rmse = 1.059645
Epoch 24
Loss = 1.6238e-03, PNorm = 42.8625, GNorm = 1.0361, lr_0 = 1.4077e-04
Loss = 1.8129e-03, PNorm = 42.8651, GNorm = 0.7725, lr_0 = 1.3480e-04
Validation rmse = 0.989727
Epoch 25
Loss = 1.6987e-03, PNorm = 42.8681, GNorm = 1.0434, lr_0 = 1.2909e-04
Loss = 1.6306e-03, PNorm = 42.8696, GNorm = 1.6628, lr_0 = 1.2362e-04
Validation rmse = 1.027511
Epoch 26
Loss = 1.5444e-03, PNorm = 42.8720, GNorm = 1.1991, lr_0 = 1.1839e-04
Validation rmse = 0.968527
Epoch 27
Loss = 1.3406e-03, PNorm = 42.8756, GNorm = 1.6224, lr_0 = 1.1288e-04
Loss = 1.9335e-03, PNorm = 42.8776, GNorm = 1.6837, lr_0 = 1.0810e-04
Validation rmse = 0.977319
Epoch 28
Loss = 1.6764e-03, PNorm = 42.8794, GNorm = 0.6097, lr_0 = 1.0352e-04
Loss = 1.4986e-03, PNorm = 42.8813, GNorm = 0.7698, lr_0 = 1.0000e-04
Validation rmse = 0.954900
Epoch 29
Loss = 1.7110e-03, PNorm = 42.8831, GNorm = 0.8145, lr_0 = 1.0000e-04
Loss = 1.6411e-03, PNorm = 42.8856, GNorm = 0.8588, lr_0 = 1.0000e-04
Validation rmse = 0.965536
Model 0 best validation rmse = 0.940867 on epoch 9
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.079114
Ensemble test rmse = 1.079114
Fold 1
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 4,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 500,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 500,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_4_dropout_0.25_ffn_num_layers_2_hidden_size_500/fold_1',
 'save_smiles_splits': True,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total scaffolds = 195 | train scaffolds = 76 | val scaffolds = 60 | test scaffolds = 59
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=500, bias=False)
      (W_h): Linear(in_features=500, out_features=500, bias=False)
      (W_o): Linear(in_features=633, out_features=500, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=504, out_features=500, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=500, out_features=1, bias=True)
  )
)
Number of parameters = 893,501
Moving model to cuda
Epoch 0
Loss = 1.5235e-02, PNorm = 42.2994, GNorm = 3.0585, lr_0 = 3.6053e-04
Validation rmse = 1.501074
Epoch 1
Loss = 7.5018e-03, PNorm = 42.3248, GNorm = 3.4255, lr_0 = 6.2105e-04
Loss = 6.3918e-03, PNorm = 42.3562, GNorm = 4.6149, lr_0 = 8.5789e-04
Validation rmse = 1.206562
Epoch 2
Loss = 5.2823e-03, PNorm = 42.3946, GNorm = 2.0000, lr_0 = 9.8284e-04
Loss = 4.4163e-03, PNorm = 42.4251, GNorm = 2.0191, lr_0 = 9.4120e-04
Validation rmse = 1.143656
Epoch 3
Loss = 4.1585e-03, PNorm = 42.4535, GNorm = 4.8669, lr_0 = 8.9744e-04
Loss = 4.0983e-03, PNorm = 42.4772, GNorm = 1.6268, lr_0 = 8.5943e-04
Validation rmse = 1.084989
Epoch 4
Loss = 2.3744e-03, PNorm = 42.4984, GNorm = 1.2809, lr_0 = 8.2303e-04
Loss = 3.2482e-03, PNorm = 42.5178, GNorm = 1.2564, lr_0 = 7.8816e-04
Validation rmse = 1.118926
Epoch 5
Loss = 3.3898e-03, PNorm = 42.5308, GNorm = 1.1632, lr_0 = 7.5478e-04
Loss = 3.2595e-03, PNorm = 42.5506, GNorm = 1.0873, lr_0 = 7.2281e-04
Validation rmse = 1.098867
Epoch 6
Loss = 2.6389e-03, PNorm = 42.5675, GNorm = 1.8944, lr_0 = 6.8920e-04
Loss = 2.8306e-03, PNorm = 42.5848, GNorm = 1.3555, lr_0 = 6.6001e-04
Validation rmse = 1.051476
Epoch 7
Loss = 2.7128e-03, PNorm = 42.6001, GNorm = 2.0881, lr_0 = 6.3205e-04
Loss = 2.7872e-03, PNorm = 42.6141, GNorm = 1.0620, lr_0 = 6.0528e-04
Validation rmse = 1.174462
Epoch 8
Loss = 2.8652e-03, PNorm = 42.6317, GNorm = 0.7202, lr_0 = 5.7714e-04
Loss = 2.5113e-03, PNorm = 42.6465, GNorm = 2.1594, lr_0 = 5.5269e-04
Validation rmse = 1.013693
Epoch 9
Loss = 2.1138e-03, PNorm = 42.6606, GNorm = 2.0617, lr_0 = 5.2928e-04
Loss = 2.6509e-03, PNorm = 42.6726, GNorm = 2.1181, lr_0 = 5.0686e-04
Validation rmse = 1.202675
Epoch 10
Loss = 2.4942e-03, PNorm = 42.6828, GNorm = 0.6916, lr_0 = 4.8539e-04
Loss = 2.1287e-03, PNorm = 42.6956, GNorm = 2.2306, lr_0 = 4.6483e-04
Validation rmse = 1.006900
Epoch 11
Loss = 2.3783e-03, PNorm = 42.7077, GNorm = 1.1122, lr_0 = 4.4322e-04
Loss = 2.5054e-03, PNorm = 42.7176, GNorm = 0.7308, lr_0 = 4.2444e-04
Validation rmse = 0.977191
Epoch 12
Loss = 1.8951e-03, PNorm = 42.7278, GNorm = 1.0097, lr_0 = 4.0646e-04
Loss = 2.3656e-03, PNorm = 42.7340, GNorm = 2.0669, lr_0 = 3.8925e-04
Validation rmse = 0.946447
Epoch 13
Loss = 2.3373e-03, PNorm = 42.7433, GNorm = 1.0599, lr_0 = 3.7276e-04
Loss = 2.0104e-03, PNorm = 42.7505, GNorm = 0.7952, lr_0 = 3.5697e-04
Validation rmse = 0.990961
Epoch 14
Loss = 2.1026e-03, PNorm = 42.7588, GNorm = 2.5265, lr_0 = 3.4037e-04
Loss = 2.0535e-03, PNorm = 42.7700, GNorm = 0.9940, lr_0 = 3.2596e-04
Validation rmse = 0.993405
Epoch 15
Loss = 2.3295e-03, PNorm = 42.7756, GNorm = 1.0597, lr_0 = 3.1215e-04
Loss = 1.8605e-03, PNorm = 42.7820, GNorm = 1.6116, lr_0 = 2.9893e-04
Validation rmse = 0.974823
Epoch 16
Loss = 2.0202e-03, PNorm = 42.7885, GNorm = 0.5588, lr_0 = 2.8503e-04
Loss = 1.9736e-03, PNorm = 42.7936, GNorm = 0.8699, lr_0 = 2.7295e-04
Validation rmse = 1.018217
Epoch 17
Loss = 1.7813e-03, PNorm = 42.7997, GNorm = 0.8851, lr_0 = 2.6139e-04
Loss = 1.7455e-03, PNorm = 42.8065, GNorm = 1.1838, lr_0 = 2.5032e-04
Validation rmse = 1.000522
Epoch 18
Loss = 1.9105e-03, PNorm = 42.8097, GNorm = 2.5890, lr_0 = 2.3972e-04
Loss = 1.6788e-03, PNorm = 42.8149, GNorm = 1.2903, lr_0 = 2.2956e-04
Validation rmse = 0.958992
Epoch 19
Loss = 1.2592e-03, PNorm = 42.8196, GNorm = 0.6421, lr_0 = 2.1889e-04
Loss = 1.9562e-03, PNorm = 42.8226, GNorm = 0.7055, lr_0 = 2.0962e-04
Validation rmse = 1.027550
Epoch 20
Loss = 1.5599e-03, PNorm = 42.8270, GNorm = 0.7929, lr_0 = 2.0074e-04
Loss = 1.8713e-03, PNorm = 42.8314, GNorm = 0.5040, lr_0 = 1.9224e-04
Validation rmse = 0.953422
Epoch 21
Loss = 1.5159e-03, PNorm = 42.8346, GNorm = 1.1841, lr_0 = 1.8409e-04
Loss = 2.0716e-03, PNorm = 42.8372, GNorm = 1.7671, lr_0 = 1.7630e-04
Validation rmse = 1.063571
Epoch 22
Loss = 1.9699e-03, PNorm = 42.8415, GNorm = 0.9367, lr_0 = 1.6810e-04
Loss = 1.5761e-03, PNorm = 42.8450, GNorm = 2.1618, lr_0 = 1.6098e-04
Validation rmse = 0.997385
Epoch 23
Loss = 1.7479e-03, PNorm = 42.8484, GNorm = 1.4265, lr_0 = 1.5416e-04
Loss = 1.5657e-03, PNorm = 42.8510, GNorm = 0.5908, lr_0 = 1.4763e-04
Loss = 1.7838e-03, PNorm = 42.8513, GNorm = 1.0499, lr_0 = 1.4699e-04
Validation rmse = 0.971499
Epoch 24
Loss = 1.7495e-03, PNorm = 42.8543, GNorm = 0.8282, lr_0 = 1.4077e-04
Loss = 1.5160e-03, PNorm = 42.8557, GNorm = 1.0407, lr_0 = 1.3480e-04
Validation rmse = 1.029204
Epoch 25
Loss = 1.8162e-03, PNorm = 42.8587, GNorm = 1.0072, lr_0 = 1.2909e-04
Loss = 1.7416e-03, PNorm = 42.8623, GNorm = 0.8754, lr_0 = 1.2362e-04
Validation rmse = 0.974660
Epoch 26
Loss = 1.6827e-03, PNorm = 42.8642, GNorm = 1.8226, lr_0 = 1.1839e-04
Validation rmse = 0.969234
Epoch 27
Loss = 1.2636e-03, PNorm = 42.8678, GNorm = 1.6147, lr_0 = 1.1288e-04
Loss = 1.4978e-03, PNorm = 42.8686, GNorm = 0.5659, lr_0 = 1.0810e-04
Validation rmse = 0.979076
Epoch 28
Loss = 1.1320e-03, PNorm = 42.8712, GNorm = 0.4735, lr_0 = 1.0352e-04
Loss = 1.5115e-03, PNorm = 42.8736, GNorm = 0.7808, lr_0 = 1.0000e-04
Validation rmse = 0.982143
Epoch 29
Loss = 1.2734e-03, PNorm = 42.8750, GNorm = 0.8275, lr_0 = 1.0000e-04
Loss = 1.7102e-03, PNorm = 42.8782, GNorm = 0.8093, lr_0 = 1.0000e-04
Validation rmse = 0.987797
Model 0 best validation rmse = 0.946447 on epoch 12
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.016801
Ensemble test rmse = 1.016801
Fold 2
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 4,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 500,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 500,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_4_dropout_0.25_ffn_num_layers_2_hidden_size_500/fold_2',
 'save_smiles_splits': True,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total scaffolds = 195 | train scaffolds = 55 | val scaffolds = 64 | test scaffolds = 76
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=500, bias=False)
      (W_h): Linear(in_features=500, out_features=500, bias=False)
      (W_o): Linear(in_features=633, out_features=500, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=504, out_features=500, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=500, out_features=1, bias=True)
  )
)
Number of parameters = 893,501
Moving model to cuda
Epoch 0
Loss = 1.5651e-02, PNorm = 42.2986, GNorm = 2.9598, lr_0 = 3.6053e-04
Validation rmse = 1.428640
Epoch 1
Loss = 5.8396e-03, PNorm = 42.3203, GNorm = 1.9296, lr_0 = 6.2105e-04
Loss = 6.6611e-03, PNorm = 42.3524, GNorm = 1.8504, lr_0 = 8.5789e-04
Validation rmse = 1.325430
Epoch 2
Loss = 3.7581e-03, PNorm = 42.3844, GNorm = 2.0150, lr_0 = 9.8284e-04
Loss = 5.9528e-03, PNorm = 42.4092, GNorm = 2.8915, lr_0 = 9.4120e-04
Validation rmse = 1.187503
Epoch 3
Loss = 4.2451e-03, PNorm = 42.4380, GNorm = 1.5478, lr_0 = 8.9744e-04
Loss = 4.1092e-03, PNorm = 42.4590, GNorm = 0.9264, lr_0 = 8.5943e-04
Validation rmse = 1.446883
Epoch 4
Loss = 3.6100e-03, PNorm = 42.4763, GNorm = 2.1165, lr_0 = 8.2303e-04
Loss = 4.9027e-03, PNorm = 42.5014, GNorm = 2.6835, lr_0 = 7.8816e-04
Validation rmse = 1.332449
Epoch 5
Loss = 3.1435e-03, PNorm = 42.5197, GNorm = 1.2835, lr_0 = 7.5478e-04
Loss = 3.3710e-03, PNorm = 42.5383, GNorm = 1.7451, lr_0 = 7.2281e-04
Validation rmse = 1.278127
Epoch 6
Loss = 3.5810e-03, PNorm = 42.5590, GNorm = 0.7210, lr_0 = 6.8920e-04
Loss = 3.6947e-03, PNorm = 42.5748, GNorm = 1.2260, lr_0 = 6.6001e-04
Validation rmse = 1.135472
Epoch 7
Loss = 4.2560e-03, PNorm = 42.5960, GNorm = 2.3227, lr_0 = 6.3205e-04
Loss = 3.3797e-03, PNorm = 42.6102, GNorm = 1.1185, lr_0 = 6.0528e-04
Validation rmse = 1.095628
Epoch 8
Loss = 3.3358e-03, PNorm = 42.6306, GNorm = 1.0159, lr_0 = 5.7714e-04
Loss = 2.6798e-03, PNorm = 42.6484, GNorm = 1.0673, lr_0 = 5.5269e-04
Validation rmse = 1.061379
Epoch 9
Loss = 2.7143e-03, PNorm = 42.6585, GNorm = 0.8689, lr_0 = 5.2928e-04
Loss = 2.3813e-03, PNorm = 42.6744, GNorm = 0.5957, lr_0 = 5.0686e-04
Validation rmse = 1.044513
Epoch 10
Loss = 2.3300e-03, PNorm = 42.6871, GNorm = 0.7604, lr_0 = 4.8539e-04
Loss = 2.7415e-03, PNorm = 42.6975, GNorm = 0.7895, lr_0 = 4.6483e-04
Validation rmse = 1.043001
Epoch 11
Loss = 2.8530e-03, PNorm = 42.7119, GNorm = 3.6796, lr_0 = 4.4322e-04
Loss = 2.4849e-03, PNorm = 42.7220, GNorm = 0.8335, lr_0 = 4.2444e-04
Validation rmse = 1.097541
Epoch 12
Loss = 2.0914e-03, PNorm = 42.7339, GNorm = 2.0825, lr_0 = 4.0646e-04
Loss = 2.0806e-03, PNorm = 42.7430, GNorm = 0.9637, lr_0 = 3.8925e-04
Validation rmse = 1.029870
Epoch 13
Loss = 2.1537e-03, PNorm = 42.7532, GNorm = 1.1231, lr_0 = 3.7276e-04
Loss = 2.2065e-03, PNorm = 42.7607, GNorm = 0.8747, lr_0 = 3.5697e-04
Validation rmse = 1.060095
Epoch 14
Loss = 2.6736e-03, PNorm = 42.7656, GNorm = 1.0088, lr_0 = 3.4037e-04
Loss = 2.4906e-03, PNorm = 42.7765, GNorm = 2.7529, lr_0 = 3.2596e-04
Validation rmse = 1.057272
Epoch 15
Loss = 1.9504e-03, PNorm = 42.7840, GNorm = 0.7003, lr_0 = 3.1215e-04
Loss = 2.0905e-03, PNorm = 42.7891, GNorm = 1.4930, lr_0 = 2.9893e-04
Validation rmse = 1.082354
Epoch 16
Loss = 2.1682e-03, PNorm = 42.7980, GNorm = 0.6958, lr_0 = 2.8503e-04
Loss = 2.3879e-03, PNorm = 42.8037, GNorm = 2.3116, lr_0 = 2.7295e-04
Validation rmse = 1.087099
Epoch 17
Loss = 2.4337e-03, PNorm = 42.8113, GNorm = 2.3700, lr_0 = 2.6139e-04
Loss = 2.0768e-03, PNorm = 42.8188, GNorm = 3.0697, lr_0 = 2.5032e-04
Validation rmse = 1.124844
Epoch 18
Loss = 2.2713e-03, PNorm = 42.8267, GNorm = 1.2090, lr_0 = 2.3972e-04
Loss = 2.1033e-03, PNorm = 42.8325, GNorm = 1.2800, lr_0 = 2.2956e-04
Validation rmse = 1.041904
Epoch 19
Loss = 2.5101e-03, PNorm = 42.8390, GNorm = 1.5434, lr_0 = 2.1889e-04
Loss = 1.8761e-03, PNorm = 42.8457, GNorm = 0.7855, lr_0 = 2.0962e-04
Validation rmse = 1.031579
Epoch 20
Loss = 1.9209e-03, PNorm = 42.8486, GNorm = 0.8542, lr_0 = 2.0074e-04
Loss = 2.0316e-03, PNorm = 42.8540, GNorm = 1.2034, lr_0 = 1.9224e-04
Validation rmse = 1.049146
Epoch 21
Loss = 2.1376e-03, PNorm = 42.8564, GNorm = 1.4288, lr_0 = 1.8409e-04
Loss = 1.7313e-03, PNorm = 42.8615, GNorm = 0.6030, lr_0 = 1.7630e-04
Validation rmse = 1.065496
Epoch 22
Loss = 1.8470e-03, PNorm = 42.8654, GNorm = 0.6705, lr_0 = 1.6810e-04
Loss = 1.8828e-03, PNorm = 42.8669, GNorm = 0.8635, lr_0 = 1.6098e-04
Validation rmse = 1.056528
Epoch 23
Loss = 1.6890e-03, PNorm = 42.8711, GNorm = 1.3896, lr_0 = 1.5416e-04
Loss = 1.8113e-03, PNorm = 42.8760, GNorm = 1.5724, lr_0 = 1.4763e-04
Loss = 3.1256e-03, PNorm = 42.8762, GNorm = 1.8805, lr_0 = 1.4699e-04
Validation rmse = 1.036364
Epoch 24
Loss = 1.7526e-03, PNorm = 42.8794, GNorm = 2.7424, lr_0 = 1.4077e-04
Loss = 1.8618e-03, PNorm = 42.8824, GNorm = 0.6631, lr_0 = 1.3480e-04
Validation rmse = 1.052625
Epoch 25
Loss = 1.9674e-03, PNorm = 42.8853, GNorm = 1.2706, lr_0 = 1.2909e-04
Loss = 1.4607e-03, PNorm = 42.8879, GNorm = 1.3324, lr_0 = 1.2362e-04
Validation rmse = 1.040122
Epoch 26
Loss = 1.9367e-03, PNorm = 42.8910, GNorm = 0.9279, lr_0 = 1.1839e-04
Validation rmse = 1.068317
Epoch 27
Loss = 2.0646e-03, PNorm = 42.8938, GNorm = 1.6206, lr_0 = 1.1288e-04
Loss = 1.7840e-03, PNorm = 42.8959, GNorm = 1.6948, lr_0 = 1.0810e-04
Validation rmse = 1.043158
Epoch 28
Loss = 1.0661e-03, PNorm = 42.8984, GNorm = 1.1051, lr_0 = 1.0352e-04
Loss = 1.6004e-03, PNorm = 42.9004, GNorm = 0.6425, lr_0 = 1.0000e-04
Validation rmse = 1.067344
Epoch 29
Loss = 1.7635e-03, PNorm = 42.9031, GNorm = 0.8522, lr_0 = 1.0000e-04
Loss = 1.7340e-03, PNorm = 42.9042, GNorm = 0.9746, lr_0 = 1.0000e-04
Validation rmse = 1.069673
Model 0 best validation rmse = 1.029870 on epoch 12
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.028035
Ensemble test rmse = 1.028035
Fold 3
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 4,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 500,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 500,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_4_dropout_0.25_ffn_num_layers_2_hidden_size_500/fold_3',
 'save_smiles_splits': True,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total scaffolds = 195 | train scaffolds = 80 | val scaffolds = 54 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=500, bias=False)
      (W_h): Linear(in_features=500, out_features=500, bias=False)
      (W_o): Linear(in_features=633, out_features=500, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=504, out_features=500, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=500, out_features=1, bias=True)
  )
)
Number of parameters = 893,501
Moving model to cuda
Epoch 0
Loss = 1.5067e-02, PNorm = 42.3009, GNorm = 5.2412, lr_0 = 3.6053e-04
Validation rmse = 1.431036
Epoch 1
Loss = 8.5659e-03, PNorm = 42.3234, GNorm = 5.9320, lr_0 = 6.2105e-04
Loss = 6.3362e-03, PNorm = 42.3544, GNorm = 2.2009, lr_0 = 8.5789e-04
Validation rmse = 1.155070
Epoch 2
Loss = 4.5241e-03, PNorm = 42.3920, GNorm = 1.3629, lr_0 = 9.8284e-04
Loss = 4.2720e-03, PNorm = 42.4227, GNorm = 1.2607, lr_0 = 9.4120e-04
Validation rmse = 1.328361
Epoch 3
Loss = 5.3703e-03, PNorm = 42.4504, GNorm = 0.9810, lr_0 = 8.9744e-04
Loss = 4.0668e-03, PNorm = 42.4746, GNorm = 1.5997, lr_0 = 8.5943e-04
Validation rmse = 1.290319
Epoch 4
Loss = 5.2198e-03, PNorm = 42.4976, GNorm = 6.1773, lr_0 = 8.2303e-04
Loss = 4.5802e-03, PNorm = 42.5185, GNorm = 2.3497, lr_0 = 7.8816e-04
Validation rmse = 1.282726
Epoch 5
Loss = 4.1759e-03, PNorm = 42.5430, GNorm = 2.3327, lr_0 = 7.5478e-04
Loss = 3.1028e-03, PNorm = 42.5662, GNorm = 1.7264, lr_0 = 7.2281e-04
Validation rmse = 1.122127
Epoch 6
Loss = 2.4048e-03, PNorm = 42.5868, GNorm = 1.3468, lr_0 = 6.8920e-04
Loss = 2.9035e-03, PNorm = 42.6008, GNorm = 1.2963, lr_0 = 6.6001e-04
Validation rmse = 1.098567
Epoch 7
Loss = 2.6791e-03, PNorm = 42.6181, GNorm = 1.5128, lr_0 = 6.3205e-04
Loss = 2.5215e-03, PNorm = 42.6315, GNorm = 0.7936, lr_0 = 6.0528e-04
Validation rmse = 1.110562
Epoch 8
Loss = 2.5430e-03, PNorm = 42.6509, GNorm = 1.8810, lr_0 = 5.7714e-04
Loss = 2.2714e-03, PNorm = 42.6667, GNorm = 1.9713, lr_0 = 5.5269e-04
Validation rmse = 1.287680
Epoch 9
Loss = 3.0253e-03, PNorm = 42.6816, GNorm = 1.3046, lr_0 = 5.2928e-04
Loss = 2.3518e-03, PNorm = 42.6971, GNorm = 0.6753, lr_0 = 5.0686e-04
Validation rmse = 1.091121
Epoch 10
Loss = 2.2687e-03, PNorm = 42.7097, GNorm = 0.6612, lr_0 = 4.8539e-04
Loss = 2.4373e-03, PNorm = 42.7212, GNorm = 1.1551, lr_0 = 4.6483e-04
Validation rmse = 1.074889
Epoch 11
Loss = 2.1821e-03, PNorm = 42.7326, GNorm = 0.5295, lr_0 = 4.4322e-04
Loss = 2.3934e-03, PNorm = 42.7449, GNorm = 0.6998, lr_0 = 4.2444e-04
Validation rmse = 1.191925
Epoch 12
Loss = 2.4180e-03, PNorm = 42.7557, GNorm = 2.4144, lr_0 = 4.0646e-04
Loss = 2.0023e-03, PNorm = 42.7651, GNorm = 1.4602, lr_0 = 3.8925e-04
Validation rmse = 1.078705
Epoch 13
Loss = 2.1028e-03, PNorm = 42.7772, GNorm = 1.2976, lr_0 = 3.7276e-04
Loss = 2.2285e-03, PNorm = 42.7855, GNorm = 1.7063, lr_0 = 3.5697e-04
Validation rmse = 1.050281
Epoch 14
Loss = 2.0225e-03, PNorm = 42.7961, GNorm = 2.8620, lr_0 = 3.4037e-04
Loss = 1.9821e-03, PNorm = 42.8036, GNorm = 1.1422, lr_0 = 3.2596e-04
Validation rmse = 1.281161
Epoch 15
Loss = 1.5788e-03, PNorm = 42.8124, GNorm = 1.4416, lr_0 = 3.1215e-04
Loss = 2.2951e-03, PNorm = 42.8174, GNorm = 1.8297, lr_0 = 2.9893e-04
Validation rmse = 1.071226
Epoch 16
Loss = 1.6228e-03, PNorm = 42.8260, GNorm = 1.8082, lr_0 = 2.8503e-04
Loss = 1.9227e-03, PNorm = 42.8322, GNorm = 0.7979, lr_0 = 2.7295e-04
Validation rmse = 1.056896
Epoch 17
Loss = 1.5196e-03, PNorm = 42.8393, GNorm = 0.6378, lr_0 = 2.6139e-04
Loss = 1.6863e-03, PNorm = 42.8451, GNorm = 0.9895, lr_0 = 2.5032e-04
Validation rmse = 1.070878
Epoch 18
Loss = 1.7272e-03, PNorm = 42.8504, GNorm = 1.8380, lr_0 = 2.3972e-04
Loss = 1.7258e-03, PNorm = 42.8578, GNorm = 0.5521, lr_0 = 2.2956e-04
Validation rmse = 1.042801
Epoch 19
Loss = 2.0917e-03, PNorm = 42.8631, GNorm = 0.7820, lr_0 = 2.1889e-04
Loss = 1.4404e-03, PNorm = 42.8698, GNorm = 0.7221, lr_0 = 2.0962e-04
Validation rmse = 1.020106
Epoch 20
Loss = 1.7500e-03, PNorm = 42.8720, GNorm = 0.6971, lr_0 = 2.0074e-04
Loss = 1.8163e-03, PNorm = 42.8768, GNorm = 1.9816, lr_0 = 1.9224e-04
Validation rmse = 1.032071
Epoch 21
Loss = 1.5291e-03, PNorm = 42.8809, GNorm = 1.0610, lr_0 = 1.8409e-04
Loss = 1.6844e-03, PNorm = 42.8836, GNorm = 1.8073, lr_0 = 1.7630e-04
Validation rmse = 1.053059
Epoch 22
Loss = 1.5804e-03, PNorm = 42.8886, GNorm = 0.9899, lr_0 = 1.6810e-04
Loss = 1.5531e-03, PNorm = 42.8922, GNorm = 1.0148, lr_0 = 1.6098e-04
Validation rmse = 1.082667
Epoch 23
Loss = 1.7444e-03, PNorm = 42.8957, GNorm = 2.4575, lr_0 = 1.5416e-04
Loss = 1.5775e-03, PNorm = 42.8985, GNorm = 1.1711, lr_0 = 1.4763e-04
Loss = 2.7641e-03, PNorm = 42.8990, GNorm = 1.6910, lr_0 = 1.4699e-04
Validation rmse = 1.101017
Epoch 24
Loss = 1.4918e-03, PNorm = 42.9017, GNorm = 1.2374, lr_0 = 1.4077e-04
Loss = 1.5468e-03, PNorm = 42.9044, GNorm = 0.6235, lr_0 = 1.3480e-04
Validation rmse = 1.062825
Epoch 25
Loss = 1.4077e-03, PNorm = 42.9070, GNorm = 1.1539, lr_0 = 1.2909e-04
Loss = 1.5843e-03, PNorm = 42.9086, GNorm = 1.6829, lr_0 = 1.2362e-04
Validation rmse = 1.045128
Epoch 26
Loss = 1.5459e-03, PNorm = 42.9098, GNorm = 1.2674, lr_0 = 1.1839e-04
Validation rmse = 1.057089
Epoch 27
Loss = 1.9596e-03, PNorm = 42.9136, GNorm = 0.8207, lr_0 = 1.1288e-04
Loss = 1.3936e-03, PNorm = 42.9159, GNorm = 0.9320, lr_0 = 1.0810e-04
Validation rmse = 1.096889
Epoch 28
Loss = 1.8777e-03, PNorm = 42.9173, GNorm = 1.0702, lr_0 = 1.0352e-04
Loss = 1.3853e-03, PNorm = 42.9199, GNorm = 0.7188, lr_0 = 1.0000e-04
Validation rmse = 1.060769
Epoch 29
Loss = 1.3796e-03, PNorm = 42.9217, GNorm = 0.4467, lr_0 = 1.0000e-04
Loss = 1.2783e-03, PNorm = 42.9234, GNorm = 1.2136, lr_0 = 1.0000e-04
Validation rmse = 1.088617
Model 0 best validation rmse = 1.020106 on epoch 19
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.061967
Ensemble test rmse = 1.061967
Fold 4
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 4,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 500,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 500,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_4_dropout_0.25_ffn_num_layers_2_hidden_size_500/fold_4',
 'save_smiles_splits': True,
 'seed': 4,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 4
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 49 | test scaffolds = 62
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=500, bias=False)
      (W_h): Linear(in_features=500, out_features=500, bias=False)
      (W_o): Linear(in_features=633, out_features=500, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=504, out_features=500, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=500, out_features=1, bias=True)
  )
)
Number of parameters = 893,501
Moving model to cuda
Epoch 0
Loss = 1.4359e-02, PNorm = 42.3002, GNorm = 3.1190, lr_0 = 3.6053e-04
Validation rmse = 1.262087
Epoch 1
Loss = 6.7894e-03, PNorm = 42.3241, GNorm = 4.5128, lr_0 = 6.2105e-04
Loss = 6.7818e-03, PNorm = 42.3558, GNorm = 3.6861, lr_0 = 8.5789e-04
Validation rmse = 1.139960
Epoch 2
Loss = 5.2169e-03, PNorm = 42.3903, GNorm = 1.3761, lr_0 = 9.8284e-04
Loss = 4.2502e-03, PNorm = 42.4204, GNorm = 1.1446, lr_0 = 9.4120e-04
Validation rmse = 1.153493
Epoch 3
Loss = 3.6343e-03, PNorm = 42.4404, GNorm = 0.8360, lr_0 = 8.9744e-04
Loss = 3.8669e-03, PNorm = 42.4668, GNorm = 0.9166, lr_0 = 8.5943e-04
Validation rmse = 1.074415
Epoch 4
Loss = 4.5778e-03, PNorm = 42.4846, GNorm = 3.0624, lr_0 = 8.2303e-04
Loss = 3.6171e-03, PNorm = 42.5036, GNorm = 0.9447, lr_0 = 7.8816e-04
Validation rmse = 0.891189
Epoch 5
Loss = 2.9290e-03, PNorm = 42.5207, GNorm = 1.2507, lr_0 = 7.5478e-04
Loss = 2.9886e-03, PNorm = 42.5378, GNorm = 1.4794, lr_0 = 7.2281e-04
Validation rmse = 0.975726
Epoch 6
Loss = 3.1223e-03, PNorm = 42.5572, GNorm = 1.8339, lr_0 = 6.8920e-04
Loss = 3.6444e-03, PNorm = 42.5727, GNorm = 1.1608, lr_0 = 6.6001e-04
Validation rmse = 1.010362
Epoch 7
Loss = 2.4218e-03, PNorm = 42.5882, GNorm = 1.0654, lr_0 = 6.3205e-04
Loss = 3.6930e-03, PNorm = 42.6037, GNorm = 1.4681, lr_0 = 6.0528e-04
Validation rmse = 1.020392
Epoch 8
Loss = 2.9305e-03, PNorm = 42.6184, GNorm = 3.3350, lr_0 = 5.7714e-04
Loss = 2.7210e-03, PNorm = 42.6326, GNorm = 0.8692, lr_0 = 5.5269e-04
Validation rmse = 1.013031
Epoch 9
Loss = 2.3747e-03, PNorm = 42.6447, GNorm = 0.9777, lr_0 = 5.2928e-04
Loss = 2.3165e-03, PNorm = 42.6569, GNorm = 0.6898, lr_0 = 5.0686e-04
Validation rmse = 1.066120
Epoch 10
Loss = 3.3939e-03, PNorm = 42.6665, GNorm = 3.9551, lr_0 = 4.8539e-04
Loss = 3.2527e-03, PNorm = 42.6800, GNorm = 2.7250, lr_0 = 4.6483e-04
Validation rmse = 1.031015
Epoch 11
Loss = 2.2438e-03, PNorm = 42.6921, GNorm = 1.8207, lr_0 = 4.4322e-04
Loss = 2.2431e-03, PNorm = 42.7034, GNorm = 1.7447, lr_0 = 4.2444e-04
Validation rmse = 1.107056
Epoch 12
Loss = 1.9395e-03, PNorm = 42.7123, GNorm = 0.8903, lr_0 = 4.0646e-04
Loss = 2.3790e-03, PNorm = 42.7218, GNorm = 0.7223, lr_0 = 3.8925e-04
Validation rmse = 1.073575
Epoch 13
Loss = 2.0845e-03, PNorm = 42.7317, GNorm = 1.5087, lr_0 = 3.7276e-04
Loss = 2.5041e-03, PNorm = 42.7410, GNorm = 1.8893, lr_0 = 3.5697e-04
Validation rmse = 1.073149
Epoch 14
Loss = 1.8446e-03, PNorm = 42.7491, GNorm = 0.5321, lr_0 = 3.4037e-04
Loss = 2.1675e-03, PNorm = 42.7576, GNorm = 1.3525, lr_0 = 3.2596e-04
Validation rmse = 0.920279
Epoch 15
Loss = 1.9499e-03, PNorm = 42.7634, GNorm = 0.5874, lr_0 = 3.1215e-04
Loss = 2.0798e-03, PNorm = 42.7702, GNorm = 1.1346, lr_0 = 2.9893e-04
Validation rmse = 0.908939
Epoch 16
Loss = 2.0169e-03, PNorm = 42.7798, GNorm = 2.4325, lr_0 = 2.8503e-04
Loss = 2.1325e-03, PNorm = 42.7860, GNorm = 0.7421, lr_0 = 2.7295e-04
Validation rmse = 0.908191
Epoch 17
Loss = 1.6726e-03, PNorm = 42.7926, GNorm = 0.7069, lr_0 = 2.6139e-04
Loss = 2.1737e-03, PNorm = 42.7958, GNorm = 1.1333, lr_0 = 2.5032e-04
Validation rmse = 0.956788
Epoch 18
Loss = 2.1222e-03, PNorm = 42.8029, GNorm = 1.1902, lr_0 = 2.3972e-04
Loss = 1.9397e-03, PNorm = 42.8074, GNorm = 1.1929, lr_0 = 2.2956e-04
Validation rmse = 1.040613
Epoch 19
Loss = 1.9715e-03, PNorm = 42.8132, GNorm = 1.5250, lr_0 = 2.1889e-04
Loss = 2.1685e-03, PNorm = 42.8182, GNorm = 2.9261, lr_0 = 2.0962e-04
Validation rmse = 1.050299
Epoch 20
Loss = 1.8294e-03, PNorm = 42.8225, GNorm = 0.7381, lr_0 = 2.0074e-04
Loss = 1.5816e-03, PNorm = 42.8245, GNorm = 2.0303, lr_0 = 1.9224e-04
Validation rmse = 0.986928
Epoch 21
Loss = 1.7046e-03, PNorm = 42.8293, GNorm = 1.9257, lr_0 = 1.8409e-04
Loss = 1.8579e-03, PNorm = 42.8328, GNorm = 1.9076, lr_0 = 1.7630e-04
Validation rmse = 0.956974
Epoch 22
Loss = 1.7175e-03, PNorm = 42.8365, GNorm = 0.8487, lr_0 = 1.6810e-04
Loss = 1.9510e-03, PNorm = 42.8384, GNorm = 0.6207, lr_0 = 1.6098e-04
Validation rmse = 1.007285
Epoch 23
Loss = 1.5034e-03, PNorm = 42.8415, GNorm = 0.5000, lr_0 = 1.5416e-04
Loss = 1.5362e-03, PNorm = 42.8440, GNorm = 0.7182, lr_0 = 1.4763e-04
Loss = 3.0014e-03, PNorm = 42.8444, GNorm = 0.9444, lr_0 = 1.4699e-04
Validation rmse = 0.952217
Epoch 24
Loss = 1.6797e-03, PNorm = 42.8472, GNorm = 1.2794, lr_0 = 1.4077e-04
Loss = 1.8850e-03, PNorm = 42.8500, GNorm = 1.0658, lr_0 = 1.3480e-04
Validation rmse = 0.996368
Epoch 25
Loss = 1.4213e-03, PNorm = 42.8534, GNorm = 0.6599, lr_0 = 1.2909e-04
Loss = 1.8639e-03, PNorm = 42.8551, GNorm = 2.1138, lr_0 = 1.2362e-04
Validation rmse = 0.956912
Epoch 26
Loss = 1.5887e-03, PNorm = 42.8574, GNorm = 0.6370, lr_0 = 1.1839e-04
Validation rmse = 0.864803
Epoch 27
Loss = 1.5284e-03, PNorm = 42.8617, GNorm = 1.8495, lr_0 = 1.1288e-04
Loss = 1.7019e-03, PNorm = 42.8629, GNorm = 1.0497, lr_0 = 1.0810e-04
Validation rmse = 0.883235
Epoch 28
Loss = 7.4646e-04, PNorm = 42.8645, GNorm = 0.4331, lr_0 = 1.0352e-04
Loss = 1.6878e-03, PNorm = 42.8662, GNorm = 0.7459, lr_0 = 1.0000e-04
Validation rmse = 0.925062
Epoch 29
Loss = 1.4827e-03, PNorm = 42.8678, GNorm = 0.7114, lr_0 = 1.0000e-04
Loss = 1.4899e-03, PNorm = 42.8705, GNorm = 1.1307, lr_0 = 1.0000e-04
Validation rmse = 0.936905
Model 0 best validation rmse = 0.864803 on epoch 26
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.031850
Ensemble test rmse = 1.031850
Fold 5
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 4,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 500,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 500,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_4_dropout_0.25_ffn_num_layers_2_hidden_size_500/fold_5',
 'save_smiles_splits': True,
 'seed': 5,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 5
Total scaffolds = 195 | train scaffolds = 94 | val scaffolds = 55 | test scaffolds = 46
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=500, bias=False)
      (W_h): Linear(in_features=500, out_features=500, bias=False)
      (W_o): Linear(in_features=633, out_features=500, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=504, out_features=500, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=500, out_features=1, bias=True)
  )
)
Number of parameters = 893,501
Moving model to cuda
Epoch 0
Loss = 1.5536e-02, PNorm = 42.2984, GNorm = 3.2559, lr_0 = 3.6053e-04
Validation rmse = 1.645610
Epoch 1
Loss = 9.6552e-03, PNorm = 42.3233, GNorm = 6.7779, lr_0 = 6.2105e-04
Loss = 6.4279e-03, PNorm = 42.3485, GNorm = 3.2782, lr_0 = 8.5789e-04
Validation rmse = 1.500767
Epoch 2
Loss = 6.1534e-03, PNorm = 42.3886, GNorm = 2.0341, lr_0 = 9.8284e-04
Loss = 4.7409e-03, PNorm = 42.4255, GNorm = 1.1474, lr_0 = 9.4120e-04
Validation rmse = 1.291812
Epoch 3
Loss = 4.3241e-03, PNorm = 42.4535, GNorm = 2.6779, lr_0 = 8.9744e-04
Loss = 4.3001e-03, PNorm = 42.4777, GNorm = 0.8983, lr_0 = 8.5943e-04
Validation rmse = 1.234515
Epoch 4
Loss = 3.4887e-03, PNorm = 42.4953, GNorm = 1.3806, lr_0 = 8.2303e-04
Loss = 3.4627e-03, PNorm = 42.5155, GNorm = 1.4225, lr_0 = 7.8816e-04
Validation rmse = 1.171586
Epoch 5
Loss = 2.6966e-03, PNorm = 42.5317, GNorm = 1.8550, lr_0 = 7.5478e-04
Loss = 3.0605e-03, PNorm = 42.5517, GNorm = 1.1142, lr_0 = 7.2281e-04
Validation rmse = 1.148971
Epoch 6
Loss = 3.6913e-03, PNorm = 42.5655, GNorm = 0.7850, lr_0 = 6.8920e-04
Loss = 3.3707e-03, PNorm = 42.5864, GNorm = 1.0838, lr_0 = 6.6001e-04
Validation rmse = 1.292812
Epoch 7
Loss = 3.5542e-03, PNorm = 42.5983, GNorm = 1.1241, lr_0 = 6.3205e-04
Loss = 2.9049e-03, PNorm = 42.6208, GNorm = 0.7560, lr_0 = 6.0528e-04
Validation rmse = 1.180115
Epoch 8
Loss = 2.1936e-03, PNorm = 42.6368, GNorm = 1.1091, lr_0 = 5.7714e-04
Loss = 2.7899e-03, PNorm = 42.6506, GNorm = 1.4411, lr_0 = 5.5269e-04
Validation rmse = 1.149539
Epoch 9
Loss = 2.5333e-03, PNorm = 42.6621, GNorm = 1.2069, lr_0 = 5.2928e-04
Loss = 2.7432e-03, PNorm = 42.6807, GNorm = 0.6805, lr_0 = 5.0686e-04
Validation rmse = 1.164034
Epoch 10
Loss = 2.7400e-03, PNorm = 42.6893, GNorm = 0.7101, lr_0 = 4.8539e-04
Loss = 2.4363e-03, PNorm = 42.7040, GNorm = 1.5749, lr_0 = 4.6483e-04
Validation rmse = 1.129317
Epoch 11
Loss = 1.8494e-03, PNorm = 42.7166, GNorm = 0.5429, lr_0 = 4.4322e-04
Loss = 2.1046e-03, PNorm = 42.7302, GNorm = 1.1428, lr_0 = 4.2444e-04
Validation rmse = 1.141852
Epoch 12
Loss = 2.1914e-03, PNorm = 42.7385, GNorm = 1.7608, lr_0 = 4.0646e-04
Loss = 2.3624e-03, PNorm = 42.7493, GNorm = 1.6077, lr_0 = 3.8925e-04
Validation rmse = 1.137133
Epoch 13
Loss = 2.1529e-03, PNorm = 42.7586, GNorm = 0.8523, lr_0 = 3.7276e-04
Loss = 2.1752e-03, PNorm = 42.7656, GNorm = 1.2412, lr_0 = 3.5697e-04
Validation rmse = 1.424610
Epoch 14
Loss = 2.8412e-03, PNorm = 42.7745, GNorm = 2.5268, lr_0 = 3.4037e-04
Loss = 2.4928e-03, PNorm = 42.7840, GNorm = 1.0706, lr_0 = 3.2596e-04
Validation rmse = 1.079524
Epoch 15
Loss = 2.3443e-03, PNorm = 42.7949, GNorm = 1.1888, lr_0 = 3.1215e-04
Loss = 2.0579e-03, PNorm = 42.8012, GNorm = 0.6958, lr_0 = 2.9893e-04
Validation rmse = 1.013705
Epoch 16
Loss = 1.9829e-03, PNorm = 42.8085, GNorm = 0.5807, lr_0 = 2.8503e-04
Loss = 2.1299e-03, PNorm = 42.8145, GNorm = 1.3655, lr_0 = 2.7295e-04
Validation rmse = 1.109270
Epoch 17
Loss = 2.0970e-03, PNorm = 42.8211, GNorm = 0.7824, lr_0 = 2.6139e-04
Loss = 2.1270e-03, PNorm = 42.8264, GNorm = 0.7733, lr_0 = 2.5032e-04
Validation rmse = 1.040774
Epoch 18
Loss = 1.9038e-03, PNorm = 42.8315, GNorm = 0.5562, lr_0 = 2.3972e-04
Loss = 2.0310e-03, PNorm = 42.8378, GNorm = 1.1749, lr_0 = 2.2956e-04
Validation rmse = 1.006033
Epoch 19
Loss = 1.8552e-03, PNorm = 42.8426, GNorm = 0.9291, lr_0 = 2.1889e-04
Loss = 2.0252e-03, PNorm = 42.8482, GNorm = 0.8254, lr_0 = 2.0962e-04
Validation rmse = 1.014180
Epoch 20
Loss = 1.9734e-03, PNorm = 42.8506, GNorm = 0.7977, lr_0 = 2.0074e-04
Loss = 1.9245e-03, PNorm = 42.8557, GNorm = 1.3513, lr_0 = 1.9224e-04
Validation rmse = 1.022197
Epoch 21
Loss = 1.7109e-03, PNorm = 42.8583, GNorm = 1.0688, lr_0 = 1.8409e-04
Loss = 1.8214e-03, PNorm = 42.8624, GNorm = 0.4389, lr_0 = 1.7630e-04
Validation rmse = 1.065853
Epoch 22
Loss = 1.5994e-03, PNorm = 42.8662, GNorm = 1.3966, lr_0 = 1.6810e-04
Loss = 1.9379e-03, PNorm = 42.8698, GNorm = 1.0127, lr_0 = 1.6098e-04
Validation rmse = 1.103472
Epoch 23
Loss = 1.9832e-03, PNorm = 42.8746, GNorm = 1.0396, lr_0 = 1.5416e-04
Loss = 1.5850e-03, PNorm = 42.8781, GNorm = 1.0037, lr_0 = 1.4763e-04
Loss = 7.4833e-04, PNorm = 42.8784, GNorm = 0.8769, lr_0 = 1.4699e-04
Validation rmse = 1.103038
Epoch 24
Loss = 1.5095e-03, PNorm = 42.8818, GNorm = 1.2186, lr_0 = 1.4077e-04
Loss = 2.0182e-03, PNorm = 42.8848, GNorm = 1.8954, lr_0 = 1.3480e-04
Validation rmse = 1.038675
Epoch 25
Loss = 1.6877e-03, PNorm = 42.8880, GNorm = 1.1170, lr_0 = 1.2909e-04
Loss = 1.8551e-03, PNorm = 42.8910, GNorm = 1.7573, lr_0 = 1.2362e-04
Validation rmse = 1.096416
Epoch 26
Loss = 1.6275e-03, PNorm = 42.8937, GNorm = 1.8944, lr_0 = 1.1839e-04
Validation rmse = 1.026063
Epoch 27
Loss = 1.8250e-03, PNorm = 42.8979, GNorm = 0.6487, lr_0 = 1.1288e-04
Loss = 1.6771e-03, PNorm = 42.8995, GNorm = 0.8025, lr_0 = 1.0810e-04
Validation rmse = 1.078271
Epoch 28
Loss = 1.0484e-03, PNorm = 42.9012, GNorm = 0.7805, lr_0 = 1.0352e-04
Loss = 1.7657e-03, PNorm = 42.9026, GNorm = 0.6126, lr_0 = 1.0000e-04
Validation rmse = 1.015773
Epoch 29
Loss = 1.5533e-03, PNorm = 42.9046, GNorm = 2.0713, lr_0 = 1.0000e-04
Loss = 1.7577e-03, PNorm = 42.9064, GNorm = 1.0447, lr_0 = 1.0000e-04
Validation rmse = 0.990149
Model 0 best validation rmse = 0.990149 on epoch 29
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.096462
Ensemble test rmse = 1.096462
Fold 6
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 4,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 500,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 500,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_4_dropout_0.25_ffn_num_layers_2_hidden_size_500/fold_6',
 'save_smiles_splits': True,
 'seed': 6,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 6
Total scaffolds = 195 | train scaffolds = 64 | val scaffolds = 68 | test scaffolds = 63
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=500, bias=False)
      (W_h): Linear(in_features=500, out_features=500, bias=False)
      (W_o): Linear(in_features=633, out_features=500, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=504, out_features=500, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=500, out_features=1, bias=True)
  )
)
Number of parameters = 893,501
Moving model to cuda
Epoch 0
Loss = 1.4515e-02, PNorm = 42.3014, GNorm = 5.6943, lr_0 = 3.6053e-04
Validation rmse = 1.304731
Epoch 1
Loss = 6.1838e-03, PNorm = 42.3221, GNorm = 2.2609, lr_0 = 6.2105e-04
Loss = 6.5622e-03, PNorm = 42.3504, GNorm = 3.1506, lr_0 = 8.5789e-04
Validation rmse = 1.227256
Epoch 2
Loss = 3.2660e-03, PNorm = 42.3847, GNorm = 0.9205, lr_0 = 9.8284e-04
Loss = 4.6017e-03, PNorm = 42.4158, GNorm = 0.8359, lr_0 = 9.4120e-04
Validation rmse = 1.229398
Epoch 3
Loss = 3.3022e-03, PNorm = 42.4441, GNorm = 2.1192, lr_0 = 8.9744e-04
Loss = 3.7551e-03, PNorm = 42.4672, GNorm = 0.9348, lr_0 = 8.5943e-04
Validation rmse = 1.152144
Epoch 4
Loss = 3.6465e-03, PNorm = 42.4884, GNorm = 2.6784, lr_0 = 8.2303e-04
Loss = 3.9896e-03, PNorm = 42.5120, GNorm = 1.5018, lr_0 = 7.8816e-04
Validation rmse = 1.136327
Epoch 5
Loss = 4.1276e-03, PNorm = 42.5278, GNorm = 0.8847, lr_0 = 7.5478e-04
Loss = 2.9645e-03, PNorm = 42.5497, GNorm = 1.1914, lr_0 = 7.2281e-04
Validation rmse = 1.378857
Epoch 6
Loss = 3.4500e-03, PNorm = 42.5676, GNorm = 1.9704, lr_0 = 6.8920e-04
Loss = 2.8316e-03, PNorm = 42.5878, GNorm = 0.9245, lr_0 = 6.6001e-04
Validation rmse = 1.128306
Epoch 7
Loss = 3.2905e-03, PNorm = 42.6047, GNorm = 0.9404, lr_0 = 6.3205e-04
Loss = 2.5451e-03, PNorm = 42.6216, GNorm = 0.8381, lr_0 = 6.0528e-04
Validation rmse = 1.216342
Epoch 8
Loss = 2.6562e-03, PNorm = 42.6359, GNorm = 1.3272, lr_0 = 5.7714e-04
Loss = 3.5766e-03, PNorm = 42.6529, GNorm = 1.9701, lr_0 = 5.5269e-04
Validation rmse = 1.261939
Epoch 9
Loss = 2.5764e-03, PNorm = 42.6681, GNorm = 0.9963, lr_0 = 5.2928e-04
Loss = 2.3534e-03, PNorm = 42.6827, GNorm = 0.6105, lr_0 = 5.0686e-04
Validation rmse = 1.057287
Epoch 10
Loss = 2.4516e-03, PNorm = 42.6978, GNorm = 0.7649, lr_0 = 4.8539e-04
Loss = 2.0927e-03, PNorm = 42.7109, GNorm = 1.3969, lr_0 = 4.6483e-04
Validation rmse = 1.109059
Epoch 11
Loss = 2.0401e-03, PNorm = 42.7197, GNorm = 0.5082, lr_0 = 4.4322e-04
Loss = 2.1994e-03, PNorm = 42.7323, GNorm = 1.7356, lr_0 = 4.2444e-04
Validation rmse = 1.119461
Epoch 12
Loss = 1.8733e-03, PNorm = 42.7429, GNorm = 1.7321, lr_0 = 4.0646e-04
Loss = 2.2159e-03, PNorm = 42.7511, GNorm = 0.6773, lr_0 = 3.8925e-04
Validation rmse = 1.120894
Epoch 13
Loss = 2.2473e-03, PNorm = 42.7623, GNorm = 1.3430, lr_0 = 3.7276e-04
Loss = 2.0435e-03, PNorm = 42.7733, GNorm = 1.2517, lr_0 = 3.5697e-04
Validation rmse = 1.301638
Epoch 14
Loss = 1.8830e-03, PNorm = 42.7839, GNorm = 2.2810, lr_0 = 3.4037e-04
Loss = 1.9679e-03, PNorm = 42.7933, GNorm = 1.5787, lr_0 = 3.2596e-04
Validation rmse = 1.220476
Epoch 15
Loss = 1.7943e-03, PNorm = 42.7993, GNorm = 0.8201, lr_0 = 3.1215e-04
Loss = 1.8510e-03, PNorm = 42.8072, GNorm = 2.7113, lr_0 = 2.9893e-04
Validation rmse = 1.111073
Epoch 16
Loss = 1.8470e-03, PNorm = 42.8172, GNorm = 0.7958, lr_0 = 2.8503e-04
Loss = 1.8973e-03, PNorm = 42.8213, GNorm = 0.8875, lr_0 = 2.7295e-04
Validation rmse = 1.056252
Epoch 17
Loss = 1.8124e-03, PNorm = 42.8293, GNorm = 1.9275, lr_0 = 2.6139e-04
Loss = 1.8764e-03, PNorm = 42.8347, GNorm = 0.6049, lr_0 = 2.5032e-04
Validation rmse = 1.069280
Epoch 18
Loss = 2.0389e-03, PNorm = 42.8415, GNorm = 1.3155, lr_0 = 2.3972e-04
Loss = 1.6690e-03, PNorm = 42.8463, GNorm = 0.5858, lr_0 = 2.2956e-04
Validation rmse = 1.114981
Epoch 19
Loss = 1.6218e-03, PNorm = 42.8523, GNorm = 0.9157, lr_0 = 2.1889e-04
Loss = 1.7385e-03, PNorm = 42.8593, GNorm = 1.2696, lr_0 = 2.0962e-04
Validation rmse = 1.095043
Epoch 20
Loss = 1.6569e-03, PNorm = 42.8639, GNorm = 0.8590, lr_0 = 2.0074e-04
Loss = 1.6281e-03, PNorm = 42.8672, GNorm = 0.5210, lr_0 = 1.9224e-04
Validation rmse = 1.084923
Epoch 21
Loss = 1.6358e-03, PNorm = 42.8733, GNorm = 0.7777, lr_0 = 1.8409e-04
Loss = 1.7466e-03, PNorm = 42.8783, GNorm = 1.3453, lr_0 = 1.7630e-04
Validation rmse = 1.149105
Epoch 22
Loss = 1.8274e-03, PNorm = 42.8825, GNorm = 1.7904, lr_0 = 1.6810e-04
Loss = 1.6597e-03, PNorm = 42.8843, GNorm = 0.6124, lr_0 = 1.6098e-04
Validation rmse = 1.055006
Epoch 23
Loss = 1.7271e-03, PNorm = 42.8893, GNorm = 1.6813, lr_0 = 1.5416e-04
Loss = 1.4503e-03, PNorm = 42.8923, GNorm = 0.4483, lr_0 = 1.4763e-04
Loss = 4.1974e-03, PNorm = 42.8925, GNorm = 1.5896, lr_0 = 1.4699e-04
Validation rmse = 1.135888
Epoch 24
Loss = 1.6694e-03, PNorm = 42.8965, GNorm = 0.5627, lr_0 = 1.4077e-04
Loss = 1.7067e-03, PNorm = 42.8997, GNorm = 1.4750, lr_0 = 1.3480e-04
Validation rmse = 1.091191
Epoch 25
Loss = 1.4546e-03, PNorm = 42.9006, GNorm = 0.6355, lr_0 = 1.2909e-04
Loss = 1.6739e-03, PNorm = 42.9042, GNorm = 1.5659, lr_0 = 1.2362e-04
Validation rmse = 1.073678
Epoch 26
Loss = 1.5032e-03, PNorm = 42.9055, GNorm = 0.6362, lr_0 = 1.1839e-04
Validation rmse = 1.056593
Epoch 27
Loss = 1.6662e-03, PNorm = 42.9087, GNorm = 1.6601, lr_0 = 1.1288e-04
Loss = 1.3908e-03, PNorm = 42.9107, GNorm = 0.9550, lr_0 = 1.0810e-04
Validation rmse = 1.057789
Epoch 28
Loss = 1.4160e-03, PNorm = 42.9133, GNorm = 1.9714, lr_0 = 1.0352e-04
Loss = 1.5117e-03, PNorm = 42.9154, GNorm = 1.2648, lr_0 = 1.0000e-04
Validation rmse = 1.139194
Epoch 29
Loss = 1.7508e-03, PNorm = 42.9174, GNorm = 1.6655, lr_0 = 1.0000e-04
Loss = 1.3263e-03, PNorm = 42.9196, GNorm = 0.7541, lr_0 = 1.0000e-04
Validation rmse = 1.088698
Model 0 best validation rmse = 1.055006 on epoch 22
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.920582
Ensemble test rmse = 0.920582
Fold 7
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 4,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 500,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 500,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_4_dropout_0.25_ffn_num_layers_2_hidden_size_500/fold_7',
 'save_smiles_splits': True,
 'seed': 7,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 7
Total scaffolds = 195 | train scaffolds = 69 | val scaffolds = 65 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=500, bias=False)
      (W_h): Linear(in_features=500, out_features=500, bias=False)
      (W_o): Linear(in_features=633, out_features=500, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=504, out_features=500, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=500, out_features=1, bias=True)
  )
)
Number of parameters = 893,501
Moving model to cuda
Epoch 0
Loss = 1.7537e-02, PNorm = 42.2976, GNorm = 4.2234, lr_0 = 3.6053e-04
Validation rmse = 1.949137
Epoch 1
Loss = 7.2150e-03, PNorm = 42.3187, GNorm = 3.3965, lr_0 = 6.2105e-04
Loss = 6.4560e-03, PNorm = 42.3512, GNorm = 3.3850, lr_0 = 8.5789e-04
Validation rmse = 1.300246
Epoch 2
Loss = 6.5727e-03, PNorm = 42.3871, GNorm = 2.2006, lr_0 = 9.8284e-04
Loss = 5.1965e-03, PNorm = 42.4177, GNorm = 1.7116, lr_0 = 9.4120e-04
Validation rmse = 1.555555
Epoch 3
Loss = 3.8080e-03, PNorm = 42.4448, GNorm = 1.2925, lr_0 = 8.9744e-04
Loss = 4.0583e-03, PNorm = 42.4680, GNorm = 2.7751, lr_0 = 8.5943e-04
Validation rmse = 1.517730
Epoch 4
Loss = 4.4269e-03, PNorm = 42.4884, GNorm = 2.9162, lr_0 = 8.2303e-04
Loss = 4.1879e-03, PNorm = 42.5098, GNorm = 3.0117, lr_0 = 7.8816e-04
Validation rmse = 1.341179
Epoch 5
Loss = 2.6976e-03, PNorm = 42.5320, GNorm = 0.8836, lr_0 = 7.5478e-04
Loss = 3.0496e-03, PNorm = 42.5483, GNorm = 0.9173, lr_0 = 7.2281e-04
Validation rmse = 1.452242
Epoch 6
Loss = 3.5625e-03, PNorm = 42.5664, GNorm = 1.6860, lr_0 = 6.8920e-04
Loss = 3.3153e-03, PNorm = 42.5838, GNorm = 3.0532, lr_0 = 6.6001e-04
Validation rmse = 1.755320
Epoch 7
Loss = 3.4562e-03, PNorm = 42.5992, GNorm = 0.7531, lr_0 = 6.3205e-04
Loss = 3.4470e-03, PNorm = 42.6141, GNorm = 1.7559, lr_0 = 6.0528e-04
Validation rmse = 1.424048
Epoch 8
Loss = 2.5960e-03, PNorm = 42.6301, GNorm = 0.9806, lr_0 = 5.7714e-04
Loss = 2.9354e-03, PNorm = 42.6435, GNorm = 1.0943, lr_0 = 5.5269e-04
Validation rmse = 1.415414
Epoch 9
Loss = 2.7684e-03, PNorm = 42.6552, GNorm = 0.8917, lr_0 = 5.2928e-04
Loss = 2.6087e-03, PNorm = 42.6695, GNorm = 1.1901, lr_0 = 5.0686e-04
Validation rmse = 1.652654
Epoch 10
Loss = 2.7230e-03, PNorm = 42.6775, GNorm = 1.4021, lr_0 = 4.8539e-04
Loss = 2.4563e-03, PNorm = 42.6880, GNorm = 1.1541, lr_0 = 4.6483e-04
Validation rmse = 1.338568
Epoch 11
Loss = 2.6688e-03, PNorm = 42.7020, GNorm = 0.9389, lr_0 = 4.4322e-04
Loss = 2.3677e-03, PNorm = 42.7107, GNorm = 1.0549, lr_0 = 4.2444e-04
Validation rmse = 1.341370
Epoch 12
Loss = 1.8990e-03, PNorm = 42.7214, GNorm = 0.4777, lr_0 = 4.0646e-04
Loss = 2.0672e-03, PNorm = 42.7288, GNorm = 0.7885, lr_0 = 3.8925e-04
Validation rmse = 1.367152
Epoch 13
Loss = 2.0516e-03, PNorm = 42.7403, GNorm = 0.4351, lr_0 = 3.7276e-04
Loss = 2.5062e-03, PNorm = 42.7499, GNorm = 1.6931, lr_0 = 3.5697e-04
Validation rmse = 1.313184
Epoch 14
Loss = 1.9887e-03, PNorm = 42.7600, GNorm = 2.1377, lr_0 = 3.4037e-04
Loss = 2.2976e-03, PNorm = 42.7671, GNorm = 2.5172, lr_0 = 3.2596e-04
Validation rmse = 1.279906
Epoch 15
Loss = 2.2975e-03, PNorm = 42.7752, GNorm = 1.6810, lr_0 = 3.1215e-04
Loss = 2.3873e-03, PNorm = 42.7835, GNorm = 1.3330, lr_0 = 2.9893e-04
Validation rmse = 1.494069
Epoch 16
Loss = 2.3450e-03, PNorm = 42.7902, GNorm = 0.9093, lr_0 = 2.8503e-04
Loss = 2.2092e-03, PNorm = 42.7969, GNorm = 1.2626, lr_0 = 2.7295e-04
Validation rmse = 1.604943
Epoch 17
Loss = 2.1618e-03, PNorm = 42.8035, GNorm = 1.1012, lr_0 = 2.6139e-04
Loss = 1.9739e-03, PNorm = 42.8103, GNorm = 0.5700, lr_0 = 2.5032e-04
Validation rmse = 1.314842
Epoch 18
Loss = 1.7304e-03, PNorm = 42.8147, GNorm = 0.3910, lr_0 = 2.3972e-04
Loss = 2.0750e-03, PNorm = 42.8201, GNorm = 0.6147, lr_0 = 2.2956e-04
Validation rmse = 1.491618
Epoch 19
Loss = 1.8552e-03, PNorm = 42.8253, GNorm = 2.2266, lr_0 = 2.1889e-04
Loss = 2.0405e-03, PNorm = 42.8302, GNorm = 1.0365, lr_0 = 2.0962e-04
Validation rmse = 1.285224
Epoch 20
Loss = 2.0792e-03, PNorm = 42.8366, GNorm = 1.3847, lr_0 = 2.0074e-04
Loss = 1.5178e-03, PNorm = 42.8413, GNorm = 0.7184, lr_0 = 1.9224e-04
Validation rmse = 1.425799
Epoch 21
Loss = 1.8367e-03, PNorm = 42.8459, GNorm = 0.7865, lr_0 = 1.8409e-04
Loss = 1.6698e-03, PNorm = 42.8509, GNorm = 0.8015, lr_0 = 1.7630e-04
Validation rmse = 1.358893
Epoch 22
Loss = 1.7626e-03, PNorm = 42.8537, GNorm = 1.3227, lr_0 = 1.6810e-04
Loss = 1.9113e-03, PNorm = 42.8571, GNorm = 1.2165, lr_0 = 1.6098e-04
Validation rmse = 1.490174
Epoch 23
Loss = 1.6465e-03, PNorm = 42.8604, GNorm = 1.2243, lr_0 = 1.5416e-04
Loss = 1.8733e-03, PNorm = 42.8644, GNorm = 0.7756, lr_0 = 1.4763e-04
Loss = 3.3449e-03, PNorm = 42.8646, GNorm = 1.8547, lr_0 = 1.4699e-04
Validation rmse = 1.364412
Epoch 24
Loss = 1.6446e-03, PNorm = 42.8666, GNorm = 1.0416, lr_0 = 1.4077e-04
Loss = 1.7798e-03, PNorm = 42.8701, GNorm = 2.1549, lr_0 = 1.3480e-04
Validation rmse = 1.410709
Epoch 25
Loss = 1.7200e-03, PNorm = 42.8725, GNorm = 0.9865, lr_0 = 1.2909e-04
Loss = 1.6773e-03, PNorm = 42.8744, GNorm = 1.3719, lr_0 = 1.2362e-04
Validation rmse = 1.397998
Epoch 26
Loss = 1.6738e-03, PNorm = 42.8764, GNorm = 1.1786, lr_0 = 1.1839e-04
Validation rmse = 1.495613
Epoch 27
Loss = 1.2498e-03, PNorm = 42.8782, GNorm = 1.5154, lr_0 = 1.1288e-04
Loss = 1.6291e-03, PNorm = 42.8818, GNorm = 1.2030, lr_0 = 1.0810e-04
Validation rmse = 1.401872
Epoch 28
Loss = 1.1695e-03, PNorm = 42.8841, GNorm = 0.4226, lr_0 = 1.0352e-04
Loss = 1.5580e-03, PNorm = 42.8857, GNorm = 1.1098, lr_0 = 1.0000e-04
Validation rmse = 1.386351
Epoch 29
Loss = 1.4089e-03, PNorm = 42.8888, GNorm = 0.7431, lr_0 = 1.0000e-04
Loss = 1.6817e-03, PNorm = 42.8909, GNorm = 0.6445, lr_0 = 1.0000e-04
Validation rmse = 1.448699
Model 0 best validation rmse = 1.279906 on epoch 14
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.938072
Ensemble test rmse = 0.938072
Fold 8
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 4,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 500,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 500,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_4_dropout_0.25_ffn_num_layers_2_hidden_size_500/fold_8',
 'save_smiles_splits': True,
 'seed': 8,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 8
Total scaffolds = 195 | train scaffolds = 75 | val scaffolds = 42 | test scaffolds = 78
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=500, bias=False)
      (W_h): Linear(in_features=500, out_features=500, bias=False)
      (W_o): Linear(in_features=633, out_features=500, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=504, out_features=500, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=500, out_features=1, bias=True)
  )
)
Number of parameters = 893,501
Moving model to cuda
Epoch 0
Loss = 1.6150e-02, PNorm = 42.2982, GNorm = 6.8932, lr_0 = 3.6053e-04
Validation rmse = 1.470091
Epoch 1
Loss = 4.6822e-03, PNorm = 42.3231, GNorm = 2.7657, lr_0 = 6.2105e-04
Loss = 5.4721e-03, PNorm = 42.3502, GNorm = 3.7690, lr_0 = 8.5789e-04
Validation rmse = 1.282353
Epoch 2
Loss = 4.8252e-03, PNorm = 42.3834, GNorm = 2.9372, lr_0 = 9.8284e-04
Loss = 4.8372e-03, PNorm = 42.4096, GNorm = 3.4299, lr_0 = 9.4120e-04
Validation rmse = 1.147464
Epoch 3
Loss = 3.9678e-03, PNorm = 42.4401, GNorm = 1.7849, lr_0 = 8.9744e-04
Loss = 3.9803e-03, PNorm = 42.4656, GNorm = 1.0601, lr_0 = 8.5943e-04
Validation rmse = 1.143497
Epoch 4
Loss = 2.7740e-03, PNorm = 42.4850, GNorm = 0.8808, lr_0 = 8.2303e-04
Loss = 3.4794e-03, PNorm = 42.5003, GNorm = 1.1386, lr_0 = 7.8816e-04
Validation rmse = 1.158825
Epoch 5
Loss = 2.7895e-03, PNorm = 42.5146, GNorm = 1.0566, lr_0 = 7.5478e-04
Loss = 3.0731e-03, PNorm = 42.5284, GNorm = 1.5285, lr_0 = 7.2281e-04
Validation rmse = 1.217880
Epoch 6
Loss = 2.5669e-03, PNorm = 42.5434, GNorm = 1.5934, lr_0 = 6.8920e-04
Loss = 2.8361e-03, PNorm = 42.5592, GNorm = 0.7722, lr_0 = 6.6001e-04
Validation rmse = 1.219579
Epoch 7
Loss = 2.8033e-03, PNorm = 42.5720, GNorm = 1.4147, lr_0 = 6.3205e-04
Loss = 2.5531e-03, PNorm = 42.5868, GNorm = 0.7627, lr_0 = 6.0528e-04
Validation rmse = 1.150389
Epoch 8
Loss = 2.9609e-03, PNorm = 42.6044, GNorm = 1.2508, lr_0 = 5.7714e-04
Loss = 2.4062e-03, PNorm = 42.6173, GNorm = 2.0544, lr_0 = 5.5269e-04
Validation rmse = 1.116240
Epoch 9
Loss = 2.8217e-03, PNorm = 42.6317, GNorm = 1.1741, lr_0 = 5.2928e-04
Loss = 2.1215e-03, PNorm = 42.6416, GNorm = 0.6860, lr_0 = 5.0686e-04
Validation rmse = 1.073562
Epoch 10
Loss = 2.1463e-03, PNorm = 42.6556, GNorm = 1.5794, lr_0 = 4.8539e-04
Loss = 2.4938e-03, PNorm = 42.6677, GNorm = 1.1969, lr_0 = 4.6483e-04
Validation rmse = 1.201552
Epoch 11
Loss = 2.4804e-03, PNorm = 42.6810, GNorm = 0.9868, lr_0 = 4.4322e-04
Loss = 2.1318e-03, PNorm = 42.6901, GNorm = 1.2071, lr_0 = 4.2444e-04
Validation rmse = 1.156749
Epoch 12
Loss = 1.8673e-03, PNorm = 42.7013, GNorm = 1.8412, lr_0 = 4.0646e-04
Loss = 1.7187e-03, PNorm = 42.7094, GNorm = 1.3540, lr_0 = 3.8925e-04
Validation rmse = 1.042047
Epoch 13
Loss = 2.3967e-03, PNorm = 42.7185, GNorm = 1.0340, lr_0 = 3.7276e-04
Loss = 1.9882e-03, PNorm = 42.7291, GNorm = 0.9656, lr_0 = 3.5697e-04
Validation rmse = 1.015970
Epoch 14
Loss = 1.9404e-03, PNorm = 42.7372, GNorm = 0.9924, lr_0 = 3.4037e-04
Loss = 2.0910e-03, PNorm = 42.7452, GNorm = 0.8414, lr_0 = 3.2596e-04
Validation rmse = 1.068367
Epoch 15
Loss = 2.0799e-03, PNorm = 42.7512, GNorm = 2.3609, lr_0 = 3.1215e-04
Loss = 2.0114e-03, PNorm = 42.7577, GNorm = 1.1936, lr_0 = 2.9893e-04
Validation rmse = 1.056715
Epoch 16
Loss = 1.6728e-03, PNorm = 42.7665, GNorm = 0.8935, lr_0 = 2.8503e-04
Loss = 2.1242e-03, PNorm = 42.7724, GNorm = 1.1623, lr_0 = 2.7295e-04
Validation rmse = 1.061028
Epoch 17
Loss = 1.6267e-03, PNorm = 42.7778, GNorm = 0.7818, lr_0 = 2.6139e-04
Loss = 1.8751e-03, PNorm = 42.7842, GNorm = 0.5209, lr_0 = 2.5032e-04
Validation rmse = 1.094225
Epoch 18
Loss = 1.8430e-03, PNorm = 42.7886, GNorm = 0.5328, lr_0 = 2.3972e-04
Loss = 1.7155e-03, PNorm = 42.7945, GNorm = 0.4100, lr_0 = 2.2956e-04
Validation rmse = 1.056509
Epoch 19
Loss = 1.4861e-03, PNorm = 42.7999, GNorm = 0.6307, lr_0 = 2.1889e-04
Loss = 1.7236e-03, PNorm = 42.8040, GNorm = 0.7523, lr_0 = 2.0962e-04
Validation rmse = 1.057014
Epoch 20
Loss = 1.4935e-03, PNorm = 42.8070, GNorm = 1.0618, lr_0 = 2.0074e-04
Loss = 1.9424e-03, PNorm = 42.8106, GNorm = 1.6275, lr_0 = 1.9224e-04
Validation rmse = 1.012195
Epoch 21
Loss = 2.1206e-03, PNorm = 42.8146, GNorm = 2.5478, lr_0 = 1.8409e-04
Loss = 1.8120e-03, PNorm = 42.8202, GNorm = 1.5668, lr_0 = 1.7630e-04
Validation rmse = 1.051848
Epoch 22
Loss = 1.5612e-03, PNorm = 42.8237, GNorm = 0.9092, lr_0 = 1.6810e-04
Loss = 1.6857e-03, PNorm = 42.8280, GNorm = 1.4521, lr_0 = 1.6098e-04
Validation rmse = 1.019147
Epoch 23
Loss = 1.5660e-03, PNorm = 42.8312, GNorm = 0.8073, lr_0 = 1.5416e-04
Loss = 1.4226e-03, PNorm = 42.8341, GNorm = 0.7703, lr_0 = 1.4763e-04
Loss = 1.9898e-03, PNorm = 42.8346, GNorm = 1.1188, lr_0 = 1.4699e-04
Validation rmse = 1.041658
Epoch 24
Loss = 1.5811e-03, PNorm = 42.8371, GNorm = 0.7068, lr_0 = 1.4077e-04
Loss = 1.6732e-03, PNorm = 42.8412, GNorm = 0.5880, lr_0 = 1.3480e-04
Validation rmse = 1.039422
Epoch 25
Loss = 1.8464e-03, PNorm = 42.8439, GNorm = 1.3198, lr_0 = 1.2909e-04
Loss = 1.3377e-03, PNorm = 42.8469, GNorm = 1.0436, lr_0 = 1.2362e-04
Validation rmse = 1.008393
Epoch 26
Loss = 1.6757e-03, PNorm = 42.8494, GNorm = 2.4115, lr_0 = 1.1839e-04
Validation rmse = 1.048294
Epoch 27
Loss = 2.8578e-03, PNorm = 42.8502, GNorm = 2.1410, lr_0 = 1.1288e-04
Loss = 1.3502e-03, PNorm = 42.8527, GNorm = 0.5513, lr_0 = 1.0810e-04
Validation rmse = 1.004708
Epoch 28
Loss = 1.3388e-03, PNorm = 42.8555, GNorm = 0.6482, lr_0 = 1.0352e-04
Loss = 1.5797e-03, PNorm = 42.8565, GNorm = 1.0271, lr_0 = 1.0000e-04
Validation rmse = 1.034744
Epoch 29
Loss = 1.2987e-03, PNorm = 42.8593, GNorm = 0.4924, lr_0 = 1.0000e-04
Loss = 1.5356e-03, PNorm = 42.8615, GNorm = 1.0615, lr_0 = 1.0000e-04
Validation rmse = 1.045657
Model 0 best validation rmse = 1.004708 on epoch 27
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.101867
Ensemble test rmse = 1.101867
Fold 9
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 4,
 'device': device(type='cuda'),
 'dropout': 0.25,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 500,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 500,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_4_dropout_0.25_ffn_num_layers_2_hidden_size_500/fold_9',
 'save_smiles_splits': True,
 'seed': 9,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 9
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 58 | test scaffolds = 53
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.25, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=500, bias=False)
      (W_h): Linear(in_features=500, out_features=500, bias=False)
      (W_o): Linear(in_features=633, out_features=500, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=504, out_features=500, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=500, out_features=1, bias=True)
  )
)
Number of parameters = 893,501
Moving model to cuda
Epoch 0
Loss = 1.5885e-02, PNorm = 42.2991, GNorm = 6.4293, lr_0 = 3.6053e-04
Validation rmse = 1.588026
Epoch 1
Loss = 1.0296e-02, PNorm = 42.3212, GNorm = 5.5053, lr_0 = 6.2105e-04
Loss = 7.8830e-03, PNorm = 42.3503, GNorm = 1.6126, lr_0 = 8.5789e-04
Validation rmse = 1.240888
Epoch 2
Loss = 4.5958e-03, PNorm = 42.3899, GNorm = 0.8403, lr_0 = 9.8284e-04
Loss = 4.3403e-03, PNorm = 42.4173, GNorm = 0.9407, lr_0 = 9.4120e-04
Validation rmse = 1.107454
Epoch 3
Loss = 3.8754e-03, PNorm = 42.4422, GNorm = 1.3862, lr_0 = 8.9744e-04
Loss = 4.1393e-03, PNorm = 42.4603, GNorm = 0.9142, lr_0 = 8.5943e-04
Validation rmse = 1.081808
Epoch 4
Loss = 4.1179e-03, PNorm = 42.4802, GNorm = 4.1658, lr_0 = 8.2303e-04
Loss = 3.4154e-03, PNorm = 42.5020, GNorm = 1.0882, lr_0 = 7.8816e-04
Validation rmse = 1.076686
Epoch 5
Loss = 2.7563e-03, PNorm = 42.5155, GNorm = 0.8080, lr_0 = 7.5478e-04
Loss = 3.2527e-03, PNorm = 42.5348, GNorm = 0.9576, lr_0 = 7.2281e-04
Validation rmse = 1.114485
Epoch 6
Loss = 3.8107e-03, PNorm = 42.5547, GNorm = 3.4335, lr_0 = 6.8920e-04
Loss = 3.1382e-03, PNorm = 42.5716, GNorm = 0.8614, lr_0 = 6.6001e-04
Validation rmse = 1.037115
Epoch 7
Loss = 3.6537e-03, PNorm = 42.5930, GNorm = 2.5382, lr_0 = 6.3205e-04
Loss = 2.7858e-03, PNorm = 42.6040, GNorm = 0.7779, lr_0 = 6.0528e-04
Validation rmse = 1.029038
Epoch 8
Loss = 2.8187e-03, PNorm = 42.6186, GNorm = 1.1363, lr_0 = 5.7714e-04
Loss = 3.1039e-03, PNorm = 42.6358, GNorm = 1.8167, lr_0 = 5.5269e-04
Validation rmse = 1.110826
Epoch 9
Loss = 2.9506e-03, PNorm = 42.6506, GNorm = 2.1377, lr_0 = 5.2928e-04
Loss = 2.3417e-03, PNorm = 42.6657, GNorm = 1.0624, lr_0 = 5.0686e-04
Validation rmse = 1.011040
Epoch 10
Loss = 2.4856e-03, PNorm = 42.6749, GNorm = 2.2346, lr_0 = 4.8539e-04
Loss = 2.5611e-03, PNorm = 42.6855, GNorm = 2.6994, lr_0 = 4.6483e-04
Validation rmse = 0.999024
Epoch 11
Loss = 2.3253e-03, PNorm = 42.6991, GNorm = 0.6549, lr_0 = 4.4322e-04
Loss = 2.4200e-03, PNorm = 42.7081, GNorm = 1.7106, lr_0 = 4.2444e-04
Validation rmse = 1.019626
Epoch 12
Loss = 2.4797e-03, PNorm = 42.7198, GNorm = 1.8698, lr_0 = 4.0646e-04
Loss = 2.3014e-03, PNorm = 42.7284, GNorm = 2.2511, lr_0 = 3.8925e-04
Validation rmse = 0.964297
Epoch 13
Loss = 1.8180e-03, PNorm = 42.7357, GNorm = 0.7313, lr_0 = 3.7276e-04
Loss = 2.3750e-03, PNorm = 42.7462, GNorm = 2.9059, lr_0 = 3.5697e-04
Validation rmse = 1.027941
Epoch 14
Loss = 2.0589e-03, PNorm = 42.7562, GNorm = 1.2430, lr_0 = 3.4037e-04
Loss = 1.8885e-03, PNorm = 42.7659, GNorm = 0.5941, lr_0 = 3.2596e-04
Validation rmse = 1.036632
Epoch 15
Loss = 1.9597e-03, PNorm = 42.7711, GNorm = 1.5804, lr_0 = 3.1215e-04
Loss = 2.3373e-03, PNorm = 42.7763, GNorm = 2.4000, lr_0 = 2.9893e-04
Validation rmse = 0.989824
Epoch 16
Loss = 2.4463e-03, PNorm = 42.7858, GNorm = 1.4580, lr_0 = 2.8503e-04
Loss = 1.8607e-03, PNorm = 42.7907, GNorm = 0.8204, lr_0 = 2.7295e-04
Validation rmse = 1.031165
Epoch 17
Loss = 1.8792e-03, PNorm = 42.7969, GNorm = 1.0893, lr_0 = 2.6139e-04
Loss = 2.0194e-03, PNorm = 42.8027, GNorm = 1.6690, lr_0 = 2.5032e-04
Validation rmse = 0.976543
Epoch 18
Loss = 1.7486e-03, PNorm = 42.8080, GNorm = 0.6919, lr_0 = 2.3972e-04
Loss = 2.3547e-03, PNorm = 42.8125, GNorm = 1.4779, lr_0 = 2.2956e-04
Validation rmse = 0.890424
Epoch 19
Loss = 2.0219e-03, PNorm = 42.8168, GNorm = 1.0382, lr_0 = 2.1889e-04
Loss = 2.1484e-03, PNorm = 42.8228, GNorm = 0.6849, lr_0 = 2.0962e-04
Validation rmse = 0.925178
Epoch 20
Loss = 2.2132e-03, PNorm = 42.8280, GNorm = 1.0609, lr_0 = 2.0074e-04
Loss = 1.6648e-03, PNorm = 42.8317, GNorm = 0.7991, lr_0 = 1.9224e-04
Validation rmse = 0.885554
Epoch 21
Loss = 1.6685e-03, PNorm = 42.8352, GNorm = 0.6031, lr_0 = 1.8409e-04
Loss = 1.7707e-03, PNorm = 42.8387, GNorm = 1.1519, lr_0 = 1.7630e-04
Validation rmse = 0.937626
Epoch 22
Loss = 1.8368e-03, PNorm = 42.8432, GNorm = 2.4170, lr_0 = 1.6810e-04
Loss = 1.8701e-03, PNorm = 42.8462, GNorm = 2.3295, lr_0 = 1.6098e-04
Validation rmse = 0.908849
Epoch 23
Loss = 1.6470e-03, PNorm = 42.8486, GNorm = 1.0378, lr_0 = 1.5416e-04
Loss = 1.9410e-03, PNorm = 42.8528, GNorm = 1.0244, lr_0 = 1.4763e-04
Loss = 2.9949e-03, PNorm = 42.8533, GNorm = 1.5302, lr_0 = 1.4699e-04
Validation rmse = 0.928804
Epoch 24
Loss = 1.8144e-03, PNorm = 42.8561, GNorm = 0.7082, lr_0 = 1.4077e-04
Loss = 1.7142e-03, PNorm = 42.8581, GNorm = 1.9938, lr_0 = 1.3480e-04
Validation rmse = 0.934153
Epoch 25
Loss = 1.6713e-03, PNorm = 42.8600, GNorm = 0.7419, lr_0 = 1.2909e-04
Loss = 1.6893e-03, PNorm = 42.8628, GNorm = 1.2008, lr_0 = 1.2362e-04
Validation rmse = 0.920778
Epoch 26
Loss = 1.6757e-03, PNorm = 42.8653, GNorm = 0.9102, lr_0 = 1.1839e-04
Validation rmse = 0.922604
Epoch 27
Loss = 2.7152e-03, PNorm = 42.8677, GNorm = 2.0236, lr_0 = 1.1288e-04
Loss = 1.7314e-03, PNorm = 42.8702, GNorm = 0.7955, lr_0 = 1.0810e-04
Validation rmse = 0.939150
Epoch 28
Loss = 1.8979e-03, PNorm = 42.8722, GNorm = 1.2227, lr_0 = 1.0352e-04
Loss = 1.6196e-03, PNorm = 42.8747, GNorm = 1.0933, lr_0 = 1.0000e-04
Validation rmse = 0.952378
Epoch 29
Loss = 2.1324e-03, PNorm = 42.8773, GNorm = 1.8274, lr_0 = 1.0000e-04
Loss = 1.6074e-03, PNorm = 42.8790, GNorm = 1.2393, lr_0 = 1.0000e-04
Validation rmse = 0.880912
Model 0 best validation rmse = 0.880912 on epoch 29
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.316832
Ensemble test rmse = 1.316832
10-fold cross validation
	Seed 0 ==> test rmse = 1.079114
	Seed 1 ==> test rmse = 1.016801
	Seed 2 ==> test rmse = 1.028035
	Seed 3 ==> test rmse = 1.061967
	Seed 4 ==> test rmse = 1.031850
	Seed 5 ==> test rmse = 1.096462
	Seed 6 ==> test rmse = 0.920582
	Seed 7 ==> test rmse = 0.938072
	Seed 8 ==> test rmse = 1.101867
	Seed 9 ==> test rmse = 1.316832
Overall test rmse = 1.059158 +/- 0.103630
Elapsed time = 0:06:24
Fold 0
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 2,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 2400,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 2400,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_2_dropout_0.0_ffn_num_layers_3_hidden_size_2400/fold_0',
 'save_smiles_splits': True,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total scaffolds = 195 | train scaffolds = 91 | val scaffolds = 66 | test scaffolds = 38
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=2400, bias=False)
      (W_h): Linear(in_features=2400, out_features=2400, bias=False)
      (W_o): Linear(in_features=2533, out_features=2400, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=2404, out_features=2400, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=2400, out_features=2400, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=2400, out_features=1, bias=True)
  )
)
Number of parameters = 23,731,201
Moving model to cuda
Epoch 0
Loss = 1.1164e-02, PNorm = 99.7845, GNorm = 4.8578, lr_0 = 3.6053e-04
Validation rmse = 1.030123
Epoch 1
Loss = 1.5665e-03, PNorm = 99.9167, GNorm = 0.7728, lr_0 = 6.2105e-04
Loss = 4.1995e-03, PNorm = 100.0776, GNorm = 1.9325, lr_0 = 8.5789e-04
Validation rmse = 0.885328
Epoch 2
Loss = 3.9594e-03, PNorm = 100.2798, GNorm = 0.6321, lr_0 = 9.8284e-04
Loss = 2.9759e-03, PNorm = 100.4825, GNorm = 0.4979, lr_0 = 9.4120e-04
Validation rmse = 1.009791
Epoch 3
Loss = 1.5709e-03, PNorm = 100.6560, GNorm = 0.6705, lr_0 = 8.9744e-04
Loss = 1.7678e-03, PNorm = 100.7624, GNorm = 0.5141, lr_0 = 8.5943e-04
Validation rmse = 0.998047
Epoch 4
Loss = 2.5529e-03, PNorm = 100.8489, GNorm = 0.6197, lr_0 = 8.2303e-04
Loss = 1.1766e-03, PNorm = 100.9163, GNorm = 0.2864, lr_0 = 7.8816e-04
Validation rmse = 0.878743
Epoch 5
Loss = 1.1913e-03, PNorm = 100.9710, GNorm = 0.8482, lr_0 = 7.5478e-04
Loss = 1.2219e-03, PNorm = 101.0227, GNorm = 0.4403, lr_0 = 7.2281e-04
Validation rmse = 0.840192
Epoch 6
Loss = 1.3266e-03, PNorm = 101.0845, GNorm = 0.4424, lr_0 = 6.8920e-04
Loss = 1.2043e-03, PNorm = 101.1279, GNorm = 0.4791, lr_0 = 6.6001e-04
Validation rmse = 0.905151
Epoch 7
Loss = 1.0108e-03, PNorm = 101.1750, GNorm = 0.2721, lr_0 = 6.3205e-04
Loss = 9.9238e-04, PNorm = 101.2185, GNorm = 0.3652, lr_0 = 6.0528e-04
Validation rmse = 0.947920
Epoch 8
Loss = 9.7444e-04, PNorm = 101.2631, GNorm = 0.4324, lr_0 = 5.7714e-04
Loss = 9.6863e-04, PNorm = 101.3040, GNorm = 0.3096, lr_0 = 5.5269e-04
Validation rmse = 0.818343
Epoch 9
Loss = 1.0449e-03, PNorm = 101.3402, GNorm = 1.7450, lr_0 = 5.2928e-04
Loss = 1.2305e-03, PNorm = 101.3875, GNorm = 0.4465, lr_0 = 5.0686e-04
Validation rmse = 0.891942
Epoch 10
Loss = 9.0231e-04, PNorm = 101.4267, GNorm = 0.4486, lr_0 = 4.8539e-04
Loss = 8.6499e-04, PNorm = 101.4704, GNorm = 0.1470, lr_0 = 4.6483e-04
Validation rmse = 0.958509
Epoch 11
Loss = 7.8142e-04, PNorm = 101.5133, GNorm = 0.4523, lr_0 = 4.4322e-04
Loss = 6.5293e-04, PNorm = 101.5486, GNorm = 0.3376, lr_0 = 4.2444e-04
Validation rmse = 0.883247
Epoch 12
Loss = 6.8173e-04, PNorm = 101.5796, GNorm = 0.2750, lr_0 = 4.0646e-04
Loss = 6.5201e-04, PNorm = 101.6116, GNorm = 0.1809, lr_0 = 3.8925e-04
Validation rmse = 0.867939
Epoch 13
Loss = 4.7496e-04, PNorm = 101.6438, GNorm = 0.1729, lr_0 = 3.7276e-04
Loss = 6.0077e-04, PNorm = 101.6739, GNorm = 0.3870, lr_0 = 3.5697e-04
Validation rmse = 0.862226
Epoch 14
Loss = 5.5481e-04, PNorm = 101.7039, GNorm = 0.4267, lr_0 = 3.4037e-04
Loss = 5.3578e-04, PNorm = 101.7298, GNorm = 0.3552, lr_0 = 3.2596e-04
Validation rmse = 0.836977
Epoch 15
Loss = 5.2589e-04, PNorm = 101.7536, GNorm = 0.4040, lr_0 = 3.1215e-04
Loss = 5.5774e-04, PNorm = 101.7815, GNorm = 0.3754, lr_0 = 2.9893e-04
Validation rmse = 0.832800
Epoch 16
Loss = 4.8374e-04, PNorm = 101.8110, GNorm = 0.2036, lr_0 = 2.8503e-04
Loss = 4.5792e-04, PNorm = 101.8353, GNorm = 0.2913, lr_0 = 2.7295e-04
Validation rmse = 0.849456
Epoch 17
Loss = 4.1486e-04, PNorm = 101.8569, GNorm = 0.3382, lr_0 = 2.6139e-04
Loss = 4.5119e-04, PNorm = 101.8772, GNorm = 0.2462, lr_0 = 2.5032e-04
Validation rmse = 0.908479
Epoch 18
Loss = 3.8222e-04, PNorm = 101.8959, GNorm = 0.1757, lr_0 = 2.3972e-04
Loss = 3.9263e-04, PNorm = 101.9197, GNorm = 0.2613, lr_0 = 2.2956e-04
Validation rmse = 0.948821
Epoch 19
Loss = 4.4370e-04, PNorm = 101.9380, GNorm = 0.4810, lr_0 = 2.1889e-04
Loss = 4.3889e-04, PNorm = 101.9588, GNorm = 0.3053, lr_0 = 2.0962e-04
Validation rmse = 0.869617
Epoch 20
Loss = 3.3261e-04, PNorm = 101.9753, GNorm = 0.2159, lr_0 = 2.0074e-04
Loss = 4.1942e-04, PNorm = 101.9935, GNorm = 0.1312, lr_0 = 1.9224e-04
Validation rmse = 0.901512
Epoch 21
Loss = 3.6477e-04, PNorm = 102.0086, GNorm = 0.2159, lr_0 = 1.8409e-04
Loss = 3.9392e-04, PNorm = 102.0247, GNorm = 0.2548, lr_0 = 1.7630e-04
Validation rmse = 0.859387
Epoch 22
Loss = 2.8201e-04, PNorm = 102.0387, GNorm = 0.2530, lr_0 = 1.6810e-04
Loss = 4.1234e-04, PNorm = 102.0528, GNorm = 0.2651, lr_0 = 1.6098e-04
Validation rmse = 0.891568
Epoch 23
Loss = 3.0734e-04, PNorm = 102.0664, GNorm = 0.2131, lr_0 = 1.5416e-04
Loss = 3.2458e-04, PNorm = 102.0793, GNorm = 0.0986, lr_0 = 1.4763e-04
Loss = 5.6966e-04, PNorm = 102.0806, GNorm = 0.1981, lr_0 = 1.4699e-04
Validation rmse = 0.882909
Epoch 24
Loss = 2.9066e-04, PNorm = 102.0921, GNorm = 0.2260, lr_0 = 1.4077e-04
Loss = 3.5407e-04, PNorm = 102.1050, GNorm = 0.3107, lr_0 = 1.3480e-04
Validation rmse = 0.865336
Epoch 25
Loss = 2.8415e-04, PNorm = 102.1151, GNorm = 0.1424, lr_0 = 1.2909e-04
Loss = 3.1514e-04, PNorm = 102.1242, GNorm = 0.2304, lr_0 = 1.2362e-04
Validation rmse = 0.918010
Epoch 26
Loss = 3.0759e-04, PNorm = 102.1328, GNorm = 0.2446, lr_0 = 1.1839e-04
Validation rmse = 0.873854
Epoch 27
Loss = 2.9459e-04, PNorm = 102.1435, GNorm = 0.3112, lr_0 = 1.1288e-04
Loss = 2.7678e-04, PNorm = 102.1514, GNorm = 0.1953, lr_0 = 1.0810e-04
Validation rmse = 0.867595
Epoch 28
Loss = 3.3148e-04, PNorm = 102.1604, GNorm = 0.2302, lr_0 = 1.0352e-04
Loss = 2.2864e-04, PNorm = 102.1689, GNorm = 0.2277, lr_0 = 1.0000e-04
Validation rmse = 0.864336
Epoch 29
Loss = 2.4040e-04, PNorm = 102.1782, GNorm = 0.3383, lr_0 = 1.0000e-04
Loss = 2.8233e-04, PNorm = 102.1867, GNorm = 0.2508, lr_0 = 1.0000e-04
Validation rmse = 0.848093
Model 0 best validation rmse = 0.818343 on epoch 8
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Moving model to cuda
Model 0 test rmse = 0.760280
Ensemble test rmse = 0.760280
Fold 1
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 2,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 2400,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 2400,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_2_dropout_0.0_ffn_num_layers_3_hidden_size_2400/fold_1',
 'save_smiles_splits': True,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total scaffolds = 195 | train scaffolds = 76 | val scaffolds = 60 | test scaffolds = 59
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=2400, bias=False)
      (W_h): Linear(in_features=2400, out_features=2400, bias=False)
      (W_o): Linear(in_features=2533, out_features=2400, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=2404, out_features=2400, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=2400, out_features=2400, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=2400, out_features=1, bias=True)
  )
)
Number of parameters = 23,731,201
Moving model to cuda
Epoch 0
Loss = 1.1559e-02, PNorm = 99.7886, GNorm = 4.5248, lr_0 = 3.6053e-04
Validation rmse = 1.176750
Epoch 1
Loss = 4.2348e-03, PNorm = 99.9117, GNorm = 0.8994, lr_0 = 6.2105e-04
Loss = 4.1036e-03, PNorm = 100.0855, GNorm = 1.8139, lr_0 = 8.5789e-04
Validation rmse = 1.144861
Epoch 2
Loss = 3.2061e-03, PNorm = 100.2923, GNorm = 2.0775, lr_0 = 9.8284e-04
Loss = 1.7593e-03, PNorm = 100.4568, GNorm = 0.4967, lr_0 = 9.4120e-04
Validation rmse = 0.899524
Epoch 3
Loss = 1.3772e-03, PNorm = 100.5884, GNorm = 0.6038, lr_0 = 8.9744e-04
Loss = 1.9862e-03, PNorm = 100.6844, GNorm = 0.5315, lr_0 = 8.5943e-04
Validation rmse = 0.831306
Epoch 4
Loss = 1.0557e-03, PNorm = 100.7590, GNorm = 0.3391, lr_0 = 8.2303e-04
Loss = 1.2397e-03, PNorm = 100.8203, GNorm = 0.4470, lr_0 = 7.8816e-04
Validation rmse = 0.886758
Epoch 5
Loss = 1.4536e-03, PNorm = 100.8733, GNorm = 0.8794, lr_0 = 7.5478e-04
Loss = 1.4560e-03, PNorm = 100.9344, GNorm = 0.9942, lr_0 = 7.2281e-04
Validation rmse = 0.805053
Epoch 6
Loss = 1.0210e-03, PNorm = 100.9875, GNorm = 0.3388, lr_0 = 6.8920e-04
Loss = 1.1167e-03, PNorm = 101.0390, GNorm = 0.7698, lr_0 = 6.6001e-04
Validation rmse = 0.814630
Epoch 7
Loss = 6.8045e-04, PNorm = 101.0855, GNorm = 0.5576, lr_0 = 6.3205e-04
Loss = 1.1139e-03, PNorm = 101.1308, GNorm = 0.5078, lr_0 = 6.0528e-04
Validation rmse = 0.795492
Epoch 8
Loss = 1.0186e-03, PNorm = 101.1816, GNorm = 0.5102, lr_0 = 5.7714e-04
Loss = 7.8268e-04, PNorm = 101.2317, GNorm = 0.5881, lr_0 = 5.5269e-04
Validation rmse = 0.790947
Epoch 9
Loss = 8.1672e-04, PNorm = 101.2667, GNorm = 0.2943, lr_0 = 5.2928e-04
Loss = 9.5328e-04, PNorm = 101.3044, GNorm = 0.5422, lr_0 = 5.0686e-04
Validation rmse = 0.847108
Epoch 10
Loss = 8.3092e-04, PNorm = 101.3401, GNorm = 0.3616, lr_0 = 4.8539e-04
Loss = 6.9238e-04, PNorm = 101.3743, GNorm = 0.5144, lr_0 = 4.6483e-04
Validation rmse = 0.770397
Epoch 11
Loss = 9.7515e-04, PNorm = 101.4140, GNorm = 0.3778, lr_0 = 4.4322e-04
Loss = 8.5564e-04, PNorm = 101.4470, GNorm = 0.3444, lr_0 = 4.2444e-04
Validation rmse = 0.797835
Epoch 12
Loss = 5.4866e-04, PNorm = 101.4719, GNorm = 0.3216, lr_0 = 4.0646e-04
Loss = 7.5066e-04, PNorm = 101.5001, GNorm = 0.4262, lr_0 = 3.8925e-04
Validation rmse = 0.793382
Epoch 13
Loss = 8.7586e-04, PNorm = 101.5285, GNorm = 0.4549, lr_0 = 3.7276e-04
Loss = 5.8537e-04, PNorm = 101.5614, GNorm = 0.3499, lr_0 = 3.5697e-04
Validation rmse = 0.800425
Epoch 14
Loss = 4.5058e-04, PNorm = 101.5918, GNorm = 0.4826, lr_0 = 3.4037e-04
Loss = 6.1104e-04, PNorm = 101.6181, GNorm = 0.2415, lr_0 = 3.2596e-04
Validation rmse = 0.813632
Epoch 15
Loss = 6.9034e-04, PNorm = 101.6427, GNorm = 0.3523, lr_0 = 3.1215e-04
Loss = 4.9621e-04, PNorm = 101.6700, GNorm = 0.3612, lr_0 = 2.9893e-04
Validation rmse = 0.807564
Epoch 16
Loss = 5.0187e-04, PNorm = 101.6953, GNorm = 0.2840, lr_0 = 2.8503e-04
Loss = 5.7247e-04, PNorm = 101.7183, GNorm = 0.5437, lr_0 = 2.7295e-04
Validation rmse = 0.791338
Epoch 17
Loss = 4.3681e-04, PNorm = 101.7443, GNorm = 0.3739, lr_0 = 2.6139e-04
Loss = 5.3385e-04, PNorm = 101.7654, GNorm = 0.3950, lr_0 = 2.5032e-04
Validation rmse = 0.808537
Epoch 18
Loss = 4.7671e-04, PNorm = 101.7850, GNorm = 0.3501, lr_0 = 2.3972e-04
Loss = 4.7676e-04, PNorm = 101.8060, GNorm = 0.3650, lr_0 = 2.2956e-04
Validation rmse = 0.813901
Epoch 19
Loss = 3.0168e-04, PNorm = 101.8249, GNorm = 0.1833, lr_0 = 2.1889e-04
Loss = 4.7095e-04, PNorm = 101.8421, GNorm = 0.2774, lr_0 = 2.0962e-04
Validation rmse = 0.804915
Epoch 20
Loss = 3.6343e-04, PNorm = 101.8609, GNorm = 0.1038, lr_0 = 2.0074e-04
Loss = 4.2783e-04, PNorm = 101.8740, GNorm = 0.1748, lr_0 = 1.9224e-04
Validation rmse = 0.773977
Epoch 21
Loss = 3.5676e-04, PNorm = 101.8918, GNorm = 0.4511, lr_0 = 1.8409e-04
Loss = 4.1771e-04, PNorm = 101.9065, GNorm = 0.3583, lr_0 = 1.7630e-04
Validation rmse = 0.772711
Epoch 22
Loss = 3.7680e-04, PNorm = 101.9236, GNorm = 0.2294, lr_0 = 1.6810e-04
Loss = 3.5555e-04, PNorm = 101.9349, GNorm = 0.3833, lr_0 = 1.6098e-04
Validation rmse = 0.778380
Epoch 23
Loss = 4.0438e-04, PNorm = 101.9479, GNorm = 0.3205, lr_0 = 1.5416e-04
Loss = 3.5060e-04, PNorm = 101.9603, GNorm = 0.4028, lr_0 = 1.4763e-04
Loss = 3.5964e-04, PNorm = 101.9617, GNorm = 0.2533, lr_0 = 1.4699e-04
Validation rmse = 0.791828
Epoch 24
Loss = 3.5630e-04, PNorm = 101.9771, GNorm = 0.2520, lr_0 = 1.4077e-04
Loss = 3.3980e-04, PNorm = 101.9884, GNorm = 0.1690, lr_0 = 1.3480e-04
Validation rmse = 0.798569
Epoch 25
Loss = 3.1723e-04, PNorm = 101.9982, GNorm = 0.1348, lr_0 = 1.2909e-04
Loss = 3.3699e-04, PNorm = 102.0082, GNorm = 0.3479, lr_0 = 1.2362e-04
Validation rmse = 0.781505
Epoch 26
Loss = 2.9720e-04, PNorm = 102.0196, GNorm = 0.3086, lr_0 = 1.1839e-04
Validation rmse = 0.778586
Epoch 27
Loss = 2.8027e-04, PNorm = 102.0297, GNorm = 0.4746, lr_0 = 1.1288e-04
Loss = 2.9799e-04, PNorm = 102.0397, GNorm = 0.3162, lr_0 = 1.0810e-04
Validation rmse = 0.773702
Epoch 28
Loss = 1.5330e-04, PNorm = 102.0482, GNorm = 0.2157, lr_0 = 1.0352e-04
Loss = 3.2072e-04, PNorm = 102.0587, GNorm = 0.2832, lr_0 = 1.0000e-04
Validation rmse = 0.769962
Epoch 29
Loss = 1.7238e-04, PNorm = 102.0679, GNorm = 0.2126, lr_0 = 1.0000e-04
Loss = 2.7878e-04, PNorm = 102.0765, GNorm = 0.1991, lr_0 = 1.0000e-04
Validation rmse = 0.767944
Model 0 best validation rmse = 0.767944 on epoch 29
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Moving model to cuda
Model 0 test rmse = 0.807432
Ensemble test rmse = 0.807432
Fold 2
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 2,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 2400,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 2400,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_2_dropout_0.0_ffn_num_layers_3_hidden_size_2400/fold_2',
 'save_smiles_splits': True,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total scaffolds = 195 | train scaffolds = 55 | val scaffolds = 64 | test scaffolds = 76
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=2400, bias=False)
      (W_h): Linear(in_features=2400, out_features=2400, bias=False)
      (W_o): Linear(in_features=2533, out_features=2400, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=2404, out_features=2400, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=2400, out_features=2400, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=2400, out_features=1, bias=True)
  )
)
Number of parameters = 23,731,201
Moving model to cuda
Epoch 0
Loss = 1.2934e-02, PNorm = 99.7865, GNorm = 0.9656, lr_0 = 3.6053e-04
Validation rmse = 1.332816
Epoch 1
Loss = 6.0629e-03, PNorm = 99.9187, GNorm = 1.4245, lr_0 = 6.2105e-04
Loss = 3.8418e-03, PNorm = 100.1155, GNorm = 0.9526, lr_0 = 8.5789e-04
Validation rmse = 1.158084
Epoch 2
Loss = 2.8812e-03, PNorm = 100.3173, GNorm = 1.4285, lr_0 = 9.8284e-04
Loss = 2.1362e-03, PNorm = 100.4763, GNorm = 0.7865, lr_0 = 9.4120e-04
Validation rmse = 0.940006
Epoch 3
Loss = 2.0331e-03, PNorm = 100.6062, GNorm = 0.5032, lr_0 = 8.9744e-04
Loss = 1.7642e-03, PNorm = 100.6967, GNorm = 0.5245, lr_0 = 8.5943e-04
Validation rmse = 0.926625
Epoch 4
Loss = 8.3072e-04, PNorm = 100.7691, GNorm = 0.4462, lr_0 = 8.2303e-04
Loss = 1.5051e-03, PNorm = 100.8375, GNorm = 1.0185, lr_0 = 7.8816e-04
Validation rmse = 0.980932
Epoch 5
Loss = 9.9714e-04, PNorm = 100.8916, GNorm = 0.5529, lr_0 = 7.5478e-04
Loss = 1.2831e-03, PNorm = 100.9500, GNorm = 0.5087, lr_0 = 7.2281e-04
Validation rmse = 0.818865
Epoch 6
Loss = 1.2942e-03, PNorm = 101.0192, GNorm = 1.2156, lr_0 = 6.8920e-04
Loss = 1.4106e-03, PNorm = 101.0789, GNorm = 0.7489, lr_0 = 6.6001e-04
Validation rmse = 0.878108
Epoch 7
Loss = 1.2859e-03, PNorm = 101.1299, GNorm = 0.7385, lr_0 = 6.3205e-04
Loss = 1.0745e-03, PNorm = 101.1734, GNorm = 0.4036, lr_0 = 6.0528e-04
Validation rmse = 0.824676
Epoch 8
Loss = 1.1612e-03, PNorm = 101.2339, GNorm = 0.2447, lr_0 = 5.7714e-04
Loss = 9.1116e-04, PNorm = 101.2858, GNorm = 0.2905, lr_0 = 5.5269e-04
Validation rmse = 0.792931
Epoch 9
Loss = 9.1274e-04, PNorm = 101.3240, GNorm = 0.5021, lr_0 = 5.2928e-04
Loss = 8.7763e-04, PNorm = 101.3634, GNorm = 0.2604, lr_0 = 5.0686e-04
Validation rmse = 0.784702
Epoch 10
Loss = 7.1195e-04, PNorm = 101.3987, GNorm = 0.8173, lr_0 = 4.8539e-04
Loss = 7.9449e-04, PNorm = 101.4349, GNorm = 0.5841, lr_0 = 4.6483e-04
Validation rmse = 0.848780
Epoch 11
Loss = 7.7890e-04, PNorm = 101.4822, GNorm = 0.2018, lr_0 = 4.4322e-04
Loss = 7.3584e-04, PNorm = 101.5219, GNorm = 0.3938, lr_0 = 4.2444e-04
Validation rmse = 0.808657
Epoch 12
Loss = 6.6350e-04, PNorm = 101.5583, GNorm = 0.2934, lr_0 = 4.0646e-04
Loss = 8.0554e-04, PNorm = 101.5930, GNorm = 0.5556, lr_0 = 3.8925e-04
Validation rmse = 0.777871
Epoch 13
Loss = 5.7689e-04, PNorm = 101.6262, GNorm = 0.3584, lr_0 = 3.7276e-04
Loss = 5.6605e-04, PNorm = 101.6597, GNorm = 0.3845, lr_0 = 3.5697e-04
Validation rmse = 0.793955
Epoch 14
Loss = 6.0084e-04, PNorm = 101.6903, GNorm = 0.2434, lr_0 = 3.4037e-04
Loss = 6.0021e-04, PNorm = 101.7270, GNorm = 0.3124, lr_0 = 3.2596e-04
Validation rmse = 0.818973
Epoch 15
Loss = 5.3072e-04, PNorm = 101.7487, GNorm = 0.3883, lr_0 = 3.1215e-04
Loss = 5.6829e-04, PNorm = 101.7782, GNorm = 0.2055, lr_0 = 2.9893e-04
Validation rmse = 0.815881
Epoch 16
Loss = 4.5820e-04, PNorm = 101.8094, GNorm = 0.1945, lr_0 = 2.8503e-04
Loss = 4.9847e-04, PNorm = 101.8350, GNorm = 0.3770, lr_0 = 2.7295e-04
Validation rmse = 0.785740
Epoch 17
Loss = 5.8251e-04, PNorm = 101.8556, GNorm = 0.3291, lr_0 = 2.6139e-04
Loss = 4.4677e-04, PNorm = 101.8774, GNorm = 0.3566, lr_0 = 2.5032e-04
Validation rmse = 0.814880
Epoch 18
Loss = 4.4478e-04, PNorm = 101.8963, GNorm = 0.2900, lr_0 = 2.3972e-04
Loss = 4.7054e-04, PNorm = 101.9195, GNorm = 0.2156, lr_0 = 2.2956e-04
Validation rmse = 0.809962
Epoch 19
Loss = 4.0206e-04, PNorm = 101.9400, GNorm = 0.3088, lr_0 = 2.1889e-04
Loss = 5.0961e-04, PNorm = 101.9590, GNorm = 0.3940, lr_0 = 2.0962e-04
Validation rmse = 0.783264
Epoch 20
Loss = 3.6294e-04, PNorm = 101.9736, GNorm = 0.4420, lr_0 = 2.0074e-04
Loss = 4.7299e-04, PNorm = 101.9921, GNorm = 0.2308, lr_0 = 1.9224e-04
Validation rmse = 0.797908
Epoch 21
Loss = 3.9227e-04, PNorm = 102.0083, GNorm = 0.2761, lr_0 = 1.8409e-04
Loss = 3.3451e-04, PNorm = 102.0253, GNorm = 0.1431, lr_0 = 1.7630e-04
Validation rmse = 0.787599
Epoch 22
Loss = 3.5982e-04, PNorm = 102.0413, GNorm = 0.4372, lr_0 = 1.6810e-04
Loss = 3.2800e-04, PNorm = 102.0556, GNorm = 0.2631, lr_0 = 1.6098e-04
Validation rmse = 0.827280
Epoch 23
Loss = 2.9148e-04, PNorm = 102.0676, GNorm = 0.2794, lr_0 = 1.5416e-04
Loss = 3.9243e-04, PNorm = 102.0811, GNorm = 0.2810, lr_0 = 1.4763e-04
Loss = 6.0491e-04, PNorm = 102.0823, GNorm = 0.3154, lr_0 = 1.4699e-04
Validation rmse = 0.808491
Epoch 24
Loss = 3.1607e-04, PNorm = 102.0960, GNorm = 0.2560, lr_0 = 1.4077e-04
Loss = 3.1646e-04, PNorm = 102.1076, GNorm = 0.1564, lr_0 = 1.3480e-04
Validation rmse = 0.798550
Epoch 25
Loss = 3.1802e-04, PNorm = 102.1186, GNorm = 0.2083, lr_0 = 1.2909e-04
Loss = 2.9030e-04, PNorm = 102.1283, GNorm = 0.2100, lr_0 = 1.2362e-04
Validation rmse = 0.807015
Epoch 26
Loss = 2.7862e-04, PNorm = 102.1371, GNorm = 0.1583, lr_0 = 1.1839e-04
Validation rmse = 0.810955
Epoch 27
Loss = 1.6422e-04, PNorm = 102.1479, GNorm = 0.1450, lr_0 = 1.1288e-04
Loss = 2.7300e-04, PNorm = 102.1578, GNorm = 0.2667, lr_0 = 1.0810e-04
Validation rmse = 0.800125
Epoch 28
Loss = 1.3757e-04, PNorm = 102.1676, GNorm = 0.1347, lr_0 = 1.0352e-04
Loss = 2.7963e-04, PNorm = 102.1762, GNorm = 0.2498, lr_0 = 1.0000e-04
Validation rmse = 0.799297
Epoch 29
Loss = 1.8909e-04, PNorm = 102.1842, GNorm = 0.1571, lr_0 = 1.0000e-04
Loss = 2.4389e-04, PNorm = 102.1927, GNorm = 0.2092, lr_0 = 1.0000e-04
Validation rmse = 0.806940
Model 0 best validation rmse = 0.777871 on epoch 12
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Moving model to cuda
Model 0 test rmse = 0.917974
Ensemble test rmse = 0.917974
Fold 3
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 2,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 2400,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 2400,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_2_dropout_0.0_ffn_num_layers_3_hidden_size_2400/fold_3',
 'save_smiles_splits': True,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total scaffolds = 195 | train scaffolds = 80 | val scaffolds = 54 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=2400, bias=False)
      (W_h): Linear(in_features=2400, out_features=2400, bias=False)
      (W_o): Linear(in_features=2533, out_features=2400, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=2404, out_features=2400, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=2400, out_features=2400, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=2400, out_features=1, bias=True)
  )
)
Number of parameters = 23,731,201
Moving model to cuda
Epoch 0
Loss = 1.2723e-02, PNorm = 99.7832, GNorm = 6.4547, lr_0 = 3.6053e-04
Validation rmse = 1.066833
Epoch 1
Loss = 3.2044e-03, PNorm = 99.9113, GNorm = 1.3289, lr_0 = 6.2105e-04
Loss = 2.6860e-03, PNorm = 100.0666, GNorm = 0.7806, lr_0 = 8.5789e-04
Validation rmse = 1.075501
Epoch 2
Loss = 1.9116e-03, PNorm = 100.2326, GNorm = 1.1160, lr_0 = 9.8284e-04
Loss = 2.6505e-03, PNorm = 100.3657, GNorm = 3.4231, lr_0 = 9.4120e-04
Validation rmse = 1.088149
Epoch 3
Loss = 2.3050e-03, PNorm = 100.5000, GNorm = 0.6700, lr_0 = 8.9744e-04
Loss = 2.1116e-03, PNorm = 100.6273, GNorm = 0.9894, lr_0 = 8.5943e-04
Validation rmse = 1.262907
Epoch 4
Loss = 2.5156e-03, PNorm = 100.7320, GNorm = 1.9882, lr_0 = 8.2303e-04
Loss = 1.6669e-03, PNorm = 100.8198, GNorm = 0.4586, lr_0 = 7.8816e-04
Validation rmse = 1.068011
Epoch 5
Loss = 1.3842e-03, PNorm = 100.8998, GNorm = 0.4270, lr_0 = 7.5478e-04
Loss = 1.3651e-03, PNorm = 100.9711, GNorm = 0.3373, lr_0 = 7.2281e-04
Validation rmse = 1.040238
Epoch 6
Loss = 1.0073e-03, PNorm = 101.0431, GNorm = 0.3559, lr_0 = 6.8920e-04
Loss = 1.1714e-03, PNorm = 101.0994, GNorm = 0.5445, lr_0 = 6.6001e-04
Validation rmse = 1.005071
Epoch 7
Loss = 1.1413e-03, PNorm = 101.1509, GNorm = 0.5055, lr_0 = 6.3205e-04
Loss = 9.5918e-04, PNorm = 101.1936, GNorm = 0.4360, lr_0 = 6.0528e-04
Validation rmse = 0.925579
Epoch 8
Loss = 1.0575e-03, PNorm = 101.2495, GNorm = 0.5835, lr_0 = 5.7714e-04
Loss = 7.9967e-04, PNorm = 101.2978, GNorm = 0.2467, lr_0 = 5.5269e-04
Validation rmse = 0.964822
Epoch 9
Loss = 8.3067e-04, PNorm = 101.3295, GNorm = 0.3096, lr_0 = 5.2928e-04
Loss = 7.8721e-04, PNorm = 101.3728, GNorm = 0.1872, lr_0 = 5.0686e-04
Validation rmse = 0.933464
Epoch 10
Loss = 7.0965e-04, PNorm = 101.4081, GNorm = 0.2226, lr_0 = 4.8539e-04
Loss = 7.2314e-04, PNorm = 101.4394, GNorm = 0.2386, lr_0 = 4.6483e-04
Validation rmse = 0.929389
Epoch 11
Loss = 6.2099e-04, PNorm = 101.4756, GNorm = 0.3119, lr_0 = 4.4322e-04
Loss = 8.1174e-04, PNorm = 101.5074, GNorm = 0.3762, lr_0 = 4.2444e-04
Validation rmse = 0.902477
Epoch 12
Loss = 5.9030e-04, PNorm = 101.5393, GNorm = 0.5000, lr_0 = 4.0646e-04
Loss = 5.2624e-04, PNorm = 101.5688, GNorm = 0.3788, lr_0 = 3.8925e-04
Validation rmse = 0.913922
Epoch 13
Loss = 6.6128e-04, PNorm = 101.5979, GNorm = 0.5043, lr_0 = 3.7276e-04
Loss = 6.5777e-04, PNorm = 101.6303, GNorm = 0.4189, lr_0 = 3.5697e-04
Validation rmse = 0.895242
Epoch 14
Loss = 5.8342e-04, PNorm = 101.6606, GNorm = 0.2682, lr_0 = 3.4037e-04
Loss = 5.0346e-04, PNorm = 101.6919, GNorm = 0.1617, lr_0 = 3.2596e-04
Validation rmse = 0.953925
Epoch 15
Loss = 5.2147e-04, PNorm = 101.7200, GNorm = 0.2561, lr_0 = 3.1215e-04
Loss = 5.1500e-04, PNorm = 101.7494, GNorm = 0.3187, lr_0 = 2.9893e-04
Validation rmse = 0.914176
Epoch 16
Loss = 4.0930e-04, PNorm = 101.7740, GNorm = 0.1468, lr_0 = 2.8503e-04
Loss = 5.5786e-04, PNorm = 101.7982, GNorm = 0.2789, lr_0 = 2.7295e-04
Validation rmse = 0.919259
Epoch 17
Loss = 4.0328e-04, PNorm = 101.8226, GNorm = 0.1907, lr_0 = 2.6139e-04
Loss = 4.3182e-04, PNorm = 101.8463, GNorm = 0.1897, lr_0 = 2.5032e-04
Validation rmse = 0.911748
Epoch 18
Loss = 3.6796e-04, PNorm = 101.8699, GNorm = 0.2343, lr_0 = 2.3972e-04
Loss = 3.7579e-04, PNorm = 101.8926, GNorm = 0.1741, lr_0 = 2.2956e-04
Validation rmse = 0.927832
Epoch 19
Loss = 4.0055e-04, PNorm = 101.9157, GNorm = 0.2463, lr_0 = 2.1889e-04
Loss = 3.8355e-04, PNorm = 101.9345, GNorm = 0.2408, lr_0 = 2.0962e-04
Validation rmse = 0.913328
Epoch 20
Loss = 3.5581e-04, PNorm = 101.9529, GNorm = 0.4123, lr_0 = 2.0074e-04
Loss = 4.1817e-04, PNorm = 101.9721, GNorm = 0.2650, lr_0 = 1.9224e-04
Validation rmse = 0.929822
Epoch 21
Loss = 3.2103e-04, PNorm = 101.9877, GNorm = 0.2624, lr_0 = 1.8409e-04
Loss = 3.8328e-04, PNorm = 102.0050, GNorm = 0.4115, lr_0 = 1.7630e-04
Validation rmse = 0.907549
Epoch 22
Loss = 3.3041e-04, PNorm = 102.0214, GNorm = 0.5297, lr_0 = 1.6810e-04
Loss = 3.8214e-04, PNorm = 102.0357, GNorm = 0.2327, lr_0 = 1.6098e-04
Validation rmse = 0.901774
Epoch 23
Loss = 2.9658e-04, PNorm = 102.0496, GNorm = 0.3011, lr_0 = 1.5416e-04
Loss = 3.3154e-04, PNorm = 102.0636, GNorm = 0.1910, lr_0 = 1.4763e-04
Loss = 3.8115e-04, PNorm = 102.0652, GNorm = 0.2737, lr_0 = 1.4699e-04
Validation rmse = 0.910382
Epoch 24
Loss = 2.9952e-04, PNorm = 102.0781, GNorm = 0.2687, lr_0 = 1.4077e-04
Loss = 3.0932e-04, PNorm = 102.0901, GNorm = 0.4099, lr_0 = 1.3480e-04
Validation rmse = 0.925872
Epoch 25
Loss = 2.7831e-04, PNorm = 102.1003, GNorm = 0.2767, lr_0 = 1.2909e-04
Loss = 3.1083e-04, PNorm = 102.1106, GNorm = 0.3541, lr_0 = 1.2362e-04
Validation rmse = 0.907605
Epoch 26
Loss = 2.8097e-04, PNorm = 102.1211, GNorm = 0.1654, lr_0 = 1.1839e-04
Validation rmse = 0.901157
Epoch 27
Loss = 5.2127e-04, PNorm = 102.1303, GNorm = 0.2158, lr_0 = 1.1288e-04
Loss = 2.7515e-04, PNorm = 102.1400, GNorm = 0.3850, lr_0 = 1.0810e-04
Validation rmse = 0.908520
Epoch 28
Loss = 1.6114e-04, PNorm = 102.1488, GNorm = 0.2388, lr_0 = 1.0352e-04
Loss = 2.4370e-04, PNorm = 102.1587, GNorm = 0.1872, lr_0 = 1.0000e-04
Validation rmse = 0.913181
Epoch 29
Loss = 3.3056e-04, PNorm = 102.1680, GNorm = 0.1776, lr_0 = 1.0000e-04
Loss = 2.4945e-04, PNorm = 102.1769, GNorm = 0.1501, lr_0 = 1.0000e-04
Validation rmse = 0.920064
Model 0 best validation rmse = 0.895242 on epoch 13
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Moving model to cuda
Model 0 test rmse = 0.688447
Ensemble test rmse = 0.688447
Fold 4
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 2,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 2400,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 2400,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_2_dropout_0.0_ffn_num_layers_3_hidden_size_2400/fold_4',
 'save_smiles_splits': True,
 'seed': 4,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 4
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 49 | test scaffolds = 62
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=2400, bias=False)
      (W_h): Linear(in_features=2400, out_features=2400, bias=False)
      (W_o): Linear(in_features=2533, out_features=2400, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=2404, out_features=2400, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=2400, out_features=2400, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=2400, out_features=1, bias=True)
  )
)
Number of parameters = 23,731,201
Moving model to cuda
Epoch 0
Loss = 9.3698e-03, PNorm = 99.7894, GNorm = 6.2016, lr_0 = 3.6053e-04
Validation rmse = 1.170168
Epoch 1
Loss = 4.5469e-03, PNorm = 99.9105, GNorm = 1.7112, lr_0 = 6.2105e-04
Loss = 2.8450e-03, PNorm = 100.0754, GNorm = 1.2450, lr_0 = 8.5789e-04
Validation rmse = 1.088991
Epoch 2
Loss = 2.2737e-03, PNorm = 100.2656, GNorm = 1.2973, lr_0 = 9.8284e-04
Loss = 1.9966e-03, PNorm = 100.4279, GNorm = 0.4910, lr_0 = 9.4120e-04
Validation rmse = 0.893375
Epoch 3
Loss = 1.4848e-03, PNorm = 100.5748, GNorm = 0.4926, lr_0 = 8.9744e-04
Loss = 1.5839e-03, PNorm = 100.6803, GNorm = 0.5879, lr_0 = 8.5943e-04
Validation rmse = 0.866027
Epoch 4
Loss = 1.6516e-03, PNorm = 100.7687, GNorm = 1.6152, lr_0 = 8.2303e-04
Loss = 1.3065e-03, PNorm = 100.8452, GNorm = 0.9202, lr_0 = 7.8816e-04
Validation rmse = 0.815290
Epoch 5
Loss = 9.7082e-04, PNorm = 100.9077, GNorm = 0.4809, lr_0 = 7.5478e-04
Loss = 1.1007e-03, PNorm = 100.9595, GNorm = 0.3273, lr_0 = 7.2281e-04
Validation rmse = 0.777693
Epoch 6
Loss = 1.0663e-03, PNorm = 101.0190, GNorm = 0.4670, lr_0 = 6.8920e-04
Loss = 1.2379e-03, PNorm = 101.0728, GNorm = 0.4172, lr_0 = 6.6001e-04
Validation rmse = 0.776674
Epoch 7
Loss = 7.2753e-04, PNorm = 101.1150, GNorm = 0.4884, lr_0 = 6.3205e-04
Loss = 1.2134e-03, PNorm = 101.1597, GNorm = 0.4929, lr_0 = 6.0528e-04
Validation rmse = 0.832070
Epoch 8
Loss = 1.0836e-03, PNorm = 101.2045, GNorm = 0.5382, lr_0 = 5.7714e-04
Loss = 9.2557e-04, PNorm = 101.2441, GNorm = 0.2903, lr_0 = 5.5269e-04
Validation rmse = 0.773173
Epoch 9
Loss = 7.0057e-04, PNorm = 101.2758, GNorm = 0.7856, lr_0 = 5.2928e-04
Loss = 9.5765e-04, PNorm = 101.3148, GNorm = 0.9437, lr_0 = 5.0686e-04
Validation rmse = 0.761871
Epoch 10
Loss = 8.2033e-04, PNorm = 101.3463, GNorm = 0.7425, lr_0 = 4.8539e-04
Loss = 1.0868e-03, PNorm = 101.3847, GNorm = 0.7090, lr_0 = 4.6483e-04
Validation rmse = 0.785243
Epoch 11
Loss = 1.0194e-03, PNorm = 101.4222, GNorm = 0.3511, lr_0 = 4.4322e-04
Loss = 7.7661e-04, PNorm = 101.4559, GNorm = 0.2418, lr_0 = 4.2444e-04
Validation rmse = 0.797073
Epoch 12
Loss = 4.5007e-04, PNorm = 101.4902, GNorm = 0.2154, lr_0 = 4.0646e-04
Loss = 8.3372e-04, PNorm = 101.5149, GNorm = 0.4713, lr_0 = 3.8925e-04
Validation rmse = 0.750189
Epoch 13
Loss = 6.3569e-04, PNorm = 101.5441, GNorm = 0.2959, lr_0 = 3.7276e-04
Loss = 7.2550e-04, PNorm = 101.5716, GNorm = 0.2683, lr_0 = 3.5697e-04
Validation rmse = 0.838938
Epoch 14
Loss = 5.7849e-04, PNorm = 101.6039, GNorm = 0.2798, lr_0 = 3.4037e-04
Loss = 6.6988e-04, PNorm = 101.6314, GNorm = 0.3376, lr_0 = 3.2596e-04
Validation rmse = 0.718646
Epoch 15
Loss = 5.0039e-04, PNorm = 101.6547, GNorm = 0.2068, lr_0 = 3.1215e-04
Loss = 6.3025e-04, PNorm = 101.6808, GNorm = 0.4821, lr_0 = 2.9893e-04
Validation rmse = 0.726854
Epoch 16
Loss = 4.7866e-04, PNorm = 101.7047, GNorm = 0.4084, lr_0 = 2.8503e-04
Loss = 6.5432e-04, PNorm = 101.7271, GNorm = 0.1661, lr_0 = 2.7295e-04
Validation rmse = 0.725042
Epoch 17
Loss = 4.6779e-04, PNorm = 101.7488, GNorm = 0.1609, lr_0 = 2.6139e-04
Loss = 5.1209e-04, PNorm = 101.7702, GNorm = 0.2388, lr_0 = 2.5032e-04
Validation rmse = 0.739748
Epoch 18
Loss = 5.3488e-04, PNorm = 101.7914, GNorm = 0.2594, lr_0 = 2.3972e-04
Loss = 4.8982e-04, PNorm = 101.8098, GNorm = 0.3964, lr_0 = 2.2956e-04
Validation rmse = 0.731916
Epoch 19
Loss = 4.1543e-04, PNorm = 101.8305, GNorm = 0.1202, lr_0 = 2.1889e-04
Loss = 5.0152e-04, PNorm = 101.8495, GNorm = 0.2782, lr_0 = 2.0962e-04
Validation rmse = 0.717196
Epoch 20
Loss = 4.7899e-04, PNorm = 101.8662, GNorm = 0.3092, lr_0 = 2.0074e-04
Loss = 4.1963e-04, PNorm = 101.8828, GNorm = 0.5456, lr_0 = 1.9224e-04
Validation rmse = 0.746292
Epoch 21
Loss = 3.9609e-04, PNorm = 101.8991, GNorm = 0.1970, lr_0 = 1.8409e-04
Loss = 4.1554e-04, PNorm = 101.9163, GNorm = 0.1971, lr_0 = 1.7630e-04
Validation rmse = 0.730599
Epoch 22
Loss = 3.4901e-04, PNorm = 101.9316, GNorm = 0.2211, lr_0 = 1.6810e-04
Loss = 4.2966e-04, PNorm = 101.9462, GNorm = 0.1003, lr_0 = 1.6098e-04
Validation rmse = 0.742762
Epoch 23
Loss = 3.8354e-04, PNorm = 101.9600, GNorm = 0.2207, lr_0 = 1.5416e-04
Loss = 3.4963e-04, PNorm = 101.9748, GNorm = 0.1022, lr_0 = 1.4763e-04
Loss = 6.7388e-04, PNorm = 101.9761, GNorm = 0.2708, lr_0 = 1.4699e-04
Validation rmse = 0.730712
Epoch 24
Loss = 3.6642e-04, PNorm = 101.9879, GNorm = 0.3113, lr_0 = 1.4077e-04
Loss = 3.6435e-04, PNorm = 102.0005, GNorm = 0.2612, lr_0 = 1.3480e-04
Validation rmse = 0.746205
Epoch 25
Loss = 3.1905e-04, PNorm = 102.0124, GNorm = 0.4695, lr_0 = 1.2909e-04
Loss = 3.7206e-04, PNorm = 102.0241, GNorm = 0.3801, lr_0 = 1.2362e-04
Validation rmse = 0.736871
Epoch 26
Loss = 2.7972e-04, PNorm = 102.0353, GNorm = 0.2589, lr_0 = 1.1839e-04
Validation rmse = 0.736572
Epoch 27
Loss = 2.4238e-04, PNorm = 102.0476, GNorm = 0.2413, lr_0 = 1.1288e-04
Loss = 3.0691e-04, PNorm = 102.0559, GNorm = 0.2099, lr_0 = 1.0810e-04
Validation rmse = 0.713882
Epoch 28
Loss = 3.1198e-04, PNorm = 102.0656, GNorm = 0.2382, lr_0 = 1.0352e-04
Loss = 3.1272e-04, PNorm = 102.0742, GNorm = 0.1359, lr_0 = 1.0000e-04
Validation rmse = 0.726052
Epoch 29
Loss = 2.6695e-04, PNorm = 102.0840, GNorm = 0.1431, lr_0 = 1.0000e-04
Loss = 3.1167e-04, PNorm = 102.0922, GNorm = 0.1409, lr_0 = 1.0000e-04
Validation rmse = 0.728731
Model 0 best validation rmse = 0.713882 on epoch 27
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Moving model to cuda
Model 0 test rmse = 0.829408
Ensemble test rmse = 0.829408
Fold 5
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 2,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 2400,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 2400,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_2_dropout_0.0_ffn_num_layers_3_hidden_size_2400/fold_5',
 'save_smiles_splits': True,
 'seed': 5,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 5
Total scaffolds = 195 | train scaffolds = 94 | val scaffolds = 55 | test scaffolds = 46
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=2400, bias=False)
      (W_h): Linear(in_features=2400, out_features=2400, bias=False)
      (W_o): Linear(in_features=2533, out_features=2400, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=2404, out_features=2400, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=2400, out_features=2400, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=2400, out_features=1, bias=True)
  )
)
Number of parameters = 23,731,201
Moving model to cuda
Epoch 0
Loss = 1.0530e-02, PNorm = 99.7829, GNorm = 3.8340, lr_0 = 3.6053e-04
Validation rmse = 1.453712
Epoch 1
Loss = 3.7787e-03, PNorm = 99.9131, GNorm = 3.1835, lr_0 = 6.2105e-04
Loss = 3.0201e-03, PNorm = 100.0842, GNorm = 1.1589, lr_0 = 8.5789e-04
Validation rmse = 1.066584
Epoch 2
Loss = 2.1145e-03, PNorm = 100.2921, GNorm = 0.7020, lr_0 = 9.8284e-04
Loss = 1.9370e-03, PNorm = 100.4683, GNorm = 1.0257, lr_0 = 9.4120e-04
Validation rmse = 0.999298
Epoch 3
Loss = 1.7640e-03, PNorm = 100.5996, GNorm = 0.5283, lr_0 = 8.9744e-04
Loss = 1.7219e-03, PNorm = 100.6910, GNorm = 0.8552, lr_0 = 8.5943e-04
Validation rmse = 0.930423
Epoch 4
Loss = 6.7737e-04, PNorm = 100.7610, GNorm = 0.2915, lr_0 = 8.2303e-04
Loss = 1.2160e-03, PNorm = 100.8260, GNorm = 0.5127, lr_0 = 7.8816e-04
Validation rmse = 0.942840
Epoch 5
Loss = 1.3608e-03, PNorm = 100.8869, GNorm = 0.7175, lr_0 = 7.5478e-04
Loss = 1.2040e-03, PNorm = 100.9400, GNorm = 0.8213, lr_0 = 7.2281e-04
Validation rmse = 0.919082
Epoch 6
Loss = 1.6390e-03, PNorm = 100.9874, GNorm = 0.5265, lr_0 = 6.8920e-04
Loss = 1.4854e-03, PNorm = 101.0361, GNorm = 0.4663, lr_0 = 6.6001e-04
Validation rmse = 0.809908
Epoch 7
Loss = 1.1395e-03, PNorm = 101.0885, GNorm = 0.3289, lr_0 = 6.3205e-04
Loss = 1.2163e-03, PNorm = 101.1345, GNorm = 0.2905, lr_0 = 6.0528e-04
Validation rmse = 0.787340
Epoch 8
Loss = 9.3187e-04, PNorm = 101.1761, GNorm = 0.3688, lr_0 = 5.7714e-04
Loss = 1.1828e-03, PNorm = 101.2124, GNorm = 0.4022, lr_0 = 5.5269e-04
Validation rmse = 0.864626
Epoch 9
Loss = 8.8123e-04, PNorm = 101.2477, GNorm = 0.3469, lr_0 = 5.2928e-04
Loss = 1.0025e-03, PNorm = 101.2848, GNorm = 0.3811, lr_0 = 5.0686e-04
Validation rmse = 0.858139
Epoch 10
Loss = 9.1372e-04, PNorm = 101.3145, GNorm = 0.2312, lr_0 = 4.8539e-04
Loss = 8.3005e-04, PNorm = 101.3434, GNorm = 0.4312, lr_0 = 4.6483e-04
Validation rmse = 0.881675
Epoch 11
Loss = 6.1880e-04, PNorm = 101.3765, GNorm = 0.3901, lr_0 = 4.4322e-04
Loss = 7.2349e-04, PNorm = 101.4082, GNorm = 0.2710, lr_0 = 4.2444e-04
Validation rmse = 0.792610
Epoch 12
Loss = 5.5558e-04, PNorm = 101.4370, GNorm = 0.3807, lr_0 = 4.0646e-04
Loss = 7.4530e-04, PNorm = 101.4634, GNorm = 0.4029, lr_0 = 3.8925e-04
Validation rmse = 0.911749
Epoch 13
Loss = 6.6747e-04, PNorm = 101.4890, GNorm = 0.5835, lr_0 = 3.7276e-04
Loss = 8.1943e-04, PNorm = 101.5126, GNorm = 0.7729, lr_0 = 3.5697e-04
Validation rmse = 0.854475
Epoch 14
Loss = 8.4622e-04, PNorm = 101.5437, GNorm = 0.2474, lr_0 = 3.4037e-04
Loss = 5.9224e-04, PNorm = 101.5661, GNorm = 0.3159, lr_0 = 3.2596e-04
Validation rmse = 0.866603
Epoch 15
Loss = 5.9775e-04, PNorm = 101.5898, GNorm = 0.5832, lr_0 = 3.1215e-04
Loss = 6.1425e-04, PNorm = 101.6158, GNorm = 0.3310, lr_0 = 2.9893e-04
Validation rmse = 0.867876
Epoch 16
Loss = 5.4487e-04, PNorm = 101.6405, GNorm = 0.1689, lr_0 = 2.8503e-04
Loss = 6.0349e-04, PNorm = 101.6613, GNorm = 0.2492, lr_0 = 2.7295e-04
Validation rmse = 0.802125
Epoch 17
Loss = 5.0067e-04, PNorm = 101.6798, GNorm = 0.3130, lr_0 = 2.6139e-04
Loss = 5.9537e-04, PNorm = 101.6994, GNorm = 0.4740, lr_0 = 2.5032e-04
Validation rmse = 0.825218
Epoch 18
Loss = 5.2149e-04, PNorm = 101.7160, GNorm = 0.1961, lr_0 = 2.3972e-04
Loss = 4.9393e-04, PNorm = 101.7369, GNorm = 0.2559, lr_0 = 2.2956e-04
Validation rmse = 0.809612
Epoch 19
Loss = 4.6869e-04, PNorm = 101.7567, GNorm = 0.4149, lr_0 = 2.1889e-04
Loss = 5.7845e-04, PNorm = 101.7752, GNorm = 0.2337, lr_0 = 2.0962e-04
Validation rmse = 0.828776
Epoch 20
Loss = 4.1348e-04, PNorm = 101.7957, GNorm = 0.1346, lr_0 = 2.0074e-04
Loss = 5.1609e-04, PNorm = 101.8116, GNorm = 0.4229, lr_0 = 1.9224e-04
Validation rmse = 0.830536
Epoch 21
Loss = 3.6896e-04, PNorm = 101.8250, GNorm = 0.3301, lr_0 = 1.8409e-04
Loss = 4.8080e-04, PNorm = 101.8407, GNorm = 0.1807, lr_0 = 1.7630e-04
Validation rmse = 0.846260
Epoch 22
Loss = 3.7439e-04, PNorm = 101.8571, GNorm = 0.1915, lr_0 = 1.6810e-04
Loss = 4.4655e-04, PNorm = 101.8716, GNorm = 0.2431, lr_0 = 1.6098e-04
Validation rmse = 0.799056
Epoch 23
Loss = 4.2258e-04, PNorm = 101.8829, GNorm = 0.2932, lr_0 = 1.5416e-04
Loss = 3.8590e-04, PNorm = 101.8965, GNorm = 0.3033, lr_0 = 1.4763e-04
Loss = 2.4810e-04, PNorm = 101.8976, GNorm = 0.2280, lr_0 = 1.4699e-04
Validation rmse = 0.829173
Epoch 24
Loss = 3.5238e-04, PNorm = 101.9086, GNorm = 0.2992, lr_0 = 1.4077e-04
Loss = 4.2400e-04, PNorm = 101.9182, GNorm = 0.3077, lr_0 = 1.3480e-04
Validation rmse = 0.821051
Epoch 25
Loss = 3.4397e-04, PNorm = 101.9306, GNorm = 0.2137, lr_0 = 1.2909e-04
Loss = 4.2103e-04, PNorm = 101.9403, GNorm = 0.3687, lr_0 = 1.2362e-04
Validation rmse = 0.837488
Epoch 26
Loss = 3.7671e-04, PNorm = 101.9504, GNorm = 0.2405, lr_0 = 1.1839e-04
Validation rmse = 0.787475
Epoch 27
Loss = 3.7664e-04, PNorm = 101.9623, GNorm = 0.2129, lr_0 = 1.1288e-04
Loss = 3.3265e-04, PNorm = 101.9711, GNorm = 0.2285, lr_0 = 1.0810e-04
Validation rmse = 0.773280
Epoch 28
Loss = 3.3263e-04, PNorm = 101.9805, GNorm = 0.3487, lr_0 = 1.0352e-04
Loss = 3.3760e-04, PNorm = 101.9893, GNorm = 0.3530, lr_0 = 1.0000e-04
Validation rmse = 0.802296
Epoch 29
Loss = 2.8074e-04, PNorm = 101.9978, GNorm = 0.2054, lr_0 = 1.0000e-04
Loss = 3.0068e-04, PNorm = 102.0050, GNorm = 0.1755, lr_0 = 1.0000e-04
Validation rmse = 0.801477
Model 0 best validation rmse = 0.773280 on epoch 27
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Moving model to cuda
Model 0 test rmse = 0.859361
Ensemble test rmse = 0.859361
Fold 6
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 2,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 2400,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 2400,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_2_dropout_0.0_ffn_num_layers_3_hidden_size_2400/fold_6',
 'save_smiles_splits': True,
 'seed': 6,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 6
Total scaffolds = 195 | train scaffolds = 64 | val scaffolds = 68 | test scaffolds = 63
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=2400, bias=False)
      (W_h): Linear(in_features=2400, out_features=2400, bias=False)
      (W_o): Linear(in_features=2533, out_features=2400, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=2404, out_features=2400, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=2400, out_features=2400, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=2400, out_features=1, bias=True)
  )
)
Number of parameters = 23,731,201
Moving model to cuda
Epoch 0
Loss = 1.3371e-02, PNorm = 99.7838, GNorm = 2.7916, lr_0 = 3.6053e-04
Validation rmse = 1.784212
Epoch 1
Loss = 3.4000e-03, PNorm = 99.9325, GNorm = 1.2462, lr_0 = 6.2105e-04
Loss = 3.2605e-03, PNorm = 100.1271, GNorm = 1.9004, lr_0 = 8.5789e-04
Validation rmse = 1.181982
Epoch 2
Loss = 1.7380e-03, PNorm = 100.3192, GNorm = 0.3361, lr_0 = 9.8284e-04
Loss = 1.8659e-03, PNorm = 100.4685, GNorm = 1.0207, lr_0 = 9.4120e-04
Validation rmse = 1.189403
Epoch 3
Loss = 1.6253e-03, PNorm = 100.5842, GNorm = 1.3514, lr_0 = 8.9744e-04
Loss = 1.4322e-03, PNorm = 100.6605, GNorm = 0.6275, lr_0 = 8.5943e-04
Validation rmse = 0.969551
Epoch 4
Loss = 1.3707e-03, PNorm = 100.7358, GNorm = 0.5622, lr_0 = 8.2303e-04
Loss = 1.3761e-03, PNorm = 100.7949, GNorm = 0.7069, lr_0 = 7.8816e-04
Validation rmse = 0.954970
Epoch 5
Loss = 9.1357e-04, PNorm = 100.8583, GNorm = 0.2863, lr_0 = 7.5478e-04
Loss = 1.1882e-03, PNorm = 100.9079, GNorm = 0.3770, lr_0 = 7.2281e-04
Validation rmse = 1.087079
Epoch 6
Loss = 9.3066e-04, PNorm = 100.9670, GNorm = 0.2244, lr_0 = 6.8920e-04
Loss = 1.1105e-03, PNorm = 101.0220, GNorm = 0.5342, lr_0 = 6.6001e-04
Validation rmse = 1.036311
Epoch 7
Loss = 1.4333e-03, PNorm = 101.0707, GNorm = 0.6248, lr_0 = 6.3205e-04
Loss = 1.1007e-03, PNorm = 101.1267, GNorm = 0.6865, lr_0 = 6.0528e-04
Validation rmse = 0.971411
Epoch 8
Loss = 7.3421e-04, PNorm = 101.1773, GNorm = 0.4347, lr_0 = 5.7714e-04
Loss = 8.5991e-04, PNorm = 101.2185, GNorm = 0.4915, lr_0 = 5.5269e-04
Validation rmse = 0.967815
Epoch 9
Loss = 7.3901e-04, PNorm = 101.2622, GNorm = 0.4834, lr_0 = 5.2928e-04
Loss = 7.7133e-04, PNorm = 101.2999, GNorm = 0.4749, lr_0 = 5.0686e-04
Validation rmse = 1.043242
Epoch 10
Loss = 7.2442e-04, PNorm = 101.3397, GNorm = 0.3343, lr_0 = 4.8539e-04
Loss = 6.0956e-04, PNorm = 101.3780, GNorm = 0.3144, lr_0 = 4.6483e-04
Validation rmse = 1.026276
Epoch 11
Loss = 7.9033e-04, PNorm = 101.4173, GNorm = 0.2915, lr_0 = 4.4322e-04
Loss = 6.2464e-04, PNorm = 101.4527, GNorm = 0.3162, lr_0 = 4.2444e-04
Validation rmse = 1.015540
Epoch 12
Loss = 4.9081e-04, PNorm = 101.4836, GNorm = 0.4216, lr_0 = 4.0646e-04
Loss = 7.5110e-04, PNorm = 101.5157, GNorm = 0.3035, lr_0 = 3.8925e-04
Validation rmse = 0.959420
Epoch 13
Loss = 6.3399e-04, PNorm = 101.5431, GNorm = 0.3034, lr_0 = 3.7276e-04
Loss = 7.7337e-04, PNorm = 101.5772, GNorm = 0.3897, lr_0 = 3.5697e-04
Validation rmse = 1.009844
Epoch 14
Loss = 5.1026e-04, PNorm = 101.6072, GNorm = 0.3362, lr_0 = 3.4037e-04
Loss = 6.1026e-04, PNorm = 101.6346, GNorm = 0.2187, lr_0 = 3.2596e-04
Validation rmse = 0.954257
Epoch 15
Loss = 5.8256e-04, PNorm = 101.6634, GNorm = 0.3893, lr_0 = 3.1215e-04
Loss = 4.5606e-04, PNorm = 101.6909, GNorm = 0.4356, lr_0 = 2.9893e-04
Validation rmse = 1.011113
Epoch 16
Loss = 4.7242e-04, PNorm = 101.7166, GNorm = 0.2049, lr_0 = 2.8503e-04
Loss = 4.9601e-04, PNorm = 101.7413, GNorm = 0.5424, lr_0 = 2.7295e-04
Validation rmse = 0.997740
Epoch 17
Loss = 5.0938e-04, PNorm = 101.7666, GNorm = 0.4014, lr_0 = 2.6139e-04
Loss = 4.8521e-04, PNorm = 101.7883, GNorm = 0.2835, lr_0 = 2.5032e-04
Validation rmse = 0.993196
Epoch 18
Loss = 4.6453e-04, PNorm = 101.8092, GNorm = 0.2394, lr_0 = 2.3972e-04
Loss = 4.8605e-04, PNorm = 101.8307, GNorm = 0.2974, lr_0 = 2.2956e-04
Validation rmse = 1.015282
Epoch 19
Loss = 3.9538e-04, PNorm = 101.8492, GNorm = 0.1645, lr_0 = 2.1889e-04
Loss = 4.2905e-04, PNorm = 101.8673, GNorm = 0.2525, lr_0 = 2.0962e-04
Validation rmse = 0.975320
Epoch 20
Loss = 3.2067e-04, PNorm = 101.8840, GNorm = 0.2860, lr_0 = 2.0074e-04
Loss = 3.6050e-04, PNorm = 101.9015, GNorm = 0.1524, lr_0 = 1.9224e-04
Validation rmse = 1.001485
Epoch 21
Loss = 3.9345e-04, PNorm = 101.9167, GNorm = 0.2629, lr_0 = 1.8409e-04
Loss = 3.2379e-04, PNorm = 101.9316, GNorm = 0.1389, lr_0 = 1.7630e-04
Validation rmse = 1.010458
Epoch 22
Loss = 3.1373e-04, PNorm = 101.9490, GNorm = 0.2211, lr_0 = 1.6810e-04
Loss = 3.1804e-04, PNorm = 101.9596, GNorm = 0.2069, lr_0 = 1.6098e-04
Validation rmse = 1.014371
Epoch 23
Loss = 3.1318e-04, PNorm = 101.9719, GNorm = 0.2217, lr_0 = 1.5416e-04
Loss = 2.9192e-04, PNorm = 101.9834, GNorm = 0.2067, lr_0 = 1.4763e-04
Loss = 7.5653e-04, PNorm = 101.9846, GNorm = 0.3962, lr_0 = 1.4699e-04
Validation rmse = 0.998137
Epoch 24
Loss = 3.0162e-04, PNorm = 101.9983, GNorm = 0.1420, lr_0 = 1.4077e-04
Loss = 2.6579e-04, PNorm = 102.0091, GNorm = 0.1969, lr_0 = 1.3480e-04
Validation rmse = 1.006888
Epoch 25
Loss = 3.0200e-04, PNorm = 102.0188, GNorm = 0.4186, lr_0 = 1.2909e-04
Loss = 2.6144e-04, PNorm = 102.0302, GNorm = 0.3370, lr_0 = 1.2362e-04
Validation rmse = 0.980223
Epoch 26
Loss = 2.3682e-04, PNorm = 102.0401, GNorm = 0.1525, lr_0 = 1.1839e-04
Validation rmse = 0.993847
Epoch 27
Loss = 3.6626e-04, PNorm = 102.0510, GNorm = 0.2862, lr_0 = 1.1288e-04
Loss = 2.5331e-04, PNorm = 102.0607, GNorm = 0.1637, lr_0 = 1.0810e-04
Validation rmse = 0.986805
Epoch 28
Loss = 2.6197e-04, PNorm = 102.0692, GNorm = 0.2134, lr_0 = 1.0352e-04
Loss = 2.3558e-04, PNorm = 102.0767, GNorm = 0.1423, lr_0 = 1.0000e-04
Validation rmse = 0.996964
Epoch 29
Loss = 2.5854e-04, PNorm = 102.0853, GNorm = 0.2238, lr_0 = 1.0000e-04
Loss = 2.2517e-04, PNorm = 102.0937, GNorm = 0.2074, lr_0 = 1.0000e-04
Validation rmse = 1.015291
Model 0 best validation rmse = 0.954257 on epoch 14
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Moving model to cuda
Model 0 test rmse = 0.741424
Ensemble test rmse = 0.741424
Fold 7
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 2,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 2400,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 2400,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_2_dropout_0.0_ffn_num_layers_3_hidden_size_2400/fold_7',
 'save_smiles_splits': True,
 'seed': 7,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 7
Total scaffolds = 195 | train scaffolds = 69 | val scaffolds = 65 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=2400, bias=False)
      (W_h): Linear(in_features=2400, out_features=2400, bias=False)
      (W_o): Linear(in_features=2533, out_features=2400, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=2404, out_features=2400, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=2400, out_features=2400, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=2400, out_features=1, bias=True)
  )
)
Number of parameters = 23,731,201
Moving model to cuda
Epoch 0
Loss = 1.1158e-02, PNorm = 99.7868, GNorm = 1.4234, lr_0 = 3.6053e-04
Validation rmse = 2.301457
Epoch 1
Loss = 5.7846e-03, PNorm = 99.9121, GNorm = 2.4217, lr_0 = 6.2105e-04
Loss = 3.4539e-03, PNorm = 100.1040, GNorm = 0.9125, lr_0 = 8.5789e-04
Validation rmse = 1.148955
Epoch 2
Loss = 2.0864e-03, PNorm = 100.3245, GNorm = 1.3794, lr_0 = 9.8284e-04
Loss = 2.4856e-03, PNorm = 100.4986, GNorm = 0.7891, lr_0 = 9.4120e-04
Validation rmse = 1.233335
Epoch 3
Loss = 2.1294e-03, PNorm = 100.6439, GNorm = 0.8605, lr_0 = 8.9744e-04
Loss = 1.6202e-03, PNorm = 100.7351, GNorm = 0.8617, lr_0 = 8.5943e-04
Validation rmse = 1.155238
Epoch 4
Loss = 1.5051e-03, PNorm = 100.8053, GNorm = 0.4228, lr_0 = 8.2303e-04
Loss = 1.3135e-03, PNorm = 100.8604, GNorm = 1.2853, lr_0 = 7.8816e-04
Validation rmse = 1.026997
Epoch 5
Loss = 1.1186e-03, PNorm = 100.9130, GNorm = 0.3199, lr_0 = 7.5478e-04
Loss = 1.4572e-03, PNorm = 100.9722, GNorm = 0.8743, lr_0 = 7.2281e-04
Validation rmse = 1.073047
Epoch 6
Loss = 1.5589e-03, PNorm = 101.0350, GNorm = 0.4230, lr_0 = 6.8920e-04
Loss = 1.0919e-03, PNorm = 101.0957, GNorm = 0.4671, lr_0 = 6.6001e-04
Validation rmse = 1.100317
Epoch 7
Loss = 9.6893e-04, PNorm = 101.1468, GNorm = 0.1888, lr_0 = 6.3205e-04
Loss = 1.0703e-03, PNorm = 101.1961, GNorm = 0.2195, lr_0 = 6.0528e-04
Validation rmse = 1.275625
Epoch 8
Loss = 1.2882e-03, PNorm = 101.2426, GNorm = 0.8310, lr_0 = 5.7714e-04
Loss = 1.1503e-03, PNorm = 101.2867, GNorm = 0.7398, lr_0 = 5.5269e-04
Validation rmse = 1.229936
Epoch 9
Loss = 8.8925e-04, PNorm = 101.3268, GNorm = 0.1682, lr_0 = 5.2928e-04
Loss = 9.4327e-04, PNorm = 101.3622, GNorm = 0.4400, lr_0 = 5.0686e-04
Validation rmse = 1.141249
Epoch 10
Loss = 9.8050e-04, PNorm = 101.3940, GNorm = 0.5145, lr_0 = 4.8539e-04
Loss = 7.0734e-04, PNorm = 101.4327, GNorm = 0.4117, lr_0 = 4.6483e-04
Validation rmse = 1.052227
Epoch 11
Loss = 6.4481e-04, PNorm = 101.4627, GNorm = 0.4183, lr_0 = 4.4322e-04
Loss = 7.3792e-04, PNorm = 101.4941, GNorm = 0.2364, lr_0 = 4.2444e-04
Validation rmse = 1.094931
Epoch 12
Loss = 6.8661e-04, PNorm = 101.5240, GNorm = 0.2108, lr_0 = 4.0646e-04
Loss = 6.1900e-04, PNorm = 101.5531, GNorm = 0.5009, lr_0 = 3.8925e-04
Validation rmse = 1.050327
Epoch 13
Loss = 7.0178e-04, PNorm = 101.5857, GNorm = 0.3333, lr_0 = 3.7276e-04
Loss = 6.5884e-04, PNorm = 101.6185, GNorm = 0.2076, lr_0 = 3.5697e-04
Validation rmse = 1.085286
Epoch 14
Loss = 4.7497e-04, PNorm = 101.6505, GNorm = 0.3496, lr_0 = 3.4037e-04
Loss = 6.1082e-04, PNorm = 101.6744, GNorm = 0.3031, lr_0 = 3.2596e-04
Validation rmse = 1.123158
Epoch 15
Loss = 6.4400e-04, PNorm = 101.7006, GNorm = 0.3215, lr_0 = 3.1215e-04
Loss = 4.9392e-04, PNorm = 101.7224, GNorm = 0.3444, lr_0 = 2.9893e-04
Validation rmse = 1.114826
Epoch 16
Loss = 4.8042e-04, PNorm = 101.7482, GNorm = 0.1491, lr_0 = 2.8503e-04
Loss = 5.4706e-04, PNorm = 101.7717, GNorm = 0.4679, lr_0 = 2.7295e-04
Validation rmse = 1.120276
Epoch 17
Loss = 4.2114e-04, PNorm = 101.7920, GNorm = 0.2389, lr_0 = 2.6139e-04
Loss = 5.8203e-04, PNorm = 101.8118, GNorm = 0.3026, lr_0 = 2.5032e-04
Validation rmse = 1.102576
Epoch 18
Loss = 4.8878e-04, PNorm = 101.8323, GNorm = 0.5291, lr_0 = 2.3972e-04
Loss = 5.1496e-04, PNorm = 101.8529, GNorm = 0.2182, lr_0 = 2.2956e-04
Validation rmse = 1.113572
Epoch 19
Loss = 4.6623e-04, PNorm = 101.8735, GNorm = 0.2836, lr_0 = 2.1889e-04
Loss = 4.2930e-04, PNorm = 101.8916, GNorm = 0.3354, lr_0 = 2.0962e-04
Validation rmse = 1.119764
Epoch 20
Loss = 4.9135e-04, PNorm = 101.9075, GNorm = 0.4571, lr_0 = 2.0074e-04
Loss = 4.2989e-04, PNorm = 101.9231, GNorm = 0.1766, lr_0 = 1.9224e-04
Validation rmse = 1.130849
Epoch 21
Loss = 3.6692e-04, PNorm = 101.9386, GNorm = 0.3227, lr_0 = 1.8409e-04
Loss = 4.7516e-04, PNorm = 101.9524, GNorm = 0.1818, lr_0 = 1.7630e-04
Validation rmse = 1.150901
Epoch 22
Loss = 3.4382e-04, PNorm = 101.9705, GNorm = 0.3009, lr_0 = 1.6810e-04
Loss = 4.2704e-04, PNorm = 101.9823, GNorm = 0.2925, lr_0 = 1.6098e-04
Validation rmse = 1.148622
Epoch 23
Loss = 3.8968e-04, PNorm = 101.9963, GNorm = 0.1872, lr_0 = 1.5416e-04
Loss = 3.2332e-04, PNorm = 102.0083, GNorm = 0.2298, lr_0 = 1.4763e-04
Loss = 4.5370e-04, PNorm = 102.0094, GNorm = 0.4353, lr_0 = 1.4699e-04
Validation rmse = 1.128567
Epoch 24
Loss = 3.3175e-04, PNorm = 102.0197, GNorm = 0.2247, lr_0 = 1.4077e-04
Loss = 3.7247e-04, PNorm = 102.0319, GNorm = 0.5200, lr_0 = 1.3480e-04
Validation rmse = 1.141651
Epoch 25
Loss = 3.0738e-04, PNorm = 102.0412, GNorm = 0.1258, lr_0 = 1.2909e-04
Loss = 4.0441e-04, PNorm = 102.0528, GNorm = 0.3375, lr_0 = 1.2362e-04
Validation rmse = 1.111608
Epoch 26
Loss = 2.9609e-04, PNorm = 102.0632, GNorm = 0.1399, lr_0 = 1.1839e-04
Validation rmse = 1.143411
Epoch 27
Loss = 1.6532e-04, PNorm = 102.0739, GNorm = 0.1884, lr_0 = 1.1288e-04
Loss = 2.9164e-04, PNorm = 102.0830, GNorm = 0.3042, lr_0 = 1.0810e-04
Validation rmse = 1.158580
Epoch 28
Loss = 1.4246e-04, PNorm = 102.0911, GNorm = 0.1154, lr_0 = 1.0352e-04
Loss = 2.9154e-04, PNorm = 102.0989, GNorm = 0.2684, lr_0 = 1.0000e-04
Validation rmse = 1.154369
Epoch 29
Loss = 3.8587e-04, PNorm = 102.1081, GNorm = 0.2082, lr_0 = 1.0000e-04
Loss = 2.5204e-04, PNorm = 102.1150, GNorm = 0.1895, lr_0 = 1.0000e-04
Validation rmse = 1.145154
Model 0 best validation rmse = 1.026997 on epoch 4
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Moving model to cuda
Model 0 test rmse = 0.819596
Ensemble test rmse = 0.819596
Fold 8
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 2,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 2400,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 2400,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_2_dropout_0.0_ffn_num_layers_3_hidden_size_2400/fold_8',
 'save_smiles_splits': True,
 'seed': 8,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 8
Total scaffolds = 195 | train scaffolds = 75 | val scaffolds = 42 | test scaffolds = 78
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=2400, bias=False)
      (W_h): Linear(in_features=2400, out_features=2400, bias=False)
      (W_o): Linear(in_features=2533, out_features=2400, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=2404, out_features=2400, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=2400, out_features=2400, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=2400, out_features=1, bias=True)
  )
)
Number of parameters = 23,731,201
Moving model to cuda
Epoch 0
Loss = 1.3280e-02, PNorm = 99.7826, GNorm = 4.8122, lr_0 = 3.6053e-04
Validation rmse = 1.563273
Epoch 1
Loss = 2.1407e-03, PNorm = 99.9345, GNorm = 1.1375, lr_0 = 6.2105e-04
Loss = 3.4215e-03, PNorm = 100.1232, GNorm = 2.2220, lr_0 = 8.5789e-04
Validation rmse = 1.065846
Epoch 2
Loss = 3.6403e-03, PNorm = 100.3175, GNorm = 2.1758, lr_0 = 9.8284e-04
Loss = 2.1813e-03, PNorm = 100.4764, GNorm = 1.2680, lr_0 = 9.4120e-04
Validation rmse = 0.871226
Epoch 3
Loss = 1.3997e-03, PNorm = 100.6079, GNorm = 0.6080, lr_0 = 8.9744e-04
Loss = 1.6282e-03, PNorm = 100.7030, GNorm = 0.7743, lr_0 = 8.5943e-04
Validation rmse = 0.924476
Epoch 4
Loss = 2.0089e-03, PNorm = 100.7884, GNorm = 0.8174, lr_0 = 8.2303e-04
Loss = 1.4785e-03, PNorm = 100.8527, GNorm = 0.3142, lr_0 = 7.8816e-04
Validation rmse = 0.775058
Epoch 5
Loss = 8.4415e-04, PNorm = 100.9106, GNorm = 0.6331, lr_0 = 7.5478e-04
Loss = 1.3143e-03, PNorm = 100.9691, GNorm = 0.4223, lr_0 = 7.2281e-04
Validation rmse = 0.748161
Epoch 6
Loss = 8.1718e-04, PNorm = 101.0179, GNorm = 0.4122, lr_0 = 6.8920e-04
Loss = 1.2470e-03, PNorm = 101.0611, GNorm = 0.2933, lr_0 = 6.6001e-04
Validation rmse = 0.763461
Epoch 7
Loss = 1.0366e-03, PNorm = 101.0991, GNorm = 0.4028, lr_0 = 6.3205e-04
Loss = 1.0471e-03, PNorm = 101.1358, GNorm = 0.6940, lr_0 = 6.0528e-04
Validation rmse = 0.749989
Epoch 8
Loss = 1.2262e-03, PNorm = 101.1827, GNorm = 0.6526, lr_0 = 5.7714e-04
Loss = 8.3841e-04, PNorm = 101.2211, GNorm = 0.3888, lr_0 = 5.5269e-04
Validation rmse = 0.735584
Epoch 9
Loss = 6.6787e-04, PNorm = 101.2562, GNorm = 0.2951, lr_0 = 5.2928e-04
Loss = 7.2960e-04, PNorm = 101.2870, GNorm = 0.2654, lr_0 = 5.0686e-04
Validation rmse = 0.744216
Epoch 10
Loss = 8.4178e-04, PNorm = 101.3194, GNorm = 0.4691, lr_0 = 4.8539e-04
Loss = 8.2623e-04, PNorm = 101.3582, GNorm = 0.3714, lr_0 = 4.6483e-04
Validation rmse = 0.727717
Epoch 11
Loss = 7.4230e-04, PNorm = 101.3936, GNorm = 0.3311, lr_0 = 4.4322e-04
Loss = 6.4966e-04, PNorm = 101.4332, GNorm = 0.1576, lr_0 = 4.2444e-04
Validation rmse = 0.738548
Epoch 12
Loss = 6.1192e-04, PNorm = 101.4677, GNorm = 0.3737, lr_0 = 4.0646e-04
Loss = 5.7183e-04, PNorm = 101.4957, GNorm = 0.2029, lr_0 = 3.8925e-04
Validation rmse = 0.718495
Epoch 13
Loss = 6.9427e-04, PNorm = 101.5234, GNorm = 0.4404, lr_0 = 3.7276e-04
Loss = 6.1482e-04, PNorm = 101.5493, GNorm = 0.3116, lr_0 = 3.5697e-04
Validation rmse = 0.743202
Epoch 14
Loss = 6.5672e-04, PNorm = 101.5828, GNorm = 0.5215, lr_0 = 3.4037e-04
Loss = 5.7182e-04, PNorm = 101.6116, GNorm = 0.2045, lr_0 = 3.2596e-04
Validation rmse = 0.717441
Epoch 15
Loss = 4.8451e-04, PNorm = 101.6384, GNorm = 0.4339, lr_0 = 3.1215e-04
Loss = 5.6374e-04, PNorm = 101.6633, GNorm = 0.2134, lr_0 = 2.9893e-04
Validation rmse = 0.712311
Epoch 16
Loss = 5.2910e-04, PNorm = 101.6908, GNorm = 0.2579, lr_0 = 2.8503e-04
Loss = 5.0208e-04, PNorm = 101.7140, GNorm = 0.4701, lr_0 = 2.7295e-04
Validation rmse = 0.728473
Epoch 17
Loss = 5.1656e-04, PNorm = 101.7313, GNorm = 0.2421, lr_0 = 2.6139e-04
Loss = 5.4168e-04, PNorm = 101.7559, GNorm = 0.1862, lr_0 = 2.5032e-04
Validation rmse = 0.744645
Epoch 18
Loss = 5.6008e-04, PNorm = 101.7766, GNorm = 0.3859, lr_0 = 2.3972e-04
Loss = 4.5828e-04, PNorm = 101.7938, GNorm = 0.1630, lr_0 = 2.2956e-04
Validation rmse = 0.701676
Epoch 19
Loss = 4.0710e-04, PNorm = 101.8135, GNorm = 0.2463, lr_0 = 2.1889e-04
Loss = 4.3965e-04, PNorm = 101.8300, GNorm = 0.2878, lr_0 = 2.0962e-04
Validation rmse = 0.707765
Epoch 20
Loss = 3.5646e-04, PNorm = 101.8471, GNorm = 0.2177, lr_0 = 2.0074e-04
Loss = 4.4120e-04, PNorm = 101.8651, GNorm = 0.1866, lr_0 = 1.9224e-04
Validation rmse = 0.714740
Epoch 21
Loss = 3.8365e-04, PNorm = 101.8842, GNorm = 0.1887, lr_0 = 1.8409e-04
Loss = 3.8031e-04, PNorm = 101.8980, GNorm = 0.2313, lr_0 = 1.7630e-04
Validation rmse = 0.707484
Epoch 22
Loss = 3.2536e-04, PNorm = 101.9131, GNorm = 0.1486, lr_0 = 1.6810e-04
Loss = 3.7950e-04, PNorm = 101.9275, GNorm = 0.1919, lr_0 = 1.6098e-04
Validation rmse = 0.705941
Epoch 23
Loss = 3.3884e-04, PNorm = 101.9404, GNorm = 0.4623, lr_0 = 1.5416e-04
Loss = 3.4516e-04, PNorm = 101.9545, GNorm = 0.1019, lr_0 = 1.4763e-04
Loss = 3.9589e-04, PNorm = 101.9557, GNorm = 0.1538, lr_0 = 1.4699e-04
Validation rmse = 0.704879
Epoch 24
Loss = 3.4460e-04, PNorm = 101.9661, GNorm = 0.2540, lr_0 = 1.4077e-04
Loss = 3.4946e-04, PNorm = 101.9787, GNorm = 0.2473, lr_0 = 1.3480e-04
Validation rmse = 0.704269
Epoch 25
Loss = 3.1895e-04, PNorm = 101.9891, GNorm = 0.2202, lr_0 = 1.2909e-04
Loss = 3.1442e-04, PNorm = 101.9992, GNorm = 0.2243, lr_0 = 1.2362e-04
Validation rmse = 0.701080
Epoch 26
Loss = 3.3446e-04, PNorm = 102.0116, GNorm = 0.2248, lr_0 = 1.1839e-04
Validation rmse = 0.701175
Epoch 27
Loss = 4.3973e-04, PNorm = 102.0214, GNorm = 0.4458, lr_0 = 1.1288e-04
Loss = 2.7234e-04, PNorm = 102.0298, GNorm = 0.2130, lr_0 = 1.0810e-04
Validation rmse = 0.707927
Epoch 28
Loss = 2.5284e-04, PNorm = 102.0383, GNorm = 0.1807, lr_0 = 1.0352e-04
Loss = 2.8854e-04, PNorm = 102.0472, GNorm = 0.1109, lr_0 = 1.0000e-04
Validation rmse = 0.700506
Epoch 29
Loss = 2.7702e-04, PNorm = 102.0562, GNorm = 0.1637, lr_0 = 1.0000e-04
Loss = 2.5077e-04, PNorm = 102.0651, GNorm = 0.4604, lr_0 = 1.0000e-04
Validation rmse = 0.701358
Model 0 best validation rmse = 0.700506 on epoch 28
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Moving model to cuda
Model 0 test rmse = 0.873806
Ensemble test rmse = 0.873806
Fold 9
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 2,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 2400,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 2400,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_2_dropout_0.0_ffn_num_layers_3_hidden_size_2400/fold_9',
 'save_smiles_splits': True,
 'seed': 9,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 9
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 58 | test scaffolds = 53
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=2400, bias=False)
      (W_h): Linear(in_features=2400, out_features=2400, bias=False)
      (W_o): Linear(in_features=2533, out_features=2400, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=2404, out_features=2400, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=2400, out_features=2400, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=2400, out_features=1, bias=True)
  )
)
Number of parameters = 23,731,201
Moving model to cuda
Epoch 0
Loss = 1.2851e-02, PNorm = 99.7880, GNorm = 1.5558, lr_0 = 3.6053e-04
Validation rmse = 1.153855
Epoch 1
Loss = 2.9534e-03, PNorm = 99.9236, GNorm = 1.1875, lr_0 = 6.2105e-04
Loss = 4.1687e-03, PNorm = 100.1042, GNorm = 1.4676, lr_0 = 8.5789e-04
Validation rmse = 1.140569
Epoch 2
Loss = 1.9332e-03, PNorm = 100.3289, GNorm = 0.8563, lr_0 = 9.8284e-04
Loss = 2.1666e-03, PNorm = 100.5130, GNorm = 0.9754, lr_0 = 9.4120e-04
Validation rmse = 0.996726
Epoch 3
Loss = 2.3704e-03, PNorm = 100.6492, GNorm = 1.2122, lr_0 = 8.9744e-04
Loss = 1.8353e-03, PNorm = 100.7479, GNorm = 0.6293, lr_0 = 8.5943e-04
Validation rmse = 0.698357
Epoch 4
Loss = 1.1742e-03, PNorm = 100.8276, GNorm = 0.2743, lr_0 = 8.2303e-04
Loss = 1.1851e-03, PNorm = 100.8806, GNorm = 0.4120, lr_0 = 7.8816e-04
Validation rmse = 0.720638
Epoch 5
Loss = 1.1040e-03, PNorm = 100.9275, GNorm = 0.6649, lr_0 = 7.5478e-04
Loss = 1.2236e-03, PNorm = 100.9737, GNorm = 0.4621, lr_0 = 7.2281e-04
Validation rmse = 0.714476
Epoch 6
Loss = 1.1218e-03, PNorm = 101.0222, GNorm = 1.0237, lr_0 = 6.8920e-04
Loss = 1.1819e-03, PNorm = 101.0598, GNorm = 0.7433, lr_0 = 6.6001e-04
Validation rmse = 0.685245
Epoch 7
Loss = 1.0998e-03, PNorm = 101.1079, GNorm = 0.5507, lr_0 = 6.3205e-04
Loss = 1.0065e-03, PNorm = 101.1523, GNorm = 0.7182, lr_0 = 6.0528e-04
Validation rmse = 0.729465
Epoch 8
Loss = 7.6055e-04, PNorm = 101.1934, GNorm = 0.2455, lr_0 = 5.7714e-04
Loss = 9.3399e-04, PNorm = 101.2296, GNorm = 0.6161, lr_0 = 5.5269e-04
Validation rmse = 0.713709
Epoch 9
Loss = 7.3132e-04, PNorm = 101.2641, GNorm = 0.3241, lr_0 = 5.2928e-04
Loss = 7.4138e-04, PNorm = 101.2980, GNorm = 0.4676, lr_0 = 5.0686e-04
Validation rmse = 0.709258
Epoch 10
Loss = 5.1663e-04, PNorm = 101.3329, GNorm = 0.3020, lr_0 = 4.8539e-04
Loss = 7.5922e-04, PNorm = 101.3689, GNorm = 0.3339, lr_0 = 4.6483e-04
Validation rmse = 0.670397
Epoch 11
Loss = 8.0473e-04, PNorm = 101.4059, GNorm = 0.4722, lr_0 = 4.4322e-04
Loss = 8.3662e-04, PNorm = 101.4416, GNorm = 0.2500, lr_0 = 4.2444e-04
Validation rmse = 0.676351
Epoch 12
Loss = 7.1018e-04, PNorm = 101.4761, GNorm = 0.2627, lr_0 = 4.0646e-04
Loss = 6.9315e-04, PNorm = 101.5107, GNorm = 0.2328, lr_0 = 3.8925e-04
Validation rmse = 0.693996
Epoch 13
Loss = 6.6363e-04, PNorm = 101.5395, GNorm = 0.5539, lr_0 = 3.7276e-04
Loss = 6.3612e-04, PNorm = 101.5706, GNorm = 0.3194, lr_0 = 3.5697e-04
Validation rmse = 0.721457
Epoch 14
Loss = 5.1947e-04, PNorm = 101.5992, GNorm = 0.5914, lr_0 = 3.4037e-04
Loss = 5.1376e-04, PNorm = 101.6207, GNorm = 0.3366, lr_0 = 3.2596e-04
Validation rmse = 0.670281
Epoch 15
Loss = 4.1870e-04, PNorm = 101.6466, GNorm = 0.3648, lr_0 = 3.1215e-04
Loss = 5.6670e-04, PNorm = 101.6713, GNorm = 0.5920, lr_0 = 2.9893e-04
Validation rmse = 0.693133
Epoch 16
Loss = 5.9221e-04, PNorm = 101.6976, GNorm = 0.6581, lr_0 = 2.8503e-04
Loss = 4.8706e-04, PNorm = 101.7174, GNorm = 0.2902, lr_0 = 2.7295e-04
Validation rmse = 0.708167
Epoch 17
Loss = 5.0091e-04, PNorm = 101.7367, GNorm = 0.3293, lr_0 = 2.6139e-04
Loss = 5.6132e-04, PNorm = 101.7563, GNorm = 0.3597, lr_0 = 2.5032e-04
Validation rmse = 0.697679
Epoch 18
Loss = 3.8229e-04, PNorm = 101.7760, GNorm = 0.1756, lr_0 = 2.3972e-04
Loss = 5.2882e-04, PNorm = 101.7942, GNorm = 0.6077, lr_0 = 2.2956e-04
Validation rmse = 0.670353
Epoch 19
Loss = 4.0364e-04, PNorm = 101.8142, GNorm = 0.2202, lr_0 = 2.1889e-04
Loss = 5.2280e-04, PNorm = 101.8339, GNorm = 0.3253, lr_0 = 2.0962e-04
Validation rmse = 0.669568
Epoch 20
Loss = 4.4919e-04, PNorm = 101.8490, GNorm = 0.3896, lr_0 = 2.0074e-04
Loss = 4.0542e-04, PNorm = 101.8621, GNorm = 0.2918, lr_0 = 1.9224e-04
Validation rmse = 0.687784
Epoch 21
Loss = 3.0115e-04, PNorm = 101.8744, GNorm = 0.1516, lr_0 = 1.8409e-04
Loss = 3.9049e-04, PNorm = 101.8885, GNorm = 0.3526, lr_0 = 1.7630e-04
Validation rmse = 0.668273
Epoch 22
Loss = 4.0558e-04, PNorm = 101.9044, GNorm = 0.3143, lr_0 = 1.6810e-04
Loss = 3.3588e-04, PNorm = 101.9170, GNorm = 0.3446, lr_0 = 1.6098e-04
Validation rmse = 0.673431
Epoch 23
Loss = 3.2367e-04, PNorm = 101.9286, GNorm = 0.2427, lr_0 = 1.5416e-04
Loss = 3.4843e-04, PNorm = 101.9410, GNorm = 0.2024, lr_0 = 1.4763e-04
Loss = 5.5521e-04, PNorm = 101.9422, GNorm = 0.4572, lr_0 = 1.4699e-04
Validation rmse = 0.677984
Epoch 24
Loss = 3.2428e-04, PNorm = 101.9539, GNorm = 0.1408, lr_0 = 1.4077e-04
Loss = 3.3467e-04, PNorm = 101.9643, GNorm = 0.2436, lr_0 = 1.3480e-04
Validation rmse = 0.674496
Epoch 25
Loss = 3.2875e-04, PNorm = 101.9749, GNorm = 0.1536, lr_0 = 1.2909e-04
Loss = 3.0295e-04, PNorm = 101.9836, GNorm = 0.2838, lr_0 = 1.2362e-04
Validation rmse = 0.684018
Epoch 26
Loss = 2.5204e-04, PNorm = 101.9924, GNorm = 0.0958, lr_0 = 1.1839e-04
Validation rmse = 0.680891
Epoch 27
Loss = 2.0505e-04, PNorm = 102.0024, GNorm = 0.2224, lr_0 = 1.1288e-04
Loss = 2.6303e-04, PNorm = 102.0108, GNorm = 0.1413, lr_0 = 1.0810e-04
Validation rmse = 0.675108
Epoch 28
Loss = 1.5773e-04, PNorm = 102.0193, GNorm = 0.1470, lr_0 = 1.0352e-04
Loss = 2.9463e-04, PNorm = 102.0281, GNorm = 0.2401, lr_0 = 1.0000e-04
Validation rmse = 0.683498
Epoch 29
Loss = 3.0798e-04, PNorm = 102.0363, GNorm = 0.2889, lr_0 = 1.0000e-04
Loss = 2.4590e-04, PNorm = 102.0433, GNorm = 0.2498, lr_0 = 1.0000e-04
Validation rmse = 0.695022
Model 0 best validation rmse = 0.668273 on epoch 21
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Moving model to cuda
Model 0 test rmse = 1.084198
Ensemble test rmse = 1.084198
10-fold cross validation
	Seed 0 ==> test rmse = 0.760280
	Seed 1 ==> test rmse = 0.807432
	Seed 2 ==> test rmse = 0.917974
	Seed 3 ==> test rmse = 0.688447
	Seed 4 ==> test rmse = 0.829408
	Seed 5 ==> test rmse = 0.859361
	Seed 6 ==> test rmse = 0.741424
	Seed 7 ==> test rmse = 0.819596
	Seed 8 ==> test rmse = 0.873806
	Seed 9 ==> test rmse = 1.084198
Overall test rmse = 0.838193 +/- 0.103840
Elapsed time = 0:08:32
Fold 0
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 1800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.05_ffn_num_layers_2_hidden_size_1800/fold_0',
 'save_smiles_splits': True,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total scaffolds = 195 | train scaffolds = 91 | val scaffolds = 66 | test scaffolds = 38
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1800, bias=False)
      (W_h): Linear(in_features=1800, out_features=1800, bias=False)
      (W_o): Linear(in_features=1933, out_features=1800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=1804, out_features=1800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=1800, out_features=1, bias=True)
  )
)
Number of parameters = 10,236,601
Moving model to cuda
Epoch 0
Loss = 1.4251e-02, PNorm = 75.8050, GNorm = 7.6143, lr_0 = 3.6053e-04
Validation rmse = 1.111676
Epoch 1
Loss = 3.0200e-03, PNorm = 75.8954, GNorm = 0.7271, lr_0 = 6.2105e-04
Loss = 4.0213e-03, PNorm = 75.9885, GNorm = 0.8355, lr_0 = 8.5789e-04
Validation rmse = 1.067722
Epoch 2
Loss = 6.2501e-03, PNorm = 76.0768, GNorm = 1.8816, lr_0 = 9.8284e-04
Loss = 3.4907e-03, PNorm = 76.1514, GNorm = 1.6271, lr_0 = 9.4120e-04
Validation rmse = 0.907046
Epoch 3
Loss = 1.3423e-03, PNorm = 76.2232, GNorm = 0.5687, lr_0 = 8.9744e-04
Loss = 2.2832e-03, PNorm = 76.2737, GNorm = 0.7679, lr_0 = 8.5943e-04
Validation rmse = 0.990234
Epoch 4
Loss = 3.5653e-03, PNorm = 76.3282, GNorm = 1.1581, lr_0 = 8.2303e-04
Loss = 2.0038e-03, PNorm = 76.3737, GNorm = 2.1692, lr_0 = 7.8816e-04
Validation rmse = 1.060311
Epoch 5
Loss = 1.4822e-03, PNorm = 76.4190, GNorm = 0.4047, lr_0 = 7.5478e-04
Loss = 1.5060e-03, PNorm = 76.4552, GNorm = 0.6758, lr_0 = 7.2281e-04
Validation rmse = 0.784593
Epoch 6
Loss = 1.2721e-03, PNorm = 76.4957, GNorm = 0.3044, lr_0 = 6.8920e-04
Loss = 1.4867e-03, PNorm = 76.5285, GNorm = 0.6587, lr_0 = 6.6001e-04
Validation rmse = 1.016370
Epoch 7
Loss = 1.6277e-03, PNorm = 76.5602, GNorm = 1.0924, lr_0 = 6.3205e-04
Loss = 1.2231e-03, PNorm = 76.5901, GNorm = 0.5449, lr_0 = 6.0528e-04
Validation rmse = 0.950316
Epoch 8
Loss = 1.5905e-03, PNorm = 76.6247, GNorm = 1.2269, lr_0 = 5.7714e-04
Loss = 1.3213e-03, PNorm = 76.6551, GNorm = 0.4605, lr_0 = 5.5269e-04
Validation rmse = 0.819398
Epoch 9
Loss = 1.1796e-03, PNorm = 76.6825, GNorm = 1.3908, lr_0 = 5.2928e-04
Loss = 1.9414e-03, PNorm = 76.7226, GNorm = 1.4121, lr_0 = 5.0686e-04
Validation rmse = 0.802038
Epoch 10
Loss = 1.6196e-03, PNorm = 76.7549, GNorm = 1.8345, lr_0 = 4.8539e-04
Loss = 1.5225e-03, PNorm = 76.7907, GNorm = 0.5356, lr_0 = 4.6483e-04
Validation rmse = 0.806217
Epoch 11
Loss = 1.3515e-03, PNorm = 76.8287, GNorm = 0.2561, lr_0 = 4.4322e-04
Loss = 1.1120e-03, PNorm = 76.8605, GNorm = 0.3431, lr_0 = 4.2444e-04
Validation rmse = 0.866811
Epoch 12
Loss = 1.0868e-03, PNorm = 76.8871, GNorm = 0.3165, lr_0 = 4.0646e-04
Loss = 9.5227e-04, PNorm = 76.9135, GNorm = 0.2235, lr_0 = 3.8925e-04
Validation rmse = 0.866634
Epoch 13
Loss = 7.3315e-04, PNorm = 76.9383, GNorm = 0.2384, lr_0 = 3.7276e-04
Loss = 1.0827e-03, PNorm = 76.9651, GNorm = 0.4130, lr_0 = 3.5697e-04
Validation rmse = 0.953318
Epoch 14
Loss = 1.0636e-03, PNorm = 76.9935, GNorm = 0.3245, lr_0 = 3.4037e-04
Loss = 1.0011e-03, PNorm = 77.0201, GNorm = 0.3817, lr_0 = 3.2596e-04
Validation rmse = 0.874451
Epoch 15
Loss = 7.4342e-04, PNorm = 77.0425, GNorm = 0.3916, lr_0 = 3.1215e-04
Loss = 8.4038e-04, PNorm = 77.0655, GNorm = 0.5783, lr_0 = 2.9893e-04
Validation rmse = 0.888507
Epoch 16
Loss = 7.1915e-04, PNorm = 77.0898, GNorm = 0.2220, lr_0 = 2.8503e-04
Loss = 8.5008e-04, PNorm = 77.1097, GNorm = 0.2459, lr_0 = 2.7295e-04
Validation rmse = 0.850991
Epoch 17
Loss = 6.1001e-04, PNorm = 77.1326, GNorm = 0.2667, lr_0 = 2.6139e-04
Loss = 7.6131e-04, PNorm = 77.1521, GNorm = 0.3832, lr_0 = 2.5032e-04
Validation rmse = 0.910898
Epoch 18
Loss = 7.6709e-04, PNorm = 77.1673, GNorm = 0.4393, lr_0 = 2.3972e-04
Loss = 7.2514e-04, PNorm = 77.1871, GNorm = 0.4755, lr_0 = 2.2956e-04
Validation rmse = 1.010220
Epoch 19
Loss = 7.9646e-04, PNorm = 77.2068, GNorm = 0.3429, lr_0 = 2.1889e-04
Loss = 6.8729e-04, PNorm = 77.2231, GNorm = 0.3922, lr_0 = 2.0962e-04
Validation rmse = 1.031356
Epoch 20
Loss = 7.5562e-04, PNorm = 77.2368, GNorm = 0.4073, lr_0 = 2.0074e-04
Loss = 7.6783e-04, PNorm = 77.2538, GNorm = 0.4234, lr_0 = 1.9224e-04
Validation rmse = 0.919194
Epoch 21
Loss = 7.1847e-04, PNorm = 77.2703, GNorm = 0.2821, lr_0 = 1.8409e-04
Loss = 6.6373e-04, PNorm = 77.2866, GNorm = 0.6381, lr_0 = 1.7630e-04
Validation rmse = 0.900012
Epoch 22
Loss = 5.6682e-04, PNorm = 77.3018, GNorm = 0.3078, lr_0 = 1.6810e-04
Loss = 7.4347e-04, PNorm = 77.3157, GNorm = 0.2802, lr_0 = 1.6098e-04
Validation rmse = 0.856196
Epoch 23
Loss = 5.0827e-04, PNorm = 77.3285, GNorm = 0.3429, lr_0 = 1.5416e-04
Loss = 6.2121e-04, PNorm = 77.3415, GNorm = 0.7041, lr_0 = 1.4763e-04
Loss = 8.7817e-04, PNorm = 77.3429, GNorm = 0.4286, lr_0 = 1.4699e-04
Validation rmse = 0.881635
Epoch 24
Loss = 6.7845e-04, PNorm = 77.3544, GNorm = 0.3069, lr_0 = 1.4077e-04
Loss = 7.0132e-04, PNorm = 77.3660, GNorm = 1.1555, lr_0 = 1.3480e-04
Validation rmse = 0.909212
Epoch 25
Loss = 7.4152e-04, PNorm = 77.3755, GNorm = 0.6670, lr_0 = 1.2909e-04
Loss = 7.2537e-04, PNorm = 77.3880, GNorm = 0.6613, lr_0 = 1.2362e-04
Validation rmse = 0.978027
Epoch 26
Loss = 6.4814e-04, PNorm = 77.3971, GNorm = 0.9606, lr_0 = 1.1839e-04
Validation rmse = 0.892144
Epoch 27
Loss = 3.7574e-04, PNorm = 77.4089, GNorm = 0.3159, lr_0 = 1.1288e-04
Loss = 5.1654e-04, PNorm = 77.4165, GNorm = 0.6161, lr_0 = 1.0810e-04
Validation rmse = 0.847660
Epoch 28
Loss = 8.3961e-04, PNorm = 77.4257, GNorm = 0.4239, lr_0 = 1.0352e-04
Loss = 4.7656e-04, PNorm = 77.4335, GNorm = 0.4042, lr_0 = 1.0000e-04
Validation rmse = 0.834125
Epoch 29
Loss = 3.5115e-04, PNorm = 77.4427, GNorm = 0.4276, lr_0 = 1.0000e-04
Loss = 5.4218e-04, PNorm = 77.4501, GNorm = 0.3874, lr_0 = 1.0000e-04
Validation rmse = 0.881528
Model 0 best validation rmse = 0.784593 on epoch 5
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.884773
Ensemble test rmse = 0.884773
Fold 1
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.05_ffn_num_layers_2_hidden_size_1800/fold_1',
 'save_smiles_splits': True,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total scaffolds = 195 | train scaffolds = 76 | val scaffolds = 60 | test scaffolds = 59
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1800, bias=False)
      (W_h): Linear(in_features=1800, out_features=1800, bias=False)
      (W_o): Linear(in_features=1933, out_features=1800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=1804, out_features=1800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=1800, out_features=1, bias=True)
  )
)
Number of parameters = 10,236,601
Moving model to cuda
Epoch 0
Loss = 1.4247e-02, PNorm = 75.8070, GNorm = 8.9999, lr_0 = 3.6053e-04
Validation rmse = 1.335666
Epoch 1
Loss = 4.5932e-03, PNorm = 75.8891, GNorm = 2.4953, lr_0 = 6.2105e-04
Loss = 4.0257e-03, PNorm = 75.9773, GNorm = 3.2460, lr_0 = 8.5789e-04
Validation rmse = 1.032892
Epoch 2
Loss = 3.0201e-03, PNorm = 76.0640, GNorm = 2.1906, lr_0 = 9.8284e-04
Loss = 3.1782e-03, PNorm = 76.1346, GNorm = 1.5075, lr_0 = 9.4120e-04
Validation rmse = 1.027967
Epoch 3
Loss = 2.2672e-03, PNorm = 76.1946, GNorm = 3.1459, lr_0 = 8.9744e-04
Loss = 2.2149e-03, PNorm = 76.2481, GNorm = 0.3022, lr_0 = 8.5943e-04
Validation rmse = 1.037891
Epoch 4
Loss = 1.4016e-03, PNorm = 76.2903, GNorm = 0.8077, lr_0 = 8.2303e-04
Loss = 1.6031e-03, PNorm = 76.3324, GNorm = 1.6225, lr_0 = 7.8816e-04
Validation rmse = 0.951547
Epoch 5
Loss = 2.0411e-03, PNorm = 76.3677, GNorm = 0.9170, lr_0 = 7.5478e-04
Loss = 1.4848e-03, PNorm = 76.4048, GNorm = 0.8817, lr_0 = 7.2281e-04
Validation rmse = 0.902726
Epoch 6
Loss = 1.3947e-03, PNorm = 76.4338, GNorm = 0.9604, lr_0 = 6.8920e-04
Loss = 1.5472e-03, PNorm = 76.4677, GNorm = 0.7349, lr_0 = 6.6001e-04
Validation rmse = 0.873980
Epoch 7
Loss = 1.0653e-03, PNorm = 76.4993, GNorm = 0.3443, lr_0 = 6.3205e-04
Loss = 1.8714e-03, PNorm = 76.5277, GNorm = 0.9523, lr_0 = 6.0528e-04
Validation rmse = 0.838030
Epoch 8
Loss = 1.5480e-03, PNorm = 76.5627, GNorm = 0.5717, lr_0 = 5.7714e-04
Loss = 1.3238e-03, PNorm = 76.5982, GNorm = 0.6125, lr_0 = 5.5269e-04
Validation rmse = 0.853202
Epoch 9
Loss = 1.1723e-03, PNorm = 76.6323, GNorm = 0.3174, lr_0 = 5.2928e-04
Loss = 1.2788e-03, PNorm = 76.6596, GNorm = 1.4372, lr_0 = 5.0686e-04
Validation rmse = 0.955365
Epoch 10
Loss = 1.3160e-03, PNorm = 76.6876, GNorm = 1.3853, lr_0 = 4.8539e-04
Loss = 1.0787e-03, PNorm = 76.7157, GNorm = 0.9221, lr_0 = 4.6483e-04
Validation rmse = 0.808159
Epoch 11
Loss = 1.2809e-03, PNorm = 76.7477, GNorm = 1.7267, lr_0 = 4.4322e-04
Loss = 1.0951e-03, PNorm = 76.7703, GNorm = 0.9552, lr_0 = 4.2444e-04
Validation rmse = 0.838644
Epoch 12
Loss = 1.1261e-03, PNorm = 76.7919, GNorm = 0.5298, lr_0 = 4.0646e-04
Loss = 1.0265e-03, PNorm = 76.8132, GNorm = 0.3365, lr_0 = 3.8925e-04
Validation rmse = 0.872653
Epoch 13
Loss = 1.0781e-03, PNorm = 76.8339, GNorm = 0.7877, lr_0 = 3.7276e-04
Loss = 1.0747e-03, PNorm = 76.8570, GNorm = 0.5898, lr_0 = 3.5697e-04
Validation rmse = 0.825375
Epoch 14
Loss = 7.5210e-04, PNorm = 76.8831, GNorm = 0.7688, lr_0 = 3.4037e-04
Loss = 8.0541e-04, PNorm = 76.9060, GNorm = 0.5534, lr_0 = 3.2596e-04
Validation rmse = 0.906488
Epoch 15
Loss = 1.0313e-03, PNorm = 76.9269, GNorm = 0.5639, lr_0 = 3.1215e-04
Loss = 7.3149e-04, PNorm = 76.9478, GNorm = 0.4351, lr_0 = 2.9893e-04
Validation rmse = 0.847608
Epoch 16
Loss = 7.2162e-04, PNorm = 76.9671, GNorm = 0.3655, lr_0 = 2.8503e-04
Loss = 9.2257e-04, PNorm = 76.9864, GNorm = 0.5007, lr_0 = 2.7295e-04
Validation rmse = 0.848532
Epoch 17
Loss = 6.4231e-04, PNorm = 77.0077, GNorm = 0.8632, lr_0 = 2.6139e-04
Loss = 7.9440e-04, PNorm = 77.0239, GNorm = 0.5868, lr_0 = 2.5032e-04
Validation rmse = 0.886377
Epoch 18
Loss = 6.9073e-04, PNorm = 77.0415, GNorm = 0.2257, lr_0 = 2.3972e-04
Loss = 7.3063e-04, PNorm = 77.0557, GNorm = 0.6980, lr_0 = 2.2956e-04
Validation rmse = 0.873846
Epoch 19
Loss = 6.4304e-04, PNorm = 77.0705, GNorm = 0.9247, lr_0 = 2.1889e-04
Loss = 7.7267e-04, PNorm = 77.0843, GNorm = 0.6015, lr_0 = 2.0962e-04
Validation rmse = 0.869329
Epoch 20
Loss = 7.0810e-04, PNorm = 77.1005, GNorm = 0.3307, lr_0 = 2.0074e-04
Loss = 7.8205e-04, PNorm = 77.1121, GNorm = 0.3161, lr_0 = 1.9224e-04
Validation rmse = 0.828690
Epoch 21
Loss = 6.4077e-04, PNorm = 77.1261, GNorm = 0.9359, lr_0 = 1.8409e-04
Loss = 7.2974e-04, PNorm = 77.1376, GNorm = 0.6231, lr_0 = 1.7630e-04
Validation rmse = 0.876395
Epoch 22
Loss = 7.1402e-04, PNorm = 77.1507, GNorm = 0.9603, lr_0 = 1.6810e-04
Loss = 6.2264e-04, PNorm = 77.1614, GNorm = 1.1102, lr_0 = 1.6098e-04
Validation rmse = 0.852628
Epoch 23
Loss = 8.0640e-04, PNorm = 77.1721, GNorm = 0.4534, lr_0 = 1.5416e-04
Loss = 6.1554e-04, PNorm = 77.1827, GNorm = 0.3521, lr_0 = 1.4763e-04
Loss = 8.8063e-04, PNorm = 77.1839, GNorm = 0.7477, lr_0 = 1.4699e-04
Validation rmse = 0.919161
Epoch 24
Loss = 6.6448e-04, PNorm = 77.1953, GNorm = 0.3191, lr_0 = 1.4077e-04
Loss = 6.2992e-04, PNorm = 77.2063, GNorm = 0.4494, lr_0 = 1.3480e-04
Validation rmse = 0.905080
Epoch 25
Loss = 4.8503e-04, PNorm = 77.2138, GNorm = 0.3888, lr_0 = 1.2909e-04
Loss = 6.3848e-04, PNorm = 77.2241, GNorm = 0.6579, lr_0 = 1.2362e-04
Validation rmse = 0.884716
Epoch 26
Loss = 6.5946e-04, PNorm = 77.2336, GNorm = 0.6302, lr_0 = 1.1839e-04
Validation rmse = 0.883820
Epoch 27
Loss = 5.1006e-04, PNorm = 77.2413, GNorm = 0.6487, lr_0 = 1.1288e-04
Loss = 4.6456e-04, PNorm = 77.2490, GNorm = 0.4351, lr_0 = 1.0810e-04
Validation rmse = 0.890575
Epoch 28
Loss = 5.3786e-04, PNorm = 77.2540, GNorm = 0.8384, lr_0 = 1.0352e-04
Loss = 5.3708e-04, PNorm = 77.2615, GNorm = 0.2877, lr_0 = 1.0000e-04
Validation rmse = 0.895269
Epoch 29
Loss = 5.1802e-04, PNorm = 77.2677, GNorm = 0.2756, lr_0 = 1.0000e-04
Loss = 4.5339e-04, PNorm = 77.2743, GNorm = 0.3855, lr_0 = 1.0000e-04
Validation rmse = 0.856238
Model 0 best validation rmse = 0.808159 on epoch 10
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.886879
Ensemble test rmse = 0.886879
Fold 2
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.05_ffn_num_layers_2_hidden_size_1800/fold_2',
 'save_smiles_splits': True,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total scaffolds = 195 | train scaffolds = 55 | val scaffolds = 64 | test scaffolds = 76
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1800, bias=False)
      (W_h): Linear(in_features=1800, out_features=1800, bias=False)
      (W_o): Linear(in_features=1933, out_features=1800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=1804, out_features=1800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=1800, out_features=1, bias=True)
  )
)
Number of parameters = 10,236,601
Moving model to cuda
Epoch 0
Loss = 1.2645e-02, PNorm = 75.8059, GNorm = 5.0299, lr_0 = 3.6053e-04
Validation rmse = 1.546812
Epoch 1
Loss = 6.7444e-03, PNorm = 75.8890, GNorm = 3.7488, lr_0 = 6.2105e-04
Loss = 5.7661e-03, PNorm = 75.9880, GNorm = 3.3641, lr_0 = 8.5789e-04
Validation rmse = 1.160017
Epoch 2
Loss = 4.1228e-03, PNorm = 76.0921, GNorm = 0.8759, lr_0 = 9.8284e-04
Loss = 2.4263e-03, PNorm = 76.1696, GNorm = 0.9479, lr_0 = 9.4120e-04
Validation rmse = 1.036220
Epoch 3
Loss = 2.2834e-03, PNorm = 76.2358, GNorm = 0.4158, lr_0 = 8.9744e-04
Loss = 2.6027e-03, PNorm = 76.2942, GNorm = 0.8374, lr_0 = 8.5943e-04
Validation rmse = 1.020789
Epoch 4
Loss = 1.5245e-03, PNorm = 76.3511, GNorm = 0.5711, lr_0 = 8.2303e-04
Loss = 2.2207e-03, PNorm = 76.3952, GNorm = 1.5791, lr_0 = 7.8816e-04
Validation rmse = 1.005991
Epoch 5
Loss = 1.6044e-03, PNorm = 76.4382, GNorm = 0.5531, lr_0 = 7.5478e-04
Loss = 1.7290e-03, PNorm = 76.4800, GNorm = 1.0545, lr_0 = 7.2281e-04
Validation rmse = 0.925141
Epoch 6
Loss = 1.4201e-03, PNorm = 76.5372, GNorm = 0.7807, lr_0 = 6.8920e-04
Loss = 1.8235e-03, PNorm = 76.5764, GNorm = 0.8623, lr_0 = 6.6001e-04
Validation rmse = 1.007864
Epoch 7
Loss = 2.0741e-03, PNorm = 76.6112, GNorm = 0.8795, lr_0 = 6.3205e-04
Loss = 1.3467e-03, PNorm = 76.6466, GNorm = 0.5780, lr_0 = 6.0528e-04
Validation rmse = 0.853896
Epoch 8
Loss = 1.6729e-03, PNorm = 76.6894, GNorm = 0.3792, lr_0 = 5.7714e-04
Loss = 1.3237e-03, PNorm = 76.7262, GNorm = 0.4163, lr_0 = 5.5269e-04
Validation rmse = 0.838173
Epoch 9
Loss = 1.4020e-03, PNorm = 76.7578, GNorm = 0.6477, lr_0 = 5.2928e-04
Loss = 1.1999e-03, PNorm = 76.7923, GNorm = 0.7962, lr_0 = 5.0686e-04
Validation rmse = 0.835780
Epoch 10
Loss = 1.4272e-03, PNorm = 76.8236, GNorm = 0.6938, lr_0 = 4.8539e-04
Loss = 1.2282e-03, PNorm = 76.8575, GNorm = 0.5425, lr_0 = 4.6483e-04
Validation rmse = 0.878752
Epoch 11
Loss = 1.3162e-03, PNorm = 76.8941, GNorm = 0.7780, lr_0 = 4.4322e-04
Loss = 1.1428e-03, PNorm = 76.9281, GNorm = 0.6425, lr_0 = 4.2444e-04
Validation rmse = 0.858983
Epoch 12
Loss = 8.8542e-04, PNorm = 76.9564, GNorm = 0.5465, lr_0 = 4.0646e-04
Loss = 1.2111e-03, PNorm = 76.9818, GNorm = 0.5950, lr_0 = 3.8925e-04
Validation rmse = 0.891372
Epoch 13
Loss = 1.2266e-03, PNorm = 77.0112, GNorm = 0.6496, lr_0 = 3.7276e-04
Loss = 8.8576e-04, PNorm = 77.0364, GNorm = 0.3626, lr_0 = 3.5697e-04
Validation rmse = 0.881419
Epoch 14
Loss = 1.0100e-03, PNorm = 77.0651, GNorm = 0.4621, lr_0 = 3.4037e-04
Loss = 9.4069e-04, PNorm = 77.0884, GNorm = 0.4776, lr_0 = 3.2596e-04
Validation rmse = 0.892563
Epoch 15
Loss = 1.0481e-03, PNorm = 77.1042, GNorm = 0.7785, lr_0 = 3.1215e-04
Loss = 9.5765e-04, PNorm = 77.1267, GNorm = 0.4946, lr_0 = 2.9893e-04
Validation rmse = 0.917702
Epoch 16
Loss = 8.5632e-04, PNorm = 77.1546, GNorm = 0.3304, lr_0 = 2.8503e-04
Loss = 8.8792e-04, PNorm = 77.1761, GNorm = 0.6256, lr_0 = 2.7295e-04
Validation rmse = 0.820374
Epoch 17
Loss = 1.1387e-03, PNorm = 77.1957, GNorm = 1.1063, lr_0 = 2.6139e-04
Loss = 8.6879e-04, PNorm = 77.2161, GNorm = 0.7403, lr_0 = 2.5032e-04
Validation rmse = 1.021063
Epoch 18
Loss = 6.9471e-04, PNorm = 77.2383, GNorm = 0.5441, lr_0 = 2.3972e-04
Loss = 8.8216e-04, PNorm = 77.2595, GNorm = 0.3843, lr_0 = 2.2956e-04
Validation rmse = 0.930172
Epoch 19
Loss = 8.3689e-04, PNorm = 77.2808, GNorm = 0.5654, lr_0 = 2.1889e-04
Loss = 8.9319e-04, PNorm = 77.2998, GNorm = 0.6000, lr_0 = 2.0962e-04
Validation rmse = 0.857111
Epoch 20
Loss = 7.1958e-04, PNorm = 77.3108, GNorm = 0.7394, lr_0 = 2.0074e-04
Loss = 6.8494e-04, PNorm = 77.3235, GNorm = 0.3994, lr_0 = 1.9224e-04
Validation rmse = 0.907442
Epoch 21
Loss = 6.7037e-04, PNorm = 77.3373, GNorm = 0.3597, lr_0 = 1.8409e-04
Loss = 6.9035e-04, PNorm = 77.3520, GNorm = 0.3311, lr_0 = 1.7630e-04
Validation rmse = 0.943377
Epoch 22
Loss = 7.9830e-04, PNorm = 77.3674, GNorm = 0.7899, lr_0 = 1.6810e-04
Loss = 6.1390e-04, PNorm = 77.3826, GNorm = 0.3652, lr_0 = 1.6098e-04
Validation rmse = 0.905498
Epoch 23
Loss = 5.4435e-04, PNorm = 77.3924, GNorm = 0.4825, lr_0 = 1.5416e-04
Loss = 6.9179e-04, PNorm = 77.4039, GNorm = 0.4813, lr_0 = 1.4763e-04
Loss = 1.3160e-03, PNorm = 77.4046, GNorm = 0.5826, lr_0 = 1.4699e-04
Validation rmse = 0.961390
Epoch 24
Loss = 6.5441e-04, PNorm = 77.4166, GNorm = 1.0424, lr_0 = 1.4077e-04
Loss = 6.4896e-04, PNorm = 77.4292, GNorm = 0.6261, lr_0 = 1.3480e-04
Validation rmse = 0.980658
Epoch 25
Loss = 6.7893e-04, PNorm = 77.4402, GNorm = 0.4180, lr_0 = 1.2909e-04
Loss = 5.8097e-04, PNorm = 77.4498, GNorm = 0.5166, lr_0 = 1.2362e-04
Validation rmse = 0.979366
Epoch 26
Loss = 5.6188e-04, PNorm = 77.4587, GNorm = 0.4820, lr_0 = 1.1839e-04
Validation rmse = 1.004466
Epoch 27
Loss = 7.4341e-04, PNorm = 77.4675, GNorm = 0.4912, lr_0 = 1.1288e-04
Loss = 5.5867e-04, PNorm = 77.4777, GNorm = 0.4055, lr_0 = 1.0810e-04
Validation rmse = 0.962536
Epoch 28
Loss = 6.3819e-04, PNorm = 77.4863, GNorm = 0.3612, lr_0 = 1.0352e-04
Loss = 4.4031e-04, PNorm = 77.4954, GNorm = 0.3865, lr_0 = 1.0000e-04
Validation rmse = 0.995165
Epoch 29
Loss = 4.2653e-04, PNorm = 77.5042, GNorm = 0.2317, lr_0 = 1.0000e-04
Loss = 4.4812e-04, PNorm = 77.5107, GNorm = 0.3200, lr_0 = 1.0000e-04
Validation rmse = 0.974337
Model 0 best validation rmse = 0.820374 on epoch 16
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.873391
Ensemble test rmse = 0.873391
Fold 3
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.05_ffn_num_layers_2_hidden_size_1800/fold_3',
 'save_smiles_splits': True,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total scaffolds = 195 | train scaffolds = 80 | val scaffolds = 54 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1800, bias=False)
      (W_h): Linear(in_features=1800, out_features=1800, bias=False)
      (W_o): Linear(in_features=1933, out_features=1800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=1804, out_features=1800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=1800, out_features=1, bias=True)
  )
)
Number of parameters = 10,236,601
Moving model to cuda
Epoch 0
Loss = 1.1801e-02, PNorm = 75.8065, GNorm = 12.7800, lr_0 = 3.6053e-04
Validation rmse = 1.210997
Epoch 1
Loss = 4.5886e-03, PNorm = 75.8915, GNorm = 1.6619, lr_0 = 6.2105e-04
Loss = 3.4737e-03, PNorm = 75.9886, GNorm = 1.8722, lr_0 = 8.5789e-04
Validation rmse = 1.126869
Epoch 2
Loss = 3.3966e-03, PNorm = 76.0843, GNorm = 1.0153, lr_0 = 9.8284e-04
Loss = 2.5035e-03, PNorm = 76.1627, GNorm = 1.1599, lr_0 = 9.4120e-04
Validation rmse = 1.135637
Epoch 3
Loss = 1.8284e-03, PNorm = 76.2353, GNorm = 0.4348, lr_0 = 8.9744e-04
Loss = 2.0585e-03, PNorm = 76.2861, GNorm = 1.9758, lr_0 = 8.5943e-04
Validation rmse = 1.043250
Epoch 4
Loss = 2.5772e-03, PNorm = 76.3347, GNorm = 1.8581, lr_0 = 8.2303e-04
Loss = 2.0149e-03, PNorm = 76.3880, GNorm = 1.7423, lr_0 = 7.8816e-04
Validation rmse = 1.089868
Epoch 5
Loss = 1.7547e-03, PNorm = 76.4404, GNorm = 2.0080, lr_0 = 7.5478e-04
Loss = 2.1726e-03, PNorm = 76.4820, GNorm = 0.4747, lr_0 = 7.2281e-04
Validation rmse = 1.053001
Epoch 6
Loss = 1.8518e-03, PNorm = 76.5359, GNorm = 0.4539, lr_0 = 6.8920e-04
Loss = 1.7561e-03, PNorm = 76.5749, GNorm = 0.5264, lr_0 = 6.6001e-04
Validation rmse = 0.944046
Epoch 7
Loss = 1.1585e-03, PNorm = 76.6027, GNorm = 0.8644, lr_0 = 6.3205e-04
Loss = 1.1314e-03, PNorm = 76.6357, GNorm = 1.0998, lr_0 = 6.0528e-04
Validation rmse = 0.961226
Epoch 8
Loss = 1.4255e-03, PNorm = 76.6689, GNorm = 0.5887, lr_0 = 5.7714e-04
Loss = 1.2195e-03, PNorm = 76.7023, GNorm = 1.0954, lr_0 = 5.5269e-04
Validation rmse = 0.969169
Epoch 9
Loss = 1.1176e-03, PNorm = 76.7340, GNorm = 0.8322, lr_0 = 5.2928e-04
Loss = 1.2479e-03, PNorm = 76.7651, GNorm = 0.4754, lr_0 = 5.0686e-04
Validation rmse = 0.965488
Epoch 10
Loss = 1.2334e-03, PNorm = 76.7881, GNorm = 1.1356, lr_0 = 4.8539e-04
Loss = 1.1093e-03, PNorm = 76.8105, GNorm = 0.3668, lr_0 = 4.6483e-04
Validation rmse = 0.991025
Epoch 11
Loss = 8.7388e-04, PNorm = 76.8339, GNorm = 0.2441, lr_0 = 4.4322e-04
Loss = 1.0707e-03, PNorm = 76.8567, GNorm = 0.3214, lr_0 = 4.2444e-04
Validation rmse = 0.971859
Epoch 12
Loss = 1.0712e-03, PNorm = 76.8804, GNorm = 0.8610, lr_0 = 4.0646e-04
Loss = 9.7815e-04, PNorm = 76.9002, GNorm = 0.7760, lr_0 = 3.8925e-04
Validation rmse = 1.076007
Epoch 13
Loss = 1.1841e-03, PNorm = 76.9255, GNorm = 1.0571, lr_0 = 3.7276e-04
Loss = 9.3576e-04, PNorm = 76.9486, GNorm = 0.4953, lr_0 = 3.5697e-04
Validation rmse = 0.953820
Epoch 14
Loss = 6.6507e-04, PNorm = 76.9712, GNorm = 1.1848, lr_0 = 3.4037e-04
Loss = 9.7330e-04, PNorm = 76.9924, GNorm = 0.4007, lr_0 = 3.2596e-04
Validation rmse = 0.988484
Epoch 15
Loss = 7.3023e-04, PNorm = 77.0134, GNorm = 0.8693, lr_0 = 3.1215e-04
Loss = 9.2418e-04, PNorm = 77.0331, GNorm = 0.2296, lr_0 = 2.9893e-04
Validation rmse = 0.995796
Epoch 16
Loss = 8.1081e-04, PNorm = 77.0542, GNorm = 0.8746, lr_0 = 2.8503e-04
Loss = 7.9016e-04, PNorm = 77.0749, GNorm = 0.7292, lr_0 = 2.7295e-04
Validation rmse = 0.950303
Epoch 17
Loss = 7.7163e-04, PNorm = 77.0940, GNorm = 0.3876, lr_0 = 2.6139e-04
Loss = 8.2766e-04, PNorm = 77.1143, GNorm = 0.3646, lr_0 = 2.5032e-04
Validation rmse = 0.982680
Epoch 18
Loss = 7.5364e-04, PNorm = 77.1332, GNorm = 0.4944, lr_0 = 2.3972e-04
Loss = 7.3351e-04, PNorm = 77.1502, GNorm = 0.6050, lr_0 = 2.2956e-04
Validation rmse = 0.974699
Epoch 19
Loss = 7.3997e-04, PNorm = 77.1679, GNorm = 0.2491, lr_0 = 2.1889e-04
Loss = 7.1210e-04, PNorm = 77.1798, GNorm = 0.6906, lr_0 = 2.0962e-04
Validation rmse = 0.979467
Epoch 20
Loss = 6.6196e-04, PNorm = 77.1930, GNorm = 1.0353, lr_0 = 2.0074e-04
Loss = 8.0930e-04, PNorm = 77.2082, GNorm = 0.5148, lr_0 = 1.9224e-04
Validation rmse = 1.004635
Epoch 21
Loss = 6.9097e-04, PNorm = 77.2247, GNorm = 0.3636, lr_0 = 1.8409e-04
Loss = 7.3090e-04, PNorm = 77.2364, GNorm = 0.7285, lr_0 = 1.7630e-04
Validation rmse = 1.017139
Epoch 22
Loss = 7.6745e-04, PNorm = 77.2549, GNorm = 0.3880, lr_0 = 1.6810e-04
Loss = 5.3842e-04, PNorm = 77.2673, GNorm = 0.1872, lr_0 = 1.6098e-04
Validation rmse = 0.992688
Epoch 23
Loss = 5.4542e-04, PNorm = 77.2786, GNorm = 0.7480, lr_0 = 1.5416e-04
Loss = 5.1995e-04, PNorm = 77.2881, GNorm = 0.4508, lr_0 = 1.4763e-04
Loss = 6.8958e-04, PNorm = 77.2892, GNorm = 0.3727, lr_0 = 1.4699e-04
Validation rmse = 0.996277
Epoch 24
Loss = 6.0221e-04, PNorm = 77.2985, GNorm = 0.2267, lr_0 = 1.4077e-04
Loss = 6.1219e-04, PNorm = 77.3094, GNorm = 0.5241, lr_0 = 1.3480e-04
Validation rmse = 1.034677
Epoch 25
Loss = 5.5964e-04, PNorm = 77.3183, GNorm = 0.1471, lr_0 = 1.2909e-04
Loss = 6.5233e-04, PNorm = 77.3276, GNorm = 1.0433, lr_0 = 1.2362e-04
Validation rmse = 0.978328
Epoch 26
Loss = 6.4923e-04, PNorm = 77.3384, GNorm = 0.3709, lr_0 = 1.1839e-04
Validation rmse = 1.004350
Epoch 27
Loss = 9.8799e-04, PNorm = 77.3477, GNorm = 0.2451, lr_0 = 1.1288e-04
Loss = 4.5067e-04, PNorm = 77.3551, GNorm = 0.4248, lr_0 = 1.0810e-04
Validation rmse = 1.031683
Epoch 28
Loss = 5.0630e-04, PNorm = 77.3599, GNorm = 0.3506, lr_0 = 1.0352e-04
Loss = 4.8649e-04, PNorm = 77.3694, GNorm = 0.3768, lr_0 = 1.0000e-04
Validation rmse = 1.008254
Epoch 29
Loss = 4.8286e-04, PNorm = 77.3779, GNorm = 0.2351, lr_0 = 1.0000e-04
Loss = 4.8833e-04, PNorm = 77.3852, GNorm = 0.5099, lr_0 = 1.0000e-04
Validation rmse = 1.006963
Model 0 best validation rmse = 0.944046 on epoch 6
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.811292
Ensemble test rmse = 0.811292
Fold 4
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.05_ffn_num_layers_2_hidden_size_1800/fold_4',
 'save_smiles_splits': True,
 'seed': 4,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 4
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 49 | test scaffolds = 62
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1800, bias=False)
      (W_h): Linear(in_features=1800, out_features=1800, bias=False)
      (W_o): Linear(in_features=1933, out_features=1800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=1804, out_features=1800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=1800, out_features=1, bias=True)
  )
)
Number of parameters = 10,236,601
Moving model to cuda
Epoch 0
Loss = 1.4263e-02, PNorm = 75.8065, GNorm = 8.6593, lr_0 = 3.6053e-04
Validation rmse = 1.409404
Epoch 1
Loss = 5.2972e-03, PNorm = 75.9002, GNorm = 3.8561, lr_0 = 6.2105e-04
Loss = 4.3345e-03, PNorm = 75.9945, GNorm = 2.2156, lr_0 = 8.5789e-04
Validation rmse = 1.004562
Epoch 2
Loss = 3.0076e-03, PNorm = 76.0869, GNorm = 2.2231, lr_0 = 9.8284e-04
Loss = 2.4725e-03, PNorm = 76.1569, GNorm = 0.8278, lr_0 = 9.4120e-04
Validation rmse = 1.047873
Epoch 3
Loss = 2.4477e-03, PNorm = 76.2210, GNorm = 0.5703, lr_0 = 8.9744e-04
Loss = 2.1058e-03, PNorm = 76.2723, GNorm = 0.7811, lr_0 = 8.5943e-04
Validation rmse = 0.887563
Epoch 4
Loss = 3.2195e-03, PNorm = 76.3248, GNorm = 1.5659, lr_0 = 8.2303e-04
Loss = 1.5825e-03, PNorm = 76.3673, GNorm = 0.5331, lr_0 = 7.8816e-04
Validation rmse = 0.837514
Epoch 5
Loss = 1.4307e-03, PNorm = 76.4043, GNorm = 0.5150, lr_0 = 7.5478e-04
Loss = 1.5237e-03, PNorm = 76.4395, GNorm = 0.6591, lr_0 = 7.2281e-04
Validation rmse = 0.852047
Epoch 6
Loss = 1.3176e-03, PNorm = 76.4755, GNorm = 0.3778, lr_0 = 6.8920e-04
Loss = 1.6265e-03, PNorm = 76.5075, GNorm = 0.6778, lr_0 = 6.6001e-04
Validation rmse = 0.852304
Epoch 7
Loss = 1.2503e-03, PNorm = 76.5406, GNorm = 0.7735, lr_0 = 6.3205e-04
Loss = 1.6545e-03, PNorm = 76.5758, GNorm = 0.9065, lr_0 = 6.0528e-04
Validation rmse = 0.861731
Epoch 8
Loss = 1.6585e-03, PNorm = 76.6108, GNorm = 1.2376, lr_0 = 5.7714e-04
Loss = 1.2565e-03, PNorm = 76.6390, GNorm = 0.5988, lr_0 = 5.5269e-04
Validation rmse = 0.785483
Epoch 9
Loss = 1.0621e-03, PNorm = 76.6674, GNorm = 1.2841, lr_0 = 5.2928e-04
Loss = 1.3968e-03, PNorm = 76.6995, GNorm = 0.6771, lr_0 = 5.0686e-04
Validation rmse = 0.756536
Epoch 10
Loss = 1.1457e-03, PNorm = 76.7249, GNorm = 1.2585, lr_0 = 4.8539e-04
Loss = 1.5290e-03, PNorm = 76.7520, GNorm = 0.5437, lr_0 = 4.6483e-04
Validation rmse = 0.776575
Epoch 11
Loss = 1.3593e-03, PNorm = 76.7867, GNorm = 1.0680, lr_0 = 4.4322e-04
Loss = 1.1480e-03, PNorm = 76.8141, GNorm = 0.2280, lr_0 = 4.2444e-04
Validation rmse = 0.745884
Epoch 12
Loss = 6.1797e-04, PNorm = 76.8357, GNorm = 0.6267, lr_0 = 4.0646e-04
Loss = 1.2285e-03, PNorm = 76.8583, GNorm = 0.4929, lr_0 = 3.8925e-04
Validation rmse = 0.759316
Epoch 13
Loss = 1.0044e-03, PNorm = 76.8843, GNorm = 0.6403, lr_0 = 3.7276e-04
Loss = 1.1877e-03, PNorm = 76.9112, GNorm = 0.5133, lr_0 = 3.5697e-04
Validation rmse = 0.805691
Epoch 14
Loss = 9.3554e-04, PNorm = 76.9353, GNorm = 0.2670, lr_0 = 3.4037e-04
Loss = 8.4845e-04, PNorm = 76.9595, GNorm = 0.3303, lr_0 = 3.2596e-04
Validation rmse = 0.720046
Epoch 15
Loss = 8.6082e-04, PNorm = 76.9789, GNorm = 0.4597, lr_0 = 3.1215e-04
Loss = 9.2410e-04, PNorm = 77.0048, GNorm = 0.6407, lr_0 = 2.9893e-04
Validation rmse = 0.717224
Epoch 16
Loss = 9.9021e-04, PNorm = 77.0283, GNorm = 1.0598, lr_0 = 2.8503e-04
Loss = 1.0895e-03, PNorm = 77.0523, GNorm = 0.2702, lr_0 = 2.7295e-04
Validation rmse = 0.715281
Epoch 17
Loss = 8.0444e-04, PNorm = 77.0711, GNorm = 0.1872, lr_0 = 2.6139e-04
Loss = 8.5459e-04, PNorm = 77.0905, GNorm = 0.4081, lr_0 = 2.5032e-04
Validation rmse = 0.708198
Epoch 18
Loss = 9.0583e-04, PNorm = 77.1094, GNorm = 0.3824, lr_0 = 2.3972e-04
Loss = 8.5237e-04, PNorm = 77.1275, GNorm = 0.3033, lr_0 = 2.2956e-04
Validation rmse = 0.750851
Epoch 19
Loss = 6.1737e-04, PNorm = 77.1446, GNorm = 0.2837, lr_0 = 2.1889e-04
Loss = 8.6651e-04, PNorm = 77.1591, GNorm = 0.7166, lr_0 = 2.0962e-04
Validation rmse = 0.687546
Epoch 20
Loss = 6.7609e-04, PNorm = 77.1740, GNorm = 0.4719, lr_0 = 2.0074e-04
Loss = 7.4139e-04, PNorm = 77.1895, GNorm = 1.4482, lr_0 = 1.9224e-04
Validation rmse = 0.785423
Epoch 21
Loss = 6.5851e-04, PNorm = 77.2045, GNorm = 0.2968, lr_0 = 1.8409e-04
Loss = 7.1406e-04, PNorm = 77.2180, GNorm = 0.4568, lr_0 = 1.7630e-04
Validation rmse = 0.718719
Epoch 22
Loss = 5.8027e-04, PNorm = 77.2320, GNorm = 0.3359, lr_0 = 1.6810e-04
Loss = 6.6835e-04, PNorm = 77.2451, GNorm = 0.3170, lr_0 = 1.6098e-04
Validation rmse = 0.717566
Epoch 23
Loss = 7.2906e-04, PNorm = 77.2583, GNorm = 0.4561, lr_0 = 1.5416e-04
Loss = 7.6671e-04, PNorm = 77.2721, GNorm = 0.3291, lr_0 = 1.4763e-04
Loss = 1.0149e-03, PNorm = 77.2730, GNorm = 0.4451, lr_0 = 1.4699e-04
Validation rmse = 0.704299
Epoch 24
Loss = 5.5563e-04, PNorm = 77.2826, GNorm = 0.3567, lr_0 = 1.4077e-04
Loss = 5.8282e-04, PNorm = 77.2925, GNorm = 0.5658, lr_0 = 1.3480e-04
Validation rmse = 0.789943
Epoch 25
Loss = 5.1502e-04, PNorm = 77.3031, GNorm = 1.0920, lr_0 = 1.2909e-04
Loss = 6.6097e-04, PNorm = 77.3128, GNorm = 0.6414, lr_0 = 1.2362e-04
Validation rmse = 0.695261
Epoch 26
Loss = 4.9587e-04, PNorm = 77.3231, GNorm = 0.5179, lr_0 = 1.1839e-04
Validation rmse = 0.704418
Epoch 27
Loss = 4.4513e-04, PNorm = 77.3340, GNorm = 0.2882, lr_0 = 1.1288e-04
Loss = 5.2097e-04, PNorm = 77.3419, GNorm = 0.5681, lr_0 = 1.0810e-04
Validation rmse = 0.701521
Epoch 28
Loss = 3.6550e-04, PNorm = 77.3512, GNorm = 0.8558, lr_0 = 1.0352e-04
Loss = 5.4284e-04, PNorm = 77.3585, GNorm = 0.4678, lr_0 = 1.0000e-04
Validation rmse = 0.744178
Epoch 29
Loss = 4.2118e-04, PNorm = 77.3673, GNorm = 0.4955, lr_0 = 1.0000e-04
Loss = 5.0093e-04, PNorm = 77.3759, GNorm = 0.4835, lr_0 = 1.0000e-04
Validation rmse = 0.698405
Model 0 best validation rmse = 0.687546 on epoch 19
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.871551
Ensemble test rmse = 0.871551
Fold 5
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.05_ffn_num_layers_2_hidden_size_1800/fold_5',
 'save_smiles_splits': True,
 'seed': 5,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 5
Total scaffolds = 195 | train scaffolds = 94 | val scaffolds = 55 | test scaffolds = 46
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1800, bias=False)
      (W_h): Linear(in_features=1800, out_features=1800, bias=False)
      (W_o): Linear(in_features=1933, out_features=1800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=1804, out_features=1800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=1800, out_features=1, bias=True)
  )
)
Number of parameters = 10,236,601
Moving model to cuda
Epoch 0
Loss = 1.3283e-02, PNorm = 75.8063, GNorm = 10.3340, lr_0 = 3.6053e-04
Validation rmse = 1.694049
Epoch 1
Loss = 6.7988e-03, PNorm = 75.8943, GNorm = 5.9161, lr_0 = 6.2105e-04
Loss = 3.6386e-03, PNorm = 75.9888, GNorm = 1.1511, lr_0 = 8.5789e-04
Validation rmse = 1.272628
Epoch 2
Loss = 3.5717e-03, PNorm = 76.0852, GNorm = 1.9184, lr_0 = 9.8284e-04
Loss = 3.2305e-03, PNorm = 76.1649, GNorm = 1.0509, lr_0 = 9.4120e-04
Validation rmse = 1.118167
Epoch 3
Loss = 2.5027e-03, PNorm = 76.2361, GNorm = 0.8988, lr_0 = 8.9744e-04
Loss = 2.2468e-03, PNorm = 76.2902, GNorm = 0.9239, lr_0 = 8.5943e-04
Validation rmse = 1.133952
Epoch 4
Loss = 2.0868e-03, PNorm = 76.3306, GNorm = 1.1513, lr_0 = 8.2303e-04
Loss = 1.8590e-03, PNorm = 76.3738, GNorm = 1.3441, lr_0 = 7.8816e-04
Validation rmse = 0.955372
Epoch 5
Loss = 1.3078e-03, PNorm = 76.4087, GNorm = 0.6357, lr_0 = 7.5478e-04
Loss = 1.7232e-03, PNorm = 76.4458, GNorm = 1.5154, lr_0 = 7.2281e-04
Validation rmse = 0.915304
Epoch 6
Loss = 1.7885e-03, PNorm = 76.4868, GNorm = 0.4459, lr_0 = 6.8920e-04
Loss = 1.7586e-03, PNorm = 76.5265, GNorm = 0.4030, lr_0 = 6.6001e-04
Validation rmse = 0.905949
Epoch 7
Loss = 1.2994e-03, PNorm = 76.5603, GNorm = 0.2564, lr_0 = 6.3205e-04
Loss = 1.6023e-03, PNorm = 76.5940, GNorm = 0.7438, lr_0 = 6.0528e-04
Validation rmse = 0.817968
Epoch 8
Loss = 1.2968e-03, PNorm = 76.6255, GNorm = 0.4129, lr_0 = 5.7714e-04
Loss = 1.4923e-03, PNorm = 76.6516, GNorm = 0.6402, lr_0 = 5.5269e-04
Validation rmse = 0.844791
Epoch 9
Loss = 1.3234e-03, PNorm = 76.6763, GNorm = 0.4548, lr_0 = 5.2928e-04
Loss = 1.4229e-03, PNorm = 76.7069, GNorm = 0.8415, lr_0 = 5.0686e-04
Validation rmse = 0.886503
Epoch 10
Loss = 1.1787e-03, PNorm = 76.7393, GNorm = 0.4265, lr_0 = 4.8539e-04
Loss = 1.2704e-03, PNorm = 76.7656, GNorm = 0.6234, lr_0 = 4.6483e-04
Validation rmse = 0.879256
Epoch 11
Loss = 1.0638e-03, PNorm = 76.7915, GNorm = 0.5097, lr_0 = 4.4322e-04
Loss = 1.0948e-03, PNorm = 76.8214, GNorm = 0.7703, lr_0 = 4.2444e-04
Validation rmse = 0.873056
Epoch 12
Loss = 9.6508e-04, PNorm = 76.8479, GNorm = 0.4631, lr_0 = 4.0646e-04
Loss = 1.0777e-03, PNorm = 76.8724, GNorm = 0.6152, lr_0 = 3.8925e-04
Validation rmse = 0.999978
Epoch 13
Loss = 1.0162e-03, PNorm = 76.8964, GNorm = 1.3920, lr_0 = 3.7276e-04
Loss = 1.0861e-03, PNorm = 76.9185, GNorm = 0.7743, lr_0 = 3.5697e-04
Validation rmse = 0.879921
Epoch 14
Loss = 1.1931e-03, PNorm = 76.9463, GNorm = 0.6370, lr_0 = 3.4037e-04
Loss = 9.8244e-04, PNorm = 76.9679, GNorm = 0.3783, lr_0 = 3.2596e-04
Validation rmse = 0.859793
Epoch 15
Loss = 9.8869e-04, PNorm = 76.9914, GNorm = 0.5024, lr_0 = 3.1215e-04
Loss = 9.1860e-04, PNorm = 77.0146, GNorm = 0.5796, lr_0 = 2.9893e-04
Validation rmse = 0.863374
Epoch 16
Loss = 8.8427e-04, PNorm = 77.0326, GNorm = 0.4861, lr_0 = 2.8503e-04
Loss = 8.7061e-04, PNorm = 77.0498, GNorm = 0.6278, lr_0 = 2.7295e-04
Validation rmse = 0.846841
Epoch 17
Loss = 6.1222e-04, PNorm = 77.0671, GNorm = 0.4527, lr_0 = 2.6139e-04
Loss = 9.3927e-04, PNorm = 77.0831, GNorm = 0.4595, lr_0 = 2.5032e-04
Validation rmse = 0.869897
Epoch 18
Loss = 7.4156e-04, PNorm = 77.1006, GNorm = 0.6270, lr_0 = 2.3972e-04
Loss = 7.4249e-04, PNorm = 77.1173, GNorm = 0.2227, lr_0 = 2.2956e-04
Validation rmse = 0.943186
Epoch 19
Loss = 1.0121e-03, PNorm = 77.1337, GNorm = 0.7202, lr_0 = 2.1889e-04
Loss = 8.2504e-04, PNorm = 77.1485, GNorm = 0.2682, lr_0 = 2.0962e-04
Validation rmse = 0.903643
Epoch 20
Loss = 6.9760e-04, PNorm = 77.1635, GNorm = 0.4929, lr_0 = 2.0074e-04
Loss = 7.9870e-04, PNorm = 77.1773, GNorm = 0.5562, lr_0 = 1.9224e-04
Validation rmse = 0.838717
Epoch 21
Loss = 6.1551e-04, PNorm = 77.1887, GNorm = 0.5594, lr_0 = 1.8409e-04
Loss = 6.2563e-04, PNorm = 77.2021, GNorm = 0.1768, lr_0 = 1.7630e-04
Validation rmse = 0.822695
Epoch 22
Loss = 5.2632e-04, PNorm = 77.2147, GNorm = 0.3865, lr_0 = 1.6810e-04
Loss = 6.5839e-04, PNorm = 77.2267, GNorm = 0.4295, lr_0 = 1.6098e-04
Validation rmse = 0.822200
Epoch 23
Loss = 6.9525e-04, PNorm = 77.2367, GNorm = 0.3933, lr_0 = 1.5416e-04
Loss = 5.0643e-04, PNorm = 77.2480, GNorm = 0.5574, lr_0 = 1.4763e-04
Loss = 5.8713e-04, PNorm = 77.2489, GNorm = 0.3047, lr_0 = 1.4699e-04
Validation rmse = 0.872210
Epoch 24
Loss = 5.2570e-04, PNorm = 77.2585, GNorm = 0.3252, lr_0 = 1.4077e-04
Loss = 6.8978e-04, PNorm = 77.2684, GNorm = 0.3760, lr_0 = 1.3480e-04
Validation rmse = 0.931790
Epoch 25
Loss = 4.9968e-04, PNorm = 77.2780, GNorm = 0.3176, lr_0 = 1.2909e-04
Loss = 5.0680e-04, PNorm = 77.2853, GNorm = 0.5145, lr_0 = 1.2362e-04
Validation rmse = 0.862339
Epoch 26
Loss = 7.1073e-04, PNorm = 77.2945, GNorm = 0.4298, lr_0 = 1.1839e-04
Validation rmse = 0.892762
Epoch 27
Loss = 5.7424e-04, PNorm = 77.3042, GNorm = 0.3556, lr_0 = 1.1288e-04
Loss = 5.3426e-04, PNorm = 77.3133, GNorm = 0.4197, lr_0 = 1.0810e-04
Validation rmse = 0.846708
Epoch 28
Loss = 7.3323e-04, PNorm = 77.3208, GNorm = 0.3912, lr_0 = 1.0352e-04
Loss = 5.4414e-04, PNorm = 77.3294, GNorm = 0.3826, lr_0 = 1.0000e-04
Validation rmse = 0.837341
Epoch 29
Loss = 4.6662e-04, PNorm = 77.3356, GNorm = 0.3958, lr_0 = 1.0000e-04
Loss = 6.1601e-04, PNorm = 77.3432, GNorm = 0.2474, lr_0 = 1.0000e-04
Validation rmse = 0.899598
Model 0 best validation rmse = 0.817968 on epoch 7
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.951778
Ensemble test rmse = 0.951778
Fold 6
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.05_ffn_num_layers_2_hidden_size_1800/fold_6',
 'save_smiles_splits': True,
 'seed': 6,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 6
Total scaffolds = 195 | train scaffolds = 64 | val scaffolds = 68 | test scaffolds = 63
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1800, bias=False)
      (W_h): Linear(in_features=1800, out_features=1800, bias=False)
      (W_o): Linear(in_features=1933, out_features=1800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=1804, out_features=1800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=1800, out_features=1, bias=True)
  )
)
Number of parameters = 10,236,601
Moving model to cuda
Epoch 0
Loss = 1.5004e-02, PNorm = 75.8080, GNorm = 3.4878, lr_0 = 3.6053e-04
Validation rmse = 1.663293
Epoch 1
Loss = 5.2421e-03, PNorm = 75.9029, GNorm = 4.5548, lr_0 = 6.2105e-04
Loss = 3.5607e-03, PNorm = 76.0043, GNorm = 1.6045, lr_0 = 8.5789e-04
Validation rmse = 1.325634
Epoch 2
Loss = 2.6633e-03, PNorm = 76.0924, GNorm = 0.5192, lr_0 = 9.8284e-04
Loss = 2.9836e-03, PNorm = 76.1621, GNorm = 1.6113, lr_0 = 9.4120e-04
Validation rmse = 1.217760
Epoch 3
Loss = 2.0721e-03, PNorm = 76.2312, GNorm = 1.7732, lr_0 = 8.9744e-04
Loss = 2.0904e-03, PNorm = 76.2830, GNorm = 0.4897, lr_0 = 8.5943e-04
Validation rmse = 1.120517
Epoch 4
Loss = 1.9576e-03, PNorm = 76.3343, GNorm = 1.5324, lr_0 = 8.2303e-04
Loss = 2.2992e-03, PNorm = 76.3902, GNorm = 0.8895, lr_0 = 7.8816e-04
Validation rmse = 1.153553
Epoch 5
Loss = 1.3700e-03, PNorm = 76.4357, GNorm = 0.4204, lr_0 = 7.5478e-04
Loss = 1.6858e-03, PNorm = 76.4734, GNorm = 0.5204, lr_0 = 7.2281e-04
Validation rmse = 1.219348
Epoch 6
Loss = 1.7932e-03, PNorm = 76.5121, GNorm = 0.9483, lr_0 = 6.8920e-04
Loss = 1.6267e-03, PNorm = 76.5553, GNorm = 0.5852, lr_0 = 6.6001e-04
Validation rmse = 1.148670
Epoch 7
Loss = 2.1803e-03, PNorm = 76.5896, GNorm = 1.6131, lr_0 = 6.3205e-04
Loss = 1.8480e-03, PNorm = 76.6335, GNorm = 0.8491, lr_0 = 6.0528e-04
Validation rmse = 1.042609
Epoch 8
Loss = 1.5358e-03, PNorm = 76.6733, GNorm = 0.3976, lr_0 = 5.7714e-04
Loss = 1.2250e-03, PNorm = 76.7080, GNorm = 0.4706, lr_0 = 5.5269e-04
Validation rmse = 1.132630
Epoch 9
Loss = 1.1825e-03, PNorm = 76.7394, GNorm = 0.2575, lr_0 = 5.2928e-04
Loss = 1.0576e-03, PNorm = 76.7719, GNorm = 0.4142, lr_0 = 5.0686e-04
Validation rmse = 1.018496
Epoch 10
Loss = 1.1846e-03, PNorm = 76.8065, GNorm = 0.3613, lr_0 = 4.8539e-04
Loss = 1.0325e-03, PNorm = 76.8378, GNorm = 0.6649, lr_0 = 4.6483e-04
Validation rmse = 1.024404
Epoch 11
Loss = 1.3275e-03, PNorm = 76.8617, GNorm = 0.6125, lr_0 = 4.4322e-04
Loss = 1.0344e-03, PNorm = 76.8912, GNorm = 0.6703, lr_0 = 4.2444e-04
Validation rmse = 1.020024
Epoch 12
Loss = 8.2040e-04, PNorm = 76.9191, GNorm = 0.9556, lr_0 = 4.0646e-04
Loss = 9.8084e-04, PNorm = 76.9437, GNorm = 0.6047, lr_0 = 3.8925e-04
Validation rmse = 1.055700
Epoch 13
Loss = 9.4102e-04, PNorm = 76.9677, GNorm = 0.3641, lr_0 = 3.7276e-04
Loss = 8.9841e-04, PNorm = 76.9966, GNorm = 0.4325, lr_0 = 3.5697e-04
Validation rmse = 1.031072
Epoch 14
Loss = 8.9050e-04, PNorm = 77.0260, GNorm = 0.6860, lr_0 = 3.4037e-04
Loss = 1.0110e-03, PNorm = 77.0491, GNorm = 0.3540, lr_0 = 3.2596e-04
Validation rmse = 1.008235
Epoch 15
Loss = 6.8313e-04, PNorm = 77.0712, GNorm = 0.7012, lr_0 = 3.1215e-04
Loss = 8.8097e-04, PNorm = 77.0941, GNorm = 0.4829, lr_0 = 2.9893e-04
Validation rmse = 1.192717
Epoch 16
Loss = 9.3771e-04, PNorm = 77.1174, GNorm = 1.1979, lr_0 = 2.8503e-04
Loss = 9.7049e-04, PNorm = 77.1373, GNorm = 1.5639, lr_0 = 2.7295e-04
Validation rmse = 1.061938
Epoch 17
Loss = 1.0396e-03, PNorm = 77.1606, GNorm = 0.8430, lr_0 = 2.6139e-04
Loss = 8.0093e-04, PNorm = 77.1794, GNorm = 0.4342, lr_0 = 2.5032e-04
Validation rmse = 1.004782
Epoch 18
Loss = 9.1220e-04, PNorm = 77.2005, GNorm = 0.3429, lr_0 = 2.3972e-04
Loss = 8.4305e-04, PNorm = 77.2190, GNorm = 0.5620, lr_0 = 2.2956e-04
Validation rmse = 0.985804
Epoch 19
Loss = 7.1509e-04, PNorm = 77.2397, GNorm = 0.3169, lr_0 = 2.1889e-04
Loss = 7.2303e-04, PNorm = 77.2550, GNorm = 0.3001, lr_0 = 2.0962e-04
Validation rmse = 1.019811
Epoch 20
Loss = 6.6861e-04, PNorm = 77.2718, GNorm = 0.4272, lr_0 = 2.0074e-04
Loss = 7.7332e-04, PNorm = 77.2846, GNorm = 0.2776, lr_0 = 1.9224e-04
Validation rmse = 0.979708
Epoch 21
Loss = 6.1863e-04, PNorm = 77.3001, GNorm = 0.4051, lr_0 = 1.8409e-04
Loss = 5.8514e-04, PNorm = 77.3124, GNorm = 0.4199, lr_0 = 1.7630e-04
Validation rmse = 1.043785
Epoch 22
Loss = 6.2293e-04, PNorm = 77.3268, GNorm = 0.3625, lr_0 = 1.6810e-04
Loss = 5.9267e-04, PNorm = 77.3382, GNorm = 0.2090, lr_0 = 1.6098e-04
Validation rmse = 0.993646
Epoch 23
Loss = 5.7552e-04, PNorm = 77.3512, GNorm = 0.6372, lr_0 = 1.5416e-04
Loss = 8.1072e-04, PNorm = 77.3614, GNorm = 0.3901, lr_0 = 1.4763e-04
Loss = 1.1560e-03, PNorm = 77.3624, GNorm = 0.3766, lr_0 = 1.4699e-04
Validation rmse = 1.029232
Epoch 24
Loss = 4.9273e-04, PNorm = 77.3729, GNorm = 0.2672, lr_0 = 1.4077e-04
Loss = 6.1292e-04, PNorm = 77.3843, GNorm = 0.3543, lr_0 = 1.3480e-04
Validation rmse = 1.013622
Epoch 25
Loss = 4.1617e-04, PNorm = 77.3939, GNorm = 0.4641, lr_0 = 1.2909e-04
Loss = 5.6001e-04, PNorm = 77.4033, GNorm = 0.5340, lr_0 = 1.2362e-04
Validation rmse = 0.991282
Epoch 26
Loss = 5.6210e-04, PNorm = 77.4105, GNorm = 0.1933, lr_0 = 1.1839e-04
Validation rmse = 0.985782
Epoch 27
Loss = 7.4419e-04, PNorm = 77.4198, GNorm = 0.7397, lr_0 = 1.1288e-04
Loss = 5.0905e-04, PNorm = 77.4275, GNorm = 0.2940, lr_0 = 1.0810e-04
Validation rmse = 1.000377
Epoch 28
Loss = 4.3357e-04, PNorm = 77.4371, GNorm = 0.2670, lr_0 = 1.0352e-04
Loss = 4.8049e-04, PNorm = 77.4430, GNorm = 0.5097, lr_0 = 1.0000e-04
Validation rmse = 1.009419
Epoch 29
Loss = 5.3587e-04, PNorm = 77.4510, GNorm = 0.4955, lr_0 = 1.0000e-04
Loss = 5.1884e-04, PNorm = 77.4580, GNorm = 0.4081, lr_0 = 1.0000e-04
Validation rmse = 0.983743
Model 0 best validation rmse = 0.979708 on epoch 20
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.735710
Ensemble test rmse = 0.735710
Fold 7
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.05_ffn_num_layers_2_hidden_size_1800/fold_7',
 'save_smiles_splits': True,
 'seed': 7,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 7
Total scaffolds = 195 | train scaffolds = 69 | val scaffolds = 65 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1800, bias=False)
      (W_h): Linear(in_features=1800, out_features=1800, bias=False)
      (W_o): Linear(in_features=1933, out_features=1800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=1804, out_features=1800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=1800, out_features=1, bias=True)
  )
)
Number of parameters = 10,236,601
Moving model to cuda
Epoch 0
Loss = 1.3269e-02, PNorm = 75.8063, GNorm = 3.4872, lr_0 = 3.6053e-04
Validation rmse = 1.745946
Epoch 1
Loss = 3.9248e-03, PNorm = 75.8919, GNorm = 2.8869, lr_0 = 6.2105e-04
Loss = 3.7970e-03, PNorm = 75.9861, GNorm = 2.0227, lr_0 = 8.5789e-04
Validation rmse = 1.255648
Epoch 2
Loss = 2.0372e-03, PNorm = 76.0725, GNorm = 1.2139, lr_0 = 9.8284e-04
Loss = 2.8622e-03, PNorm = 76.1467, GNorm = 1.2074, lr_0 = 9.4120e-04
Validation rmse = 1.211236
Epoch 3
Loss = 2.6346e-03, PNorm = 76.2138, GNorm = 2.3013, lr_0 = 8.9744e-04
Loss = 2.3898e-03, PNorm = 76.2616, GNorm = 1.0114, lr_0 = 8.5943e-04
Validation rmse = 1.229914
Epoch 4
Loss = 2.0687e-03, PNorm = 76.3032, GNorm = 1.1382, lr_0 = 8.2303e-04
Loss = 1.8667e-03, PNorm = 76.3462, GNorm = 1.6773, lr_0 = 7.8816e-04
Validation rmse = 1.163989
Epoch 5
Loss = 1.7774e-03, PNorm = 76.3935, GNorm = 0.6565, lr_0 = 7.5478e-04
Loss = 1.7211e-03, PNorm = 76.4431, GNorm = 0.2468, lr_0 = 7.2281e-04
Validation rmse = 1.246877
Epoch 6
Loss = 1.8807e-03, PNorm = 76.4860, GNorm = 1.6139, lr_0 = 6.8920e-04
Loss = 1.4360e-03, PNorm = 76.5255, GNorm = 0.7809, lr_0 = 6.6001e-04
Validation rmse = 1.192441
Epoch 7
Loss = 1.2826e-03, PNorm = 76.5598, GNorm = 0.8648, lr_0 = 6.3205e-04
Loss = 1.5745e-03, PNorm = 76.5942, GNorm = 0.5513, lr_0 = 6.0528e-04
Validation rmse = 1.230582
Epoch 8
Loss = 1.5591e-03, PNorm = 76.6218, GNorm = 0.7802, lr_0 = 5.7714e-04
Loss = 1.6693e-03, PNorm = 76.6520, GNorm = 0.4640, lr_0 = 5.5269e-04
Validation rmse = 1.264205
Epoch 9
Loss = 1.2759e-03, PNorm = 76.6826, GNorm = 0.4563, lr_0 = 5.2928e-04
Loss = 1.1368e-03, PNorm = 76.7103, GNorm = 0.7400, lr_0 = 5.0686e-04
Validation rmse = 1.195489
Epoch 10
Loss = 1.2268e-03, PNorm = 76.7391, GNorm = 0.8118, lr_0 = 4.8539e-04
Loss = 1.0568e-03, PNorm = 76.7724, GNorm = 0.5247, lr_0 = 4.6483e-04
Validation rmse = 1.221074
Epoch 11
Loss = 8.7221e-04, PNorm = 76.8039, GNorm = 0.3562, lr_0 = 4.4322e-04
Loss = 1.0853e-03, PNorm = 76.8275, GNorm = 0.2117, lr_0 = 4.2444e-04
Validation rmse = 1.272194
Epoch 12
Loss = 1.0140e-03, PNorm = 76.8490, GNorm = 0.5660, lr_0 = 4.0646e-04
Loss = 9.0596e-04, PNorm = 76.8713, GNorm = 0.7602, lr_0 = 3.8925e-04
Validation rmse = 1.124816
Epoch 13
Loss = 1.0745e-03, PNorm = 76.8970, GNorm = 1.0021, lr_0 = 3.7276e-04
Loss = 1.0455e-03, PNorm = 76.9243, GNorm = 0.4279, lr_0 = 3.5697e-04
Validation rmse = 1.374441
Epoch 14
Loss = 1.1966e-03, PNorm = 76.9468, GNorm = 1.3973, lr_0 = 3.4037e-04
Loss = 9.9410e-04, PNorm = 76.9685, GNorm = 0.5638, lr_0 = 3.2596e-04
Validation rmse = 1.276587
Epoch 15
Loss = 9.3419e-04, PNorm = 76.9878, GNorm = 0.4085, lr_0 = 3.1215e-04
Loss = 8.5704e-04, PNorm = 77.0042, GNorm = 0.4122, lr_0 = 2.9893e-04
Validation rmse = 1.281872
Epoch 16
Loss = 8.6429e-04, PNorm = 77.0288, GNorm = 0.1999, lr_0 = 2.8503e-04
Loss = 8.6088e-04, PNorm = 77.0484, GNorm = 1.0788, lr_0 = 2.7295e-04
Validation rmse = 1.227989
Epoch 17
Loss = 1.1254e-03, PNorm = 77.0692, GNorm = 0.9658, lr_0 = 2.6139e-04
Loss = 8.6135e-04, PNorm = 77.0869, GNorm = 1.2558, lr_0 = 2.5032e-04
Validation rmse = 1.163027
Epoch 18
Loss = 8.3030e-04, PNorm = 77.1045, GNorm = 0.5024, lr_0 = 2.3972e-04
Loss = 8.6960e-04, PNorm = 77.1232, GNorm = 0.3962, lr_0 = 2.2956e-04
Validation rmse = 1.235977
Epoch 19
Loss = 7.6495e-04, PNorm = 77.1382, GNorm = 1.1239, lr_0 = 2.1889e-04
Loss = 7.2338e-04, PNorm = 77.1540, GNorm = 0.2844, lr_0 = 2.0962e-04
Validation rmse = 1.203106
Epoch 20
Loss = 6.1100e-04, PNorm = 77.1673, GNorm = 0.5933, lr_0 = 2.0074e-04
Loss = 6.3495e-04, PNorm = 77.1787, GNorm = 0.7397, lr_0 = 1.9224e-04
Validation rmse = 1.192260
Epoch 21
Loss = 5.9299e-04, PNorm = 77.1890, GNorm = 0.7347, lr_0 = 1.8409e-04
Loss = 6.6484e-04, PNorm = 77.2017, GNorm = 0.3961, lr_0 = 1.7630e-04
Validation rmse = 1.254732
Epoch 22
Loss = 5.7002e-04, PNorm = 77.2144, GNorm = 0.3593, lr_0 = 1.6810e-04
Loss = 6.3449e-04, PNorm = 77.2255, GNorm = 0.4851, lr_0 = 1.6098e-04
Validation rmse = 1.293498
Epoch 23
Loss = 5.6954e-04, PNorm = 77.2361, GNorm = 0.3412, lr_0 = 1.5416e-04
Loss = 5.0311e-04, PNorm = 77.2464, GNorm = 0.3234, lr_0 = 1.4763e-04
Loss = 1.3029e-03, PNorm = 77.2470, GNorm = 0.6279, lr_0 = 1.4699e-04
Validation rmse = 1.222190
Epoch 24
Loss = 6.5877e-04, PNorm = 77.2581, GNorm = 0.6468, lr_0 = 1.4077e-04
Loss = 6.1998e-04, PNorm = 77.2659, GNorm = 0.4761, lr_0 = 1.3480e-04
Validation rmse = 1.211801
Epoch 25
Loss = 4.7735e-04, PNorm = 77.2744, GNorm = 0.2062, lr_0 = 1.2909e-04
Loss = 6.0990e-04, PNorm = 77.2833, GNorm = 0.8346, lr_0 = 1.2362e-04
Validation rmse = 1.203892
Epoch 26
Loss = 6.2794e-04, PNorm = 77.2888, GNorm = 0.5568, lr_0 = 1.1839e-04
Validation rmse = 1.197732
Epoch 27
Loss = 4.4441e-04, PNorm = 77.2975, GNorm = 0.6125, lr_0 = 1.1288e-04
Loss = 5.4193e-04, PNorm = 77.3055, GNorm = 0.6491, lr_0 = 1.0810e-04
Validation rmse = 1.269580
Epoch 28
Loss = 3.8151e-04, PNorm = 77.3139, GNorm = 0.2025, lr_0 = 1.0352e-04
Loss = 5.1809e-04, PNorm = 77.3201, GNorm = 0.5807, lr_0 = 1.0000e-04
Validation rmse = 1.257085
Epoch 29
Loss = 5.4108e-04, PNorm = 77.3273, GNorm = 0.2595, lr_0 = 1.0000e-04
Loss = 4.1896e-04, PNorm = 77.3339, GNorm = 0.4247, lr_0 = 1.0000e-04
Validation rmse = 1.226242
Model 0 best validation rmse = 1.124816 on epoch 12
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.780314
Ensemble test rmse = 0.780314
Fold 8
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.05_ffn_num_layers_2_hidden_size_1800/fold_8',
 'save_smiles_splits': True,
 'seed': 8,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 8
Total scaffolds = 195 | train scaffolds = 75 | val scaffolds = 42 | test scaffolds = 78
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1800, bias=False)
      (W_h): Linear(in_features=1800, out_features=1800, bias=False)
      (W_o): Linear(in_features=1933, out_features=1800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=1804, out_features=1800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=1800, out_features=1, bias=True)
  )
)
Number of parameters = 10,236,601
Moving model to cuda
Epoch 0
Loss = 9.5986e-03, PNorm = 75.8081, GNorm = 5.5847, lr_0 = 3.6053e-04
Validation rmse = 1.269559
Epoch 1
Loss = 3.0388e-03, PNorm = 75.8776, GNorm = 1.6328, lr_0 = 6.2105e-04
Loss = 3.9976e-03, PNorm = 75.9626, GNorm = 5.3088, lr_0 = 8.5789e-04
Validation rmse = 1.079915
Epoch 2
Loss = 2.8222e-03, PNorm = 76.0479, GNorm = 2.1992, lr_0 = 9.8284e-04
Loss = 2.4116e-03, PNorm = 76.1191, GNorm = 2.1010, lr_0 = 9.4120e-04
Validation rmse = 1.023709
Epoch 3
Loss = 1.8808e-03, PNorm = 76.1812, GNorm = 0.7359, lr_0 = 8.9744e-04
Loss = 1.8242e-03, PNorm = 76.2283, GNorm = 1.1367, lr_0 = 8.5943e-04
Validation rmse = 0.949673
Epoch 4
Loss = 2.6061e-03, PNorm = 76.2782, GNorm = 1.1645, lr_0 = 8.2303e-04
Loss = 1.6882e-03, PNorm = 76.3217, GNorm = 0.5004, lr_0 = 7.8816e-04
Validation rmse = 0.864852
Epoch 5
Loss = 9.3438e-04, PNorm = 76.3558, GNorm = 1.2527, lr_0 = 7.5478e-04
Loss = 1.6421e-03, PNorm = 76.3913, GNorm = 1.4297, lr_0 = 7.2281e-04
Validation rmse = 0.941227
Epoch 6
Loss = 1.1266e-03, PNorm = 76.4289, GNorm = 1.0646, lr_0 = 6.8920e-04
Loss = 1.2416e-03, PNorm = 76.4618, GNorm = 0.4979, lr_0 = 6.6001e-04
Validation rmse = 0.935441
Epoch 7
Loss = 1.3440e-03, PNorm = 76.4904, GNorm = 1.1602, lr_0 = 6.3205e-04
Loss = 1.4265e-03, PNorm = 76.5185, GNorm = 0.9486, lr_0 = 6.0528e-04
Validation rmse = 0.866381
Epoch 8
Loss = 1.5848e-03, PNorm = 76.5469, GNorm = 1.1481, lr_0 = 5.7714e-04
Loss = 1.2280e-03, PNorm = 76.5764, GNorm = 1.5882, lr_0 = 5.5269e-04
Validation rmse = 0.963308
Epoch 9
Loss = 1.5711e-03, PNorm = 76.6077, GNorm = 2.3287, lr_0 = 5.2928e-04
Loss = 1.1851e-03, PNorm = 76.6364, GNorm = 0.3441, lr_0 = 5.0686e-04
Validation rmse = 0.862304
Epoch 10
Loss = 9.4272e-04, PNorm = 76.6643, GNorm = 0.4961, lr_0 = 4.8539e-04
Loss = 1.0178e-03, PNorm = 76.6897, GNorm = 0.8379, lr_0 = 4.6483e-04
Validation rmse = 0.878495
Epoch 11
Loss = 1.2151e-03, PNorm = 76.7139, GNorm = 0.3555, lr_0 = 4.4322e-04
Loss = 8.7087e-04, PNorm = 76.7391, GNorm = 1.0029, lr_0 = 4.2444e-04
Validation rmse = 0.859910
Epoch 12
Loss = 9.2352e-04, PNorm = 76.7648, GNorm = 0.5689, lr_0 = 4.0646e-04
Loss = 7.8407e-04, PNorm = 76.7888, GNorm = 0.2844, lr_0 = 3.8925e-04
Validation rmse = 0.783464
Epoch 13
Loss = 8.1966e-04, PNorm = 76.8102, GNorm = 0.4296, lr_0 = 3.7276e-04
Loss = 8.3552e-04, PNorm = 76.8318, GNorm = 1.0513, lr_0 = 3.5697e-04
Validation rmse = 0.774264
Epoch 14
Loss = 9.7713e-04, PNorm = 76.8531, GNorm = 0.6301, lr_0 = 3.4037e-04
Loss = 8.3190e-04, PNorm = 76.8699, GNorm = 0.6687, lr_0 = 3.2596e-04
Validation rmse = 0.806800
Epoch 15
Loss = 7.9501e-04, PNorm = 76.8865, GNorm = 0.3746, lr_0 = 3.1215e-04
Loss = 8.3742e-04, PNorm = 76.9079, GNorm = 0.3970, lr_0 = 2.9893e-04
Validation rmse = 0.818810
Epoch 16
Loss = 7.3126e-04, PNorm = 76.9273, GNorm = 0.4252, lr_0 = 2.8503e-04
Loss = 9.7151e-04, PNorm = 76.9447, GNorm = 0.5027, lr_0 = 2.7295e-04
Validation rmse = 0.850818
Epoch 17
Loss = 7.4536e-04, PNorm = 76.9574, GNorm = 0.4847, lr_0 = 2.6139e-04
Loss = 9.7943e-04, PNorm = 76.9761, GNorm = 0.4082, lr_0 = 2.5032e-04
Validation rmse = 0.901626
Epoch 18
Loss = 8.1018e-04, PNorm = 76.9935, GNorm = 0.4055, lr_0 = 2.3972e-04
Loss = 6.9900e-04, PNorm = 77.0061, GNorm = 0.3045, lr_0 = 2.2956e-04
Validation rmse = 0.829875
Epoch 19
Loss = 7.2464e-04, PNorm = 77.0224, GNorm = 0.3988, lr_0 = 2.1889e-04
Loss = 6.5040e-04, PNorm = 77.0365, GNorm = 0.4645, lr_0 = 2.0962e-04
Validation rmse = 0.846951
Epoch 20
Loss = 5.7646e-04, PNorm = 77.0500, GNorm = 0.3572, lr_0 = 2.0074e-04
Loss = 7.1029e-04, PNorm = 77.0637, GNorm = 0.7381, lr_0 = 1.9224e-04
Validation rmse = 0.867931
Epoch 21
Loss = 5.7832e-04, PNorm = 77.0765, GNorm = 0.5660, lr_0 = 1.8409e-04
Loss = 5.6326e-04, PNorm = 77.0873, GNorm = 0.2796, lr_0 = 1.7630e-04
Validation rmse = 0.830679
Epoch 22
Loss = 6.3987e-04, PNorm = 77.0992, GNorm = 0.7630, lr_0 = 1.6810e-04
Loss = 6.7808e-04, PNorm = 77.1106, GNorm = 0.4403, lr_0 = 1.6098e-04
Validation rmse = 0.879900
Epoch 23
Loss = 5.7176e-04, PNorm = 77.1207, GNorm = 0.4922, lr_0 = 1.5416e-04
Loss = 5.6189e-04, PNorm = 77.1315, GNorm = 0.5085, lr_0 = 1.4763e-04
Loss = 6.9571e-04, PNorm = 77.1323, GNorm = 0.3011, lr_0 = 1.4699e-04
Validation rmse = 0.844133
Epoch 24
Loss = 4.5536e-04, PNorm = 77.1403, GNorm = 0.4698, lr_0 = 1.4077e-04
Loss = 5.1320e-04, PNorm = 77.1491, GNorm = 0.4028, lr_0 = 1.3480e-04
Validation rmse = 0.852174
Epoch 25
Loss = 5.5646e-04, PNorm = 77.1553, GNorm = 0.7218, lr_0 = 1.2909e-04
Loss = 4.8990e-04, PNorm = 77.1639, GNorm = 0.4524, lr_0 = 1.2362e-04
Validation rmse = 0.880083
Epoch 26
Loss = 4.9839e-04, PNorm = 77.1729, GNorm = 0.2598, lr_0 = 1.1839e-04
Validation rmse = 0.842841
Epoch 27
Loss = 1.0581e-03, PNorm = 77.1789, GNorm = 1.2637, lr_0 = 1.1288e-04
Loss = 4.9291e-04, PNorm = 77.1847, GNorm = 0.2314, lr_0 = 1.0810e-04
Validation rmse = 0.855324
Epoch 28
Loss = 4.1565e-04, PNorm = 77.1917, GNorm = 0.4306, lr_0 = 1.0352e-04
Loss = 4.5372e-04, PNorm = 77.1983, GNorm = 0.3784, lr_0 = 1.0000e-04
Validation rmse = 0.882203
Epoch 29
Loss = 5.2361e-04, PNorm = 77.2073, GNorm = 0.2608, lr_0 = 1.0000e-04
Loss = 3.9901e-04, PNorm = 77.2133, GNorm = 0.3781, lr_0 = 1.0000e-04
Validation rmse = 0.864976
Model 0 best validation rmse = 0.774264 on epoch 13
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.024486
Ensemble test rmse = 1.024486
Fold 9
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_6_dropout_0.05_ffn_num_layers_2_hidden_size_1800/fold_9',
 'save_smiles_splits': True,
 'seed': 9,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 9
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 58 | test scaffolds = 53
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1800, bias=False)
      (W_h): Linear(in_features=1800, out_features=1800, bias=False)
      (W_o): Linear(in_features=1933, out_features=1800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=1804, out_features=1800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.05, inplace=False)
    (4): Linear(in_features=1800, out_features=1, bias=True)
  )
)
Number of parameters = 10,236,601
Moving model to cuda
Epoch 0
Loss = 1.6130e-02, PNorm = 75.8065, GNorm = 1.2742, lr_0 = 3.6053e-04
Validation rmse = 1.231047
Epoch 1
Loss = 3.8534e-03, PNorm = 75.9020, GNorm = 1.0788, lr_0 = 6.2105e-04
Loss = 4.3389e-03, PNorm = 76.0038, GNorm = 2.1048, lr_0 = 8.5789e-04
Validation rmse = 1.000608
Epoch 2
Loss = 2.5222e-03, PNorm = 76.1064, GNorm = 0.6592, lr_0 = 9.8284e-04
Loss = 3.7431e-03, PNorm = 76.1876, GNorm = 0.9331, lr_0 = 9.4120e-04
Validation rmse = 0.945019
Epoch 3
Loss = 2.1021e-03, PNorm = 76.2611, GNorm = 1.1337, lr_0 = 8.9744e-04
Loss = 2.5105e-03, PNorm = 76.3157, GNorm = 0.4912, lr_0 = 8.5943e-04
Validation rmse = 0.856249
Epoch 4
Loss = 1.9617e-03, PNorm = 76.3674, GNorm = 1.2939, lr_0 = 8.2303e-04
Loss = 1.5906e-03, PNorm = 76.4076, GNorm = 0.5547, lr_0 = 7.8816e-04
Validation rmse = 0.847065
Epoch 5
Loss = 1.4976e-03, PNorm = 76.4467, GNorm = 1.6360, lr_0 = 7.5478e-04
Loss = 1.7757e-03, PNorm = 76.4888, GNorm = 0.8633, lr_0 = 7.2281e-04
Validation rmse = 0.866755
Epoch 6
Loss = 1.4716e-03, PNorm = 76.5276, GNorm = 1.7105, lr_0 = 6.8920e-04
Loss = 1.7071e-03, PNorm = 76.5567, GNorm = 0.5108, lr_0 = 6.6001e-04
Validation rmse = 0.833025
Epoch 7
Loss = 1.8178e-03, PNorm = 76.5907, GNorm = 0.7770, lr_0 = 6.3205e-04
Loss = 1.6791e-03, PNorm = 76.6252, GNorm = 1.9426, lr_0 = 6.0528e-04
Validation rmse = 0.720395
Epoch 8
Loss = 1.5429e-03, PNorm = 76.6613, GNorm = 1.5985, lr_0 = 5.7714e-04
Loss = 1.5321e-03, PNorm = 76.6952, GNorm = 0.4738, lr_0 = 5.5269e-04
Validation rmse = 0.794708
Epoch 9
Loss = 1.0602e-03, PNorm = 76.7246, GNorm = 0.3009, lr_0 = 5.2928e-04
Loss = 1.0810e-03, PNorm = 76.7539, GNorm = 0.5846, lr_0 = 5.0686e-04
Validation rmse = 0.732779
Epoch 10
Loss = 1.1364e-03, PNorm = 76.7777, GNorm = 0.3601, lr_0 = 4.8539e-04
Loss = 1.0281e-03, PNorm = 76.8033, GNorm = 0.4285, lr_0 = 4.6483e-04
Validation rmse = 0.799151
Epoch 11
Loss = 1.3965e-03, PNorm = 76.8325, GNorm = 0.3813, lr_0 = 4.4322e-04
Loss = 1.0367e-03, PNorm = 76.8563, GNorm = 0.7332, lr_0 = 4.2444e-04
Validation rmse = 0.720394
Epoch 12
Loss = 1.0579e-03, PNorm = 76.8836, GNorm = 0.2215, lr_0 = 4.0646e-04
Loss = 1.1345e-03, PNorm = 76.9079, GNorm = 0.6985, lr_0 = 3.8925e-04
Validation rmse = 0.739917
Epoch 13
Loss = 7.7882e-04, PNorm = 76.9296, GNorm = 0.2949, lr_0 = 3.7276e-04
Loss = 1.0723e-03, PNorm = 76.9537, GNorm = 0.9409, lr_0 = 3.5697e-04
Validation rmse = 0.733381
Epoch 14
Loss = 7.9230e-04, PNorm = 76.9804, GNorm = 0.3918, lr_0 = 3.4037e-04
Loss = 9.9116e-04, PNorm = 76.9977, GNorm = 0.7421, lr_0 = 3.2596e-04
Validation rmse = 0.749633
Epoch 15
Loss = 8.4073e-04, PNorm = 77.0191, GNorm = 0.4033, lr_0 = 3.1215e-04
Loss = 8.6263e-04, PNorm = 77.0428, GNorm = 0.3371, lr_0 = 2.9893e-04
Validation rmse = 0.743980
Epoch 16
Loss = 9.0552e-04, PNorm = 77.0652, GNorm = 0.9511, lr_0 = 2.8503e-04
Loss = 7.8195e-04, PNorm = 77.0831, GNorm = 0.2972, lr_0 = 2.7295e-04
Validation rmse = 0.768047
Epoch 17
Loss = 7.8771e-04, PNorm = 77.0989, GNorm = 0.4365, lr_0 = 2.6139e-04
Loss = 8.9679e-04, PNorm = 77.1125, GNorm = 0.8311, lr_0 = 2.5032e-04
Validation rmse = 0.735212
Epoch 18
Loss = 6.7696e-04, PNorm = 77.1295, GNorm = 0.4616, lr_0 = 2.3972e-04
Loss = 7.9379e-04, PNorm = 77.1450, GNorm = 0.4709, lr_0 = 2.2956e-04
Validation rmse = 0.665894
Epoch 19
Loss = 6.9949e-04, PNorm = 77.1611, GNorm = 0.6553, lr_0 = 2.1889e-04
Loss = 8.7453e-04, PNorm = 77.1795, GNorm = 0.5391, lr_0 = 2.0962e-04
Validation rmse = 0.736693
Epoch 20
Loss = 8.0920e-04, PNorm = 77.1945, GNorm = 0.5701, lr_0 = 2.0074e-04
Loss = 6.2817e-04, PNorm = 77.2075, GNorm = 0.3227, lr_0 = 1.9224e-04
Validation rmse = 0.712239
Epoch 21
Loss = 4.9852e-04, PNorm = 77.2182, GNorm = 0.4277, lr_0 = 1.8409e-04
Loss = 7.1911e-04, PNorm = 77.2323, GNorm = 0.3824, lr_0 = 1.7630e-04
Validation rmse = 0.720931
Epoch 22
Loss = 6.4754e-04, PNorm = 77.2448, GNorm = 0.4400, lr_0 = 1.6810e-04
Loss = 5.6684e-04, PNorm = 77.2571, GNorm = 0.6275, lr_0 = 1.6098e-04
Validation rmse = 0.704580
Epoch 23
Loss = 5.2530e-04, PNorm = 77.2664, GNorm = 0.4466, lr_0 = 1.5416e-04
Loss = 6.0940e-04, PNorm = 77.2783, GNorm = 0.3014, lr_0 = 1.4763e-04
Loss = 8.1852e-04, PNorm = 77.2794, GNorm = 0.2917, lr_0 = 1.4699e-04
Validation rmse = 0.693043
Epoch 24
Loss = 5.6312e-04, PNorm = 77.2882, GNorm = 0.1635, lr_0 = 1.4077e-04
Loss = 6.7946e-04, PNorm = 77.2989, GNorm = 0.3279, lr_0 = 1.3480e-04
Validation rmse = 0.724700
Epoch 25
Loss = 7.1902e-04, PNorm = 77.3109, GNorm = 0.6667, lr_0 = 1.2909e-04
Loss = 5.4857e-04, PNorm = 77.3203, GNorm = 0.5156, lr_0 = 1.2362e-04
Validation rmse = 0.738706
Epoch 26
Loss = 6.3635e-04, PNorm = 77.3284, GNorm = 0.4206, lr_0 = 1.1839e-04
Validation rmse = 0.727618
Epoch 27
Loss = 4.2881e-04, PNorm = 77.3390, GNorm = 0.3989, lr_0 = 1.1288e-04
Loss = 7.2297e-04, PNorm = 77.3464, GNorm = 1.1041, lr_0 = 1.0810e-04
Validation rmse = 0.698319
Epoch 28
Loss = 2.9587e-04, PNorm = 77.3562, GNorm = 0.2982, lr_0 = 1.0352e-04
Loss = 4.6271e-04, PNorm = 77.3647, GNorm = 0.3225, lr_0 = 1.0000e-04
Validation rmse = 0.700354
Epoch 29
Loss = 8.0845e-04, PNorm = 77.3739, GNorm = 0.4812, lr_0 = 1.0000e-04
Loss = 5.8897e-04, PNorm = 77.3806, GNorm = 0.3206, lr_0 = 1.0000e-04
Validation rmse = 0.713057
Model 0 best validation rmse = 0.665894 on epoch 18
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.141874
Ensemble test rmse = 1.141874
10-fold cross validation
	Seed 0 ==> test rmse = 0.884773
	Seed 1 ==> test rmse = 0.886879
	Seed 2 ==> test rmse = 0.873391
	Seed 3 ==> test rmse = 0.811292
	Seed 4 ==> test rmse = 0.871551
	Seed 5 ==> test rmse = 0.951778
	Seed 6 ==> test rmse = 0.735710
	Seed 7 ==> test rmse = 0.780314
	Seed 8 ==> test rmse = 1.024486
	Seed 9 ==> test rmse = 1.141874
Overall test rmse = 0.896205 +/- 0.112979
Elapsed time = 0:08:27
Fold 0
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 900,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 900,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.05_ffn_num_layers_1_hidden_size_900/fold_0',
 'save_smiles_splits': True,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total scaffolds = 195 | train scaffolds = 91 | val scaffolds = 66 | test scaffolds = 38
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=900, bias=False)
      (W_h): Linear(in_features=900, out_features=900, bias=False)
      (W_o): Linear(in_features=1033, out_features=900, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=904, out_features=1, bias=True)
  )
)
Number of parameters = 1,873,805
Moving model to cuda
Epoch 0
Loss = 1.4697e-02, PNorm = 46.0522, GNorm = 4.0473, lr_0 = 3.6053e-04
Validation rmse = 2.213728
Epoch 1
Loss = 5.8576e-03, PNorm = 46.1002, GNorm = 2.7889, lr_0 = 6.2105e-04
Loss = 8.4801e-03, PNorm = 46.1538, GNorm = 3.3507, lr_0 = 8.5789e-04
Validation rmse = 1.643441
Epoch 2
Loss = 4.2010e-03, PNorm = 46.2203, GNorm = 0.8845, lr_0 = 9.8284e-04
Loss = 4.1358e-03, PNorm = 46.2687, GNorm = 1.3802, lr_0 = 9.4120e-04
Validation rmse = 1.998418
Epoch 3
Loss = 5.3682e-03, PNorm = 46.3116, GNorm = 4.8035, lr_0 = 8.9744e-04
Loss = 3.5155e-03, PNorm = 46.3461, GNorm = 1.9284, lr_0 = 8.5943e-04
Validation rmse = 1.313451
Epoch 4
Loss = 4.1656e-03, PNorm = 46.3767, GNorm = 2.5891, lr_0 = 8.2303e-04
Loss = 3.0324e-03, PNorm = 46.4091, GNorm = 5.2619, lr_0 = 7.8816e-04
Validation rmse = 1.237901
Epoch 5
Loss = 2.2489e-03, PNorm = 46.4397, GNorm = 3.1372, lr_0 = 7.5478e-04
Loss = 2.1264e-03, PNorm = 46.4673, GNorm = 2.5734, lr_0 = 7.2281e-04
Validation rmse = 1.344823
Epoch 6
Loss = 1.6540e-03, PNorm = 46.5017, GNorm = 1.0520, lr_0 = 6.8920e-04
Loss = 1.9179e-03, PNorm = 46.5226, GNorm = 0.9682, lr_0 = 6.6001e-04
Validation rmse = 1.445096
Epoch 7
Loss = 2.3351e-03, PNorm = 46.5441, GNorm = 3.7653, lr_0 = 6.3205e-04
Loss = 1.8287e-03, PNorm = 46.5667, GNorm = 2.0612, lr_0 = 6.0528e-04
Validation rmse = 1.106739
Epoch 8
Loss = 1.9596e-03, PNorm = 46.5894, GNorm = 1.6975, lr_0 = 5.7714e-04
Loss = 1.8045e-03, PNorm = 46.6103, GNorm = 0.7115, lr_0 = 5.5269e-04
Validation rmse = 1.128406
Epoch 9
Loss = 1.6178e-03, PNorm = 46.6308, GNorm = 3.1118, lr_0 = 5.2928e-04
Loss = 1.7029e-03, PNorm = 46.6523, GNorm = 1.2628, lr_0 = 5.0686e-04
Validation rmse = 1.192182
Epoch 10
Loss = 1.5197e-03, PNorm = 46.6697, GNorm = 1.6517, lr_0 = 4.8539e-04
Loss = 1.5975e-03, PNorm = 46.6876, GNorm = 1.6430, lr_0 = 4.6483e-04
Validation rmse = 1.207036
Epoch 11
Loss = 1.2136e-03, PNorm = 46.7042, GNorm = 0.4384, lr_0 = 4.4322e-04
Loss = 1.3017e-03, PNorm = 46.7203, GNorm = 1.3165, lr_0 = 4.2444e-04
Validation rmse = 1.062591
Epoch 12
Loss = 1.3704e-03, PNorm = 46.7331, GNorm = 1.3821, lr_0 = 4.0646e-04
Loss = 1.3629e-03, PNorm = 46.7479, GNorm = 1.0381, lr_0 = 3.8925e-04
Validation rmse = 1.068416
Epoch 13
Loss = 1.1208e-03, PNorm = 46.7633, GNorm = 0.3609, lr_0 = 3.7276e-04
Loss = 1.4373e-03, PNorm = 46.7781, GNorm = 0.6013, lr_0 = 3.5697e-04
Validation rmse = 1.237789
Epoch 14
Loss = 1.0858e-03, PNorm = 46.7930, GNorm = 1.3035, lr_0 = 3.4037e-04
Loss = 1.1884e-03, PNorm = 46.8065, GNorm = 1.7546, lr_0 = 3.2596e-04
Validation rmse = 1.043153
Epoch 15
Loss = 1.1143e-03, PNorm = 46.8189, GNorm = 0.7386, lr_0 = 3.1215e-04
Loss = 1.0375e-03, PNorm = 46.8304, GNorm = 1.5180, lr_0 = 2.9893e-04
Validation rmse = 1.114216
Epoch 16
Loss = 1.0736e-03, PNorm = 46.8430, GNorm = 0.4862, lr_0 = 2.8503e-04
Loss = 9.8039e-04, PNorm = 46.8537, GNorm = 1.3887, lr_0 = 2.7295e-04
Validation rmse = 1.066232
Epoch 17
Loss = 9.4708e-04, PNorm = 46.8672, GNorm = 1.8392, lr_0 = 2.6139e-04
Loss = 1.1501e-03, PNorm = 46.8793, GNorm = 0.6611, lr_0 = 2.5032e-04
Validation rmse = 1.010420
Epoch 18
Loss = 7.1739e-04, PNorm = 46.8894, GNorm = 0.7512, lr_0 = 2.3972e-04
Loss = 1.0274e-03, PNorm = 46.8989, GNorm = 0.9454, lr_0 = 2.2956e-04
Validation rmse = 1.138075
Epoch 19
Loss = 8.8848e-04, PNorm = 46.9101, GNorm = 0.9514, lr_0 = 2.1889e-04
Loss = 1.1704e-03, PNorm = 46.9187, GNorm = 0.8067, lr_0 = 2.0962e-04
Validation rmse = 1.178835
Epoch 20
Loss = 1.0206e-03, PNorm = 46.9272, GNorm = 0.4728, lr_0 = 2.0074e-04
Loss = 1.1302e-03, PNorm = 46.9354, GNorm = 1.8244, lr_0 = 1.9224e-04
Validation rmse = 1.054494
Epoch 21
Loss = 9.9520e-04, PNorm = 46.9433, GNorm = 0.9546, lr_0 = 1.8409e-04
Loss = 9.9565e-04, PNorm = 46.9522, GNorm = 1.5089, lr_0 = 1.7630e-04
Validation rmse = 1.023211
Epoch 22
Loss = 7.2681e-04, PNorm = 46.9609, GNorm = 0.7002, lr_0 = 1.6810e-04
Loss = 1.1291e-03, PNorm = 46.9680, GNorm = 1.0965, lr_0 = 1.6098e-04
Validation rmse = 0.995110
Epoch 23
Loss = 9.2399e-04, PNorm = 46.9749, GNorm = 0.5963, lr_0 = 1.5416e-04
Loss = 8.4802e-04, PNorm = 46.9817, GNorm = 1.1617, lr_0 = 1.4763e-04
Loss = 1.2568e-03, PNorm = 46.9824, GNorm = 0.8646, lr_0 = 1.4699e-04
Validation rmse = 1.083626
Epoch 24
Loss = 9.9314e-04, PNorm = 46.9878, GNorm = 0.5798, lr_0 = 1.4077e-04
Loss = 9.0780e-04, PNorm = 46.9943, GNorm = 1.0602, lr_0 = 1.3480e-04
Validation rmse = 1.064865
Epoch 25
Loss = 9.2316e-04, PNorm = 46.9990, GNorm = 1.0510, lr_0 = 1.2909e-04
Loss = 8.9428e-04, PNorm = 47.0046, GNorm = 0.5411, lr_0 = 1.2362e-04
Validation rmse = 1.069162
Epoch 26
Loss = 8.0848e-04, PNorm = 47.0104, GNorm = 1.3737, lr_0 = 1.1839e-04
Validation rmse = 1.043031
Epoch 27
Loss = 4.7016e-04, PNorm = 47.0159, GNorm = 0.9832, lr_0 = 1.1288e-04
Loss = 9.0315e-04, PNorm = 47.0207, GNorm = 0.9800, lr_0 = 1.0810e-04
Validation rmse = 1.017483
Epoch 28
Loss = 1.2313e-03, PNorm = 47.0254, GNorm = 0.9094, lr_0 = 1.0352e-04
Loss = 7.4740e-04, PNorm = 47.0303, GNorm = 0.3006, lr_0 = 1.0000e-04
Validation rmse = 1.007860
Epoch 29
Loss = 9.7318e-04, PNorm = 47.0354, GNorm = 1.4517, lr_0 = 1.0000e-04
Loss = 9.2193e-04, PNorm = 47.0404, GNorm = 0.3636, lr_0 = 1.0000e-04
Validation rmse = 1.099277
Model 0 best validation rmse = 0.995110 on epoch 22
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 0.881515
Ensemble test rmse = 0.881515
Fold 1
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 900,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 900,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.05_ffn_num_layers_1_hidden_size_900/fold_1',
 'save_smiles_splits': True,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total scaffolds = 195 | train scaffolds = 76 | val scaffolds = 60 | test scaffolds = 59
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=900, bias=False)
      (W_h): Linear(in_features=900, out_features=900, bias=False)
      (W_o): Linear(in_features=1033, out_features=900, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=904, out_features=1, bias=True)
  )
)
Number of parameters = 1,873,805
Moving model to cuda
Epoch 0
Loss = 1.7239e-02, PNorm = 46.0506, GNorm = 10.3094, lr_0 = 3.6053e-04
Validation rmse = 1.822641
Epoch 1
Loss = 8.1239e-03, PNorm = 46.0928, GNorm = 4.6428, lr_0 = 6.2105e-04
Loss = 7.1262e-03, PNorm = 46.1495, GNorm = 4.8298, lr_0 = 8.5789e-04
Validation rmse = 1.453524
Epoch 2
Loss = 4.8577e-03, PNorm = 46.2146, GNorm = 1.5324, lr_0 = 9.8284e-04
Loss = 4.1906e-03, PNorm = 46.2684, GNorm = 2.1093, lr_0 = 9.4120e-04
Validation rmse = 1.379676
Epoch 3
Loss = 3.5693e-03, PNorm = 46.3192, GNorm = 2.5737, lr_0 = 8.9744e-04
Loss = 3.6731e-03, PNorm = 46.3643, GNorm = 1.3511, lr_0 = 8.5943e-04
Validation rmse = 1.373077
Epoch 4
Loss = 1.8762e-03, PNorm = 46.4018, GNorm = 0.6667, lr_0 = 8.2303e-04
Loss = 2.3561e-03, PNorm = 46.4353, GNorm = 2.5417, lr_0 = 7.8816e-04
Validation rmse = 1.249095
Epoch 5
Loss = 1.7077e-03, PNorm = 46.4640, GNorm = 1.1049, lr_0 = 7.5478e-04
Loss = 2.3113e-03, PNorm = 46.4954, GNorm = 1.5175, lr_0 = 7.2281e-04
Validation rmse = 1.188767
Epoch 6
Loss = 1.9325e-03, PNorm = 46.5235, GNorm = 0.9741, lr_0 = 6.8920e-04
Loss = 2.2468e-03, PNorm = 46.5541, GNorm = 1.3331, lr_0 = 6.6001e-04
Validation rmse = 1.296022
Epoch 7
Loss = 2.1398e-03, PNorm = 46.5800, GNorm = 1.3794, lr_0 = 6.3205e-04
Loss = 2.2513e-03, PNorm = 46.6023, GNorm = 0.8015, lr_0 = 6.0528e-04
Validation rmse = 1.163992
Epoch 8
Loss = 1.8675e-03, PNorm = 46.6293, GNorm = 0.6246, lr_0 = 5.7714e-04
Loss = 1.4732e-03, PNorm = 46.6511, GNorm = 1.6546, lr_0 = 5.5269e-04
Validation rmse = 1.169559
Epoch 9
Loss = 1.2428e-03, PNorm = 46.6707, GNorm = 0.4681, lr_0 = 5.2928e-04
Loss = 1.5143e-03, PNorm = 46.6874, GNorm = 0.5162, lr_0 = 5.0686e-04
Validation rmse = 1.107089
Epoch 10
Loss = 1.1428e-03, PNorm = 46.7064, GNorm = 0.4270, lr_0 = 4.8539e-04
Loss = 1.1330e-03, PNorm = 46.7213, GNorm = 0.7263, lr_0 = 4.6483e-04
Validation rmse = 1.102698
Epoch 11
Loss = 1.8282e-03, PNorm = 46.7383, GNorm = 3.5064, lr_0 = 4.4322e-04
Loss = 1.6028e-03, PNorm = 46.7539, GNorm = 3.2252, lr_0 = 4.2444e-04
Validation rmse = 1.074069
Epoch 12
Loss = 1.0771e-03, PNorm = 46.7711, GNorm = 0.7020, lr_0 = 4.0646e-04
Loss = 1.4288e-03, PNorm = 46.7868, GNorm = 1.7202, lr_0 = 3.8925e-04
Validation rmse = 1.132715
Epoch 13
Loss = 1.6705e-03, PNorm = 46.8017, GNorm = 2.1374, lr_0 = 3.7276e-04
Loss = 1.3247e-03, PNorm = 46.8172, GNorm = 0.5079, lr_0 = 3.5697e-04
Validation rmse = 1.017173
Epoch 14
Loss = 1.1871e-03, PNorm = 46.8339, GNorm = 2.0233, lr_0 = 3.4037e-04
Loss = 1.3109e-03, PNorm = 46.8472, GNorm = 0.9304, lr_0 = 3.2596e-04
Validation rmse = 1.083858
Epoch 15
Loss = 1.4248e-03, PNorm = 46.8580, GNorm = 1.1829, lr_0 = 3.1215e-04
Loss = 1.0463e-03, PNorm = 46.8730, GNorm = 0.7585, lr_0 = 2.9893e-04
Validation rmse = 1.006347
Epoch 16
Loss = 9.0532e-04, PNorm = 46.8842, GNorm = 0.5695, lr_0 = 2.8503e-04
Loss = 1.2250e-03, PNorm = 46.8941, GNorm = 1.1607, lr_0 = 2.7295e-04
Validation rmse = 1.066551
Epoch 17
Loss = 1.0333e-03, PNorm = 46.9058, GNorm = 1.1546, lr_0 = 2.6139e-04
Loss = 1.1393e-03, PNorm = 46.9144, GNorm = 0.8409, lr_0 = 2.5032e-04
Validation rmse = 1.052254
Epoch 18
Loss = 1.0351e-03, PNorm = 46.9252, GNorm = 0.8942, lr_0 = 2.3972e-04
Loss = 1.0678e-03, PNorm = 46.9339, GNorm = 2.0410, lr_0 = 2.2956e-04
Validation rmse = 1.039204
Epoch 19
Loss = 7.4043e-04, PNorm = 46.9441, GNorm = 0.5009, lr_0 = 2.1889e-04
Loss = 1.0454e-03, PNorm = 46.9530, GNorm = 0.9495, lr_0 = 2.0962e-04
Validation rmse = 1.005603
Epoch 20
Loss = 8.3234e-04, PNorm = 46.9625, GNorm = 0.9143, lr_0 = 2.0074e-04
Loss = 9.9217e-04, PNorm = 46.9719, GNorm = 0.4473, lr_0 = 1.9224e-04
Validation rmse = 0.999179
Epoch 21
Loss = 8.3607e-04, PNorm = 46.9793, GNorm = 1.3368, lr_0 = 1.8409e-04
Loss = 1.0655e-03, PNorm = 46.9864, GNorm = 1.3148, lr_0 = 1.7630e-04
Validation rmse = 0.989737
Epoch 22
Loss = 8.9726e-04, PNorm = 46.9949, GNorm = 1.1379, lr_0 = 1.6810e-04
Loss = 8.3078e-04, PNorm = 47.0013, GNorm = 1.1958, lr_0 = 1.6098e-04
Validation rmse = 1.037980
Epoch 23
Loss = 9.6765e-04, PNorm = 47.0088, GNorm = 0.6317, lr_0 = 1.5416e-04
Loss = 8.4382e-04, PNorm = 47.0158, GNorm = 0.5761, lr_0 = 1.4763e-04
Loss = 1.3024e-03, PNorm = 47.0166, GNorm = 1.5727, lr_0 = 1.4699e-04
Validation rmse = 0.992096
Epoch 24
Loss = 9.9681e-04, PNorm = 47.0240, GNorm = 1.0820, lr_0 = 1.4077e-04
Loss = 7.7708e-04, PNorm = 47.0308, GNorm = 0.3891, lr_0 = 1.3480e-04
Validation rmse = 0.996656
Epoch 25
Loss = 7.7001e-04, PNorm = 47.0364, GNorm = 0.5307, lr_0 = 1.2909e-04
Loss = 9.1930e-04, PNorm = 47.0416, GNorm = 1.6530, lr_0 = 1.2362e-04
Validation rmse = 0.996793
Epoch 26
Loss = 8.8557e-04, PNorm = 47.0479, GNorm = 1.2702, lr_0 = 1.1839e-04
Validation rmse = 1.022450
Epoch 27
Loss = 9.2515e-04, PNorm = 47.0533, GNorm = 1.9275, lr_0 = 1.1288e-04
Loss = 8.1833e-04, PNorm = 47.0584, GNorm = 0.9785, lr_0 = 1.0810e-04
Validation rmse = 1.001090
Epoch 28
Loss = 4.7843e-04, PNorm = 47.0629, GNorm = 0.5302, lr_0 = 1.0352e-04
Loss = 8.2834e-04, PNorm = 47.0673, GNorm = 1.4167, lr_0 = 1.0000e-04
Validation rmse = 0.999972
Epoch 29
Loss = 5.2044e-04, PNorm = 47.0722, GNorm = 0.6287, lr_0 = 1.0000e-04
Loss = 7.7447e-04, PNorm = 47.0784, GNorm = 0.9736, lr_0 = 1.0000e-04
Validation rmse = 0.977297
Model 0 best validation rmse = 0.977297 on epoch 29
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.041063
Ensemble test rmse = 1.041063
Fold 2
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 900,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 900,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.05_ffn_num_layers_1_hidden_size_900/fold_2',
 'save_smiles_splits': True,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total scaffolds = 195 | train scaffolds = 55 | val scaffolds = 64 | test scaffolds = 76
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=900, bias=False)
      (W_h): Linear(in_features=900, out_features=900, bias=False)
      (W_o): Linear(in_features=1033, out_features=900, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=904, out_features=1, bias=True)
  )
)
Number of parameters = 1,873,805
Moving model to cuda
Epoch 0
Loss = 1.4892e-02, PNorm = 46.0523, GNorm = 2.8702, lr_0 = 3.6053e-04
Validation rmse = 1.584358
Epoch 1
Loss = 6.2577e-03, PNorm = 46.0968, GNorm = 3.7916, lr_0 = 6.2105e-04
Loss = 7.5516e-03, PNorm = 46.1580, GNorm = 2.5778, lr_0 = 8.5789e-04
Validation rmse = 1.453994
Epoch 2
Loss = 7.2081e-03, PNorm = 46.2217, GNorm = 5.5573, lr_0 = 9.8284e-04
Loss = 4.4997e-03, PNorm = 46.2759, GNorm = 2.2992, lr_0 = 9.4120e-04
Validation rmse = 1.497090
Epoch 3
Loss = 4.5833e-03, PNorm = 46.3274, GNorm = 1.7427, lr_0 = 8.9744e-04
Loss = 3.9690e-03, PNorm = 46.3676, GNorm = 1.5827, lr_0 = 8.5943e-04
Validation rmse = 1.403415
Epoch 4
Loss = 2.0626e-03, PNorm = 46.4058, GNorm = 1.0477, lr_0 = 8.2303e-04
Loss = 2.9009e-03, PNorm = 46.4422, GNorm = 5.7538, lr_0 = 7.8816e-04
Validation rmse = 1.446075
Epoch 5
Loss = 1.9716e-03, PNorm = 46.4817, GNorm = 1.8514, lr_0 = 7.5478e-04
Loss = 2.3180e-03, PNorm = 46.5179, GNorm = 1.3725, lr_0 = 7.2281e-04
Validation rmse = 1.336493
Epoch 6
Loss = 1.5467e-03, PNorm = 46.5575, GNorm = 2.3006, lr_0 = 6.8920e-04
Loss = 2.0241e-03, PNorm = 46.5870, GNorm = 0.6387, lr_0 = 6.6001e-04
Validation rmse = 1.290749
Epoch 7
Loss = 1.8947e-03, PNorm = 46.6152, GNorm = 2.5497, lr_0 = 6.3205e-04
Loss = 1.3521e-03, PNorm = 46.6423, GNorm = 0.6558, lr_0 = 6.0528e-04
Validation rmse = 1.252697
Epoch 8
Loss = 1.8870e-03, PNorm = 46.6694, GNorm = 1.5400, lr_0 = 5.7714e-04
Loss = 1.8125e-03, PNorm = 46.6958, GNorm = 1.2870, lr_0 = 5.5269e-04
Validation rmse = 1.210709
Epoch 9
Loss = 1.5111e-03, PNorm = 46.7187, GNorm = 2.3598, lr_0 = 5.2928e-04
Loss = 1.4670e-03, PNorm = 46.7411, GNorm = 0.3808, lr_0 = 5.0686e-04
Validation rmse = 1.281413
Epoch 10
Loss = 1.4066e-03, PNorm = 46.7576, GNorm = 0.7935, lr_0 = 4.8539e-04
Loss = 1.4103e-03, PNorm = 46.7749, GNorm = 1.2443, lr_0 = 4.6483e-04
Validation rmse = 1.197973
Epoch 11
Loss = 1.8720e-03, PNorm = 46.7930, GNorm = 0.6440, lr_0 = 4.4322e-04
Loss = 1.6526e-03, PNorm = 46.8149, GNorm = 1.8689, lr_0 = 4.2444e-04
Validation rmse = 1.216243
Epoch 12
Loss = 1.3246e-03, PNorm = 46.8339, GNorm = 0.7180, lr_0 = 4.0646e-04
Loss = 1.3290e-03, PNorm = 46.8487, GNorm = 0.6845, lr_0 = 3.8925e-04
Validation rmse = 1.202502
Epoch 13
Loss = 1.7519e-03, PNorm = 46.8637, GNorm = 1.2835, lr_0 = 3.7276e-04
Loss = 1.4367e-03, PNorm = 46.8753, GNorm = 0.9986, lr_0 = 3.5697e-04
Validation rmse = 1.289488
Epoch 14
Loss = 1.6320e-03, PNorm = 46.8916, GNorm = 1.0951, lr_0 = 3.4037e-04
Loss = 1.1485e-03, PNorm = 46.9066, GNorm = 1.4627, lr_0 = 3.2596e-04
Validation rmse = 1.256137
Epoch 15
Loss = 1.2512e-03, PNorm = 46.9191, GNorm = 0.9071, lr_0 = 3.1215e-04
Loss = 1.1901e-03, PNorm = 46.9302, GNorm = 1.3003, lr_0 = 2.9893e-04
Validation rmse = 1.244691
Epoch 16
Loss = 1.0419e-03, PNorm = 46.9411, GNorm = 0.7175, lr_0 = 2.8503e-04
Loss = 1.1878e-03, PNorm = 46.9517, GNorm = 1.2368, lr_0 = 2.7295e-04
Validation rmse = 1.190193
Epoch 17
Loss = 1.2173e-03, PNorm = 46.9642, GNorm = 2.3960, lr_0 = 2.6139e-04
Loss = 1.2352e-03, PNorm = 46.9740, GNorm = 1.7295, lr_0 = 2.5032e-04
Validation rmse = 1.337111
Epoch 18
Loss = 1.0837e-03, PNorm = 46.9842, GNorm = 0.3550, lr_0 = 2.3972e-04
Loss = 1.0901e-03, PNorm = 46.9940, GNorm = 0.7949, lr_0 = 2.2956e-04
Validation rmse = 1.267931
Epoch 19
Loss = 1.3201e-03, PNorm = 47.0041, GNorm = 1.6691, lr_0 = 2.1889e-04
Loss = 9.8952e-04, PNorm = 47.0147, GNorm = 0.6161, lr_0 = 2.0962e-04
Validation rmse = 1.151586
Epoch 20
Loss = 9.6188e-04, PNorm = 47.0194, GNorm = 0.7331, lr_0 = 2.0074e-04
Loss = 1.0328e-03, PNorm = 47.0288, GNorm = 1.1682, lr_0 = 1.9224e-04
Validation rmse = 1.202472
Epoch 21
Loss = 1.0482e-03, PNorm = 47.0363, GNorm = 0.9792, lr_0 = 1.8409e-04
Loss = 1.0944e-03, PNorm = 47.0446, GNorm = 0.4507, lr_0 = 1.7630e-04
Validation rmse = 1.329811
Epoch 22
Loss = 1.1688e-03, PNorm = 47.0533, GNorm = 0.6211, lr_0 = 1.6810e-04
Loss = 8.6764e-04, PNorm = 47.0604, GNorm = 1.2532, lr_0 = 1.6098e-04
Validation rmse = 1.205709
Epoch 23
Loss = 7.1981e-04, PNorm = 47.0664, GNorm = 1.3983, lr_0 = 1.5416e-04
Loss = 1.0521e-03, PNorm = 47.0726, GNorm = 0.8120, lr_0 = 1.4763e-04
Loss = 2.7953e-03, PNorm = 47.0732, GNorm = 2.0639, lr_0 = 1.4699e-04
Validation rmse = 1.175520
Epoch 24
Loss = 7.8167e-04, PNorm = 47.0799, GNorm = 1.7736, lr_0 = 1.4077e-04
Loss = 1.0926e-03, PNorm = 47.0848, GNorm = 0.6865, lr_0 = 1.3480e-04
Validation rmse = 1.208772
Epoch 25
Loss = 1.0249e-03, PNorm = 47.0913, GNorm = 0.3387, lr_0 = 1.2909e-04
Loss = 7.7550e-04, PNorm = 47.0962, GNorm = 1.0730, lr_0 = 1.2362e-04
Validation rmse = 1.201228
Epoch 26
Loss = 9.0480e-04, PNorm = 47.1014, GNorm = 0.5818, lr_0 = 1.1839e-04
Validation rmse = 1.195167
Epoch 27
Loss = 4.8177e-04, PNorm = 47.1066, GNorm = 0.4599, lr_0 = 1.1288e-04
Loss = 8.4047e-04, PNorm = 47.1114, GNorm = 0.9898, lr_0 = 1.0810e-04
Validation rmse = 1.216403
Epoch 28
Loss = 8.0896e-04, PNorm = 47.1160, GNorm = 0.6655, lr_0 = 1.0352e-04
Loss = 7.5195e-04, PNorm = 47.1208, GNorm = 0.7837, lr_0 = 1.0000e-04
Validation rmse = 1.171388
Epoch 29
Loss = 8.1156e-04, PNorm = 47.1265, GNorm = 0.9939, lr_0 = 1.0000e-04
Loss = 9.2960e-04, PNorm = 47.1301, GNorm = 0.8952, lr_0 = 1.0000e-04
Validation rmse = 1.168199
Model 0 best validation rmse = 1.151586 on epoch 19
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.084966
Ensemble test rmse = 1.084966
Fold 3
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 900,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 900,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.05_ffn_num_layers_1_hidden_size_900/fold_3',
 'save_smiles_splits': True,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total scaffolds = 195 | train scaffolds = 80 | val scaffolds = 54 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=900, bias=False)
      (W_h): Linear(in_features=900, out_features=900, bias=False)
      (W_o): Linear(in_features=1033, out_features=900, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=904, out_features=1, bias=True)
  )
)
Number of parameters = 1,873,805
Moving model to cuda
Epoch 0
Loss = 1.8375e-02, PNorm = 46.0507, GNorm = 22.8442, lr_0 = 3.6053e-04
Validation rmse = 1.627645
Epoch 1
Loss = 7.6933e-03, PNorm = 46.0910, GNorm = 4.6013, lr_0 = 6.2105e-04
Loss = 7.3345e-03, PNorm = 46.1544, GNorm = 6.2166, lr_0 = 8.5789e-04
Validation rmse = 1.538393
Epoch 2
Loss = 6.5827e-03, PNorm = 46.2127, GNorm = 4.9064, lr_0 = 9.8284e-04
Loss = 4.7566e-03, PNorm = 46.2734, GNorm = 2.1032, lr_0 = 9.4120e-04
Validation rmse = 1.304865
Epoch 3
Loss = 3.7730e-03, PNorm = 46.3247, GNorm = 2.1402, lr_0 = 8.9744e-04
Loss = 4.1018e-03, PNorm = 46.3661, GNorm = 2.2929, lr_0 = 8.5943e-04
Validation rmse = 1.498421
Epoch 4
Loss = 2.3830e-03, PNorm = 46.4031, GNorm = 1.5744, lr_0 = 8.2303e-04
Loss = 3.4409e-03, PNorm = 46.4423, GNorm = 3.1535, lr_0 = 7.8816e-04
Validation rmse = 1.246992
Epoch 5
Loss = 2.3860e-03, PNorm = 46.4825, GNorm = 1.3247, lr_0 = 7.5478e-04
Loss = 2.1179e-03, PNorm = 46.5147, GNorm = 0.9093, lr_0 = 7.2281e-04
Validation rmse = 1.244773
Epoch 6
Loss = 2.0358e-03, PNorm = 46.5467, GNorm = 0.7369, lr_0 = 6.8920e-04
Loss = 1.9620e-03, PNorm = 46.5745, GNorm = 2.2595, lr_0 = 6.6001e-04
Validation rmse = 1.176336
Epoch 7
Loss = 1.6387e-03, PNorm = 46.6005, GNorm = 1.6740, lr_0 = 6.3205e-04
Loss = 1.5571e-03, PNorm = 46.6259, GNorm = 1.8227, lr_0 = 6.0528e-04
Validation rmse = 1.128953
Epoch 8
Loss = 1.6324e-03, PNorm = 46.6574, GNorm = 0.7731, lr_0 = 5.7714e-04
Loss = 1.4701e-03, PNorm = 46.6816, GNorm = 1.5339, lr_0 = 5.5269e-04
Validation rmse = 1.407236
Epoch 9
Loss = 1.6029e-03, PNorm = 46.7032, GNorm = 1.5243, lr_0 = 5.2928e-04
Loss = 1.4476e-03, PNorm = 46.7255, GNorm = 0.9546, lr_0 = 5.0686e-04
Validation rmse = 1.109694
Epoch 10
Loss = 1.4159e-03, PNorm = 46.7460, GNorm = 1.4663, lr_0 = 4.8539e-04
Loss = 1.2701e-03, PNorm = 46.7661, GNorm = 0.9415, lr_0 = 4.6483e-04
Validation rmse = 1.200069
Epoch 11
Loss = 1.1975e-03, PNorm = 46.7873, GNorm = 1.7656, lr_0 = 4.4322e-04
Loss = 1.4805e-03, PNorm = 46.8044, GNorm = 0.6853, lr_0 = 4.2444e-04
Validation rmse = 1.142762
Epoch 12
Loss = 1.2168e-03, PNorm = 46.8229, GNorm = 2.5655, lr_0 = 4.0646e-04
Loss = 1.0660e-03, PNorm = 46.8408, GNorm = 0.9841, lr_0 = 3.8925e-04
Validation rmse = 1.126878
Epoch 13
Loss = 1.0793e-03, PNorm = 46.8542, GNorm = 1.1548, lr_0 = 3.7276e-04
Loss = 1.0816e-03, PNorm = 46.8689, GNorm = 0.7200, lr_0 = 3.5697e-04
Validation rmse = 1.164345
Epoch 14
Loss = 1.0912e-03, PNorm = 46.8839, GNorm = 3.0027, lr_0 = 3.4037e-04
Loss = 1.0602e-03, PNorm = 46.8983, GNorm = 0.4848, lr_0 = 3.2596e-04
Validation rmse = 1.241765
Epoch 15
Loss = 1.0790e-03, PNorm = 46.9122, GNorm = 1.3337, lr_0 = 3.1215e-04
Loss = 9.7999e-04, PNorm = 46.9254, GNorm = 0.4868, lr_0 = 2.9893e-04
Validation rmse = 1.114801
Epoch 16
Loss = 1.0163e-03, PNorm = 46.9412, GNorm = 1.4063, lr_0 = 2.8503e-04
Loss = 1.0631e-03, PNorm = 46.9553, GNorm = 1.4230, lr_0 = 2.7295e-04
Validation rmse = 1.128909
Epoch 17
Loss = 7.9765e-04, PNorm = 46.9682, GNorm = 0.6442, lr_0 = 2.6139e-04
Loss = 9.1639e-04, PNorm = 46.9801, GNorm = 0.5858, lr_0 = 2.5032e-04
Validation rmse = 1.231687
Epoch 18
Loss = 9.6015e-04, PNorm = 46.9910, GNorm = 2.0700, lr_0 = 2.3972e-04
Loss = 8.8934e-04, PNorm = 47.0014, GNorm = 1.8296, lr_0 = 2.2956e-04
Validation rmse = 1.176322
Epoch 19
Loss = 8.9746e-04, PNorm = 47.0127, GNorm = 0.8309, lr_0 = 2.1889e-04
Loss = 8.5422e-04, PNorm = 47.0227, GNorm = 0.6204, lr_0 = 2.0962e-04
Validation rmse = 1.126866
Epoch 20
Loss = 8.1313e-04, PNorm = 47.0291, GNorm = 0.9978, lr_0 = 2.0074e-04
Loss = 8.6190e-04, PNorm = 47.0378, GNorm = 0.8847, lr_0 = 1.9224e-04
Validation rmse = 1.176449
Epoch 21
Loss = 7.4488e-04, PNorm = 47.0461, GNorm = 0.3930, lr_0 = 1.8409e-04
Loss = 8.2102e-04, PNorm = 47.0541, GNorm = 1.5257, lr_0 = 1.7630e-04
Validation rmse = 1.145129
Epoch 22
Loss = 8.6050e-04, PNorm = 47.0633, GNorm = 0.8063, lr_0 = 1.6810e-04
Loss = 7.3255e-04, PNorm = 47.0703, GNorm = 0.2541, lr_0 = 1.6098e-04
Validation rmse = 1.166133
Epoch 23
Loss = 7.3042e-04, PNorm = 47.0764, GNorm = 0.5131, lr_0 = 1.5416e-04
Loss = 7.1811e-04, PNorm = 47.0830, GNorm = 0.5620, lr_0 = 1.4763e-04
Loss = 7.8899e-04, PNorm = 47.0837, GNorm = 0.4466, lr_0 = 1.4699e-04
Validation rmse = 1.130915
Epoch 24
Loss = 7.0651e-04, PNorm = 47.0897, GNorm = 0.6485, lr_0 = 1.4077e-04
Loss = 7.3322e-04, PNorm = 47.0969, GNorm = 0.5491, lr_0 = 1.3480e-04
Validation rmse = 1.179027
Epoch 25
Loss = 7.3015e-04, PNorm = 47.1017, GNorm = 0.4714, lr_0 = 1.2909e-04
Loss = 7.4797e-04, PNorm = 47.1073, GNorm = 1.2728, lr_0 = 1.2362e-04
Validation rmse = 1.141398
Epoch 26
Loss = 7.2610e-04, PNorm = 47.1117, GNorm = 0.7536, lr_0 = 1.1839e-04
Validation rmse = 1.196328
Epoch 27
Loss = 1.1741e-03, PNorm = 47.1179, GNorm = 0.4594, lr_0 = 1.1288e-04
Loss = 6.7359e-04, PNorm = 47.1238, GNorm = 0.4673, lr_0 = 1.0810e-04
Validation rmse = 1.154413
Epoch 28
Loss = 6.0293e-04, PNorm = 47.1271, GNorm = 0.6462, lr_0 = 1.0352e-04
Loss = 6.6575e-04, PNorm = 47.1313, GNorm = 0.4574, lr_0 = 1.0000e-04
Validation rmse = 1.147540
Epoch 29
Loss = 6.4299e-04, PNorm = 47.1355, GNorm = 0.3102, lr_0 = 1.0000e-04
Loss = 6.7586e-04, PNorm = 47.1404, GNorm = 1.1315, lr_0 = 1.0000e-04
Validation rmse = 1.152833
Model 0 best validation rmse = 1.109694 on epoch 9
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.149219
Ensemble test rmse = 1.149219
Fold 4
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 900,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 900,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.05_ffn_num_layers_1_hidden_size_900/fold_4',
 'save_smiles_splits': True,
 'seed': 4,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 4
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 49 | test scaffolds = 62
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=900, bias=False)
      (W_h): Linear(in_features=900, out_features=900, bias=False)
      (W_o): Linear(in_features=1033, out_features=900, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=904, out_features=1, bias=True)
  )
)
Number of parameters = 1,873,805
Moving model to cuda
Epoch 0
Loss = 1.8445e-02, PNorm = 46.0500, GNorm = 5.4154, lr_0 = 3.6053e-04
Validation rmse = 1.389579
Epoch 1
Loss = 8.8558e-03, PNorm = 46.0973, GNorm = 2.0268, lr_0 = 6.2105e-04
Loss = 6.1440e-03, PNorm = 46.1549, GNorm = 1.2537, lr_0 = 8.5789e-04
Validation rmse = 1.595045
Epoch 2
Loss = 5.5989e-03, PNorm = 46.2195, GNorm = 6.3486, lr_0 = 9.8284e-04
Loss = 5.7870e-03, PNorm = 46.2720, GNorm = 3.4814, lr_0 = 9.4120e-04
Validation rmse = 1.390981
Epoch 3
Loss = 3.7367e-03, PNorm = 46.3295, GNorm = 2.8055, lr_0 = 8.9744e-04
Loss = 3.2784e-03, PNorm = 46.3661, GNorm = 2.2006, lr_0 = 8.5943e-04
Validation rmse = 1.284714
Epoch 4
Loss = 3.6705e-03, PNorm = 46.4037, GNorm = 3.9065, lr_0 = 8.2303e-04
Loss = 2.5112e-03, PNorm = 46.4401, GNorm = 2.1195, lr_0 = 7.8816e-04
Validation rmse = 1.446647
Epoch 5
Loss = 2.6580e-03, PNorm = 46.4703, GNorm = 2.8305, lr_0 = 7.5478e-04
Loss = 2.3916e-03, PNorm = 46.5008, GNorm = 3.5106, lr_0 = 7.2281e-04
Validation rmse = 1.083094
Epoch 6
Loss = 1.3213e-03, PNorm = 46.5359, GNorm = 1.0584, lr_0 = 6.8920e-04
Loss = 1.8780e-03, PNorm = 46.5635, GNorm = 2.1488, lr_0 = 6.6001e-04
Validation rmse = 1.018744
Epoch 7
Loss = 1.2266e-03, PNorm = 46.5884, GNorm = 2.1431, lr_0 = 6.3205e-04
Loss = 2.2713e-03, PNorm = 46.6151, GNorm = 0.6915, lr_0 = 6.0528e-04
Validation rmse = 1.191311
Epoch 8
Loss = 1.5645e-03, PNorm = 46.6394, GNorm = 0.8222, lr_0 = 5.7714e-04
Loss = 1.6847e-03, PNorm = 46.6585, GNorm = 1.4263, lr_0 = 5.5269e-04
Validation rmse = 1.072176
Epoch 9
Loss = 1.1279e-03, PNorm = 46.6808, GNorm = 0.6212, lr_0 = 5.2928e-04
Loss = 1.6708e-03, PNorm = 46.6974, GNorm = 0.8761, lr_0 = 5.0686e-04
Validation rmse = 1.007474
Epoch 10
Loss = 1.6018e-03, PNorm = 46.7149, GNorm = 1.7766, lr_0 = 4.8539e-04
Loss = 1.6079e-03, PNorm = 46.7320, GNorm = 1.2350, lr_0 = 4.6483e-04
Validation rmse = 1.378394
Epoch 11
Loss = 1.5101e-03, PNorm = 46.7485, GNorm = 0.9216, lr_0 = 4.4322e-04
Loss = 1.2273e-03, PNorm = 46.7620, GNorm = 0.6102, lr_0 = 4.2444e-04
Validation rmse = 1.080651
Epoch 12
Loss = 9.3946e-04, PNorm = 46.7737, GNorm = 0.3618, lr_0 = 4.0646e-04
Loss = 1.2272e-03, PNorm = 46.7873, GNorm = 0.5732, lr_0 = 3.8925e-04
Validation rmse = 1.061995
Epoch 13
Loss = 1.0402e-03, PNorm = 46.8006, GNorm = 0.9578, lr_0 = 3.7276e-04
Loss = 1.4037e-03, PNorm = 46.8149, GNorm = 0.9942, lr_0 = 3.5697e-04
Validation rmse = 0.991165
Epoch 14
Loss = 1.0476e-03, PNorm = 46.8267, GNorm = 1.4179, lr_0 = 3.4037e-04
Loss = 1.3334e-03, PNorm = 46.8374, GNorm = 2.3443, lr_0 = 3.2596e-04
Validation rmse = 0.980406
Epoch 15
Loss = 8.9868e-04, PNorm = 46.8486, GNorm = 0.4542, lr_0 = 3.1215e-04
Loss = 1.3172e-03, PNorm = 46.8593, GNorm = 1.2083, lr_0 = 2.9893e-04
Validation rmse = 0.971556
Epoch 16
Loss = 1.0437e-03, PNorm = 46.8715, GNorm = 1.8018, lr_0 = 2.8503e-04
Loss = 1.3409e-03, PNorm = 46.8811, GNorm = 0.5216, lr_0 = 2.7295e-04
Validation rmse = 0.942907
Epoch 17
Loss = 9.3603e-04, PNorm = 46.8918, GNorm = 1.0074, lr_0 = 2.6139e-04
Loss = 1.1146e-03, PNorm = 46.9015, GNorm = 0.8424, lr_0 = 2.5032e-04
Validation rmse = 1.051117
Epoch 18
Loss = 1.2050e-03, PNorm = 46.9117, GNorm = 1.5815, lr_0 = 2.3972e-04
Loss = 9.7075e-04, PNorm = 46.9224, GNorm = 0.6457, lr_0 = 2.2956e-04
Validation rmse = 0.998992
Epoch 19
Loss = 9.5342e-04, PNorm = 46.9309, GNorm = 0.5630, lr_0 = 2.1889e-04
Loss = 1.0445e-03, PNorm = 46.9403, GNorm = 0.5326, lr_0 = 2.0962e-04
Validation rmse = 0.993711
Epoch 20
Loss = 1.0082e-03, PNorm = 46.9484, GNorm = 0.4652, lr_0 = 2.0074e-04
Loss = 1.0159e-03, PNorm = 46.9566, GNorm = 0.7973, lr_0 = 1.9224e-04
Validation rmse = 1.148780
Epoch 21
Loss = 8.6314e-04, PNorm = 46.9633, GNorm = 1.1862, lr_0 = 1.8409e-04
Loss = 1.1067e-03, PNorm = 46.9710, GNorm = 1.5310, lr_0 = 1.7630e-04
Validation rmse = 0.995973
Epoch 22
Loss = 8.1162e-04, PNorm = 46.9790, GNorm = 1.1387, lr_0 = 1.6810e-04
Loss = 1.1232e-03, PNorm = 46.9866, GNorm = 1.2446, lr_0 = 1.6098e-04
Validation rmse = 1.013012
Epoch 23
Loss = 9.9476e-04, PNorm = 46.9921, GNorm = 1.5219, lr_0 = 1.5416e-04
Loss = 8.5947e-04, PNorm = 46.9989, GNorm = 0.8359, lr_0 = 1.4763e-04
Loss = 1.3458e-03, PNorm = 46.9995, GNorm = 0.8891, lr_0 = 1.4699e-04
Validation rmse = 0.931516
Epoch 24
Loss = 8.3483e-04, PNorm = 47.0043, GNorm = 0.4293, lr_0 = 1.4077e-04
Loss = 9.9422e-04, PNorm = 47.0101, GNorm = 0.8549, lr_0 = 1.3480e-04
Validation rmse = 0.997486
Epoch 25
Loss = 7.7060e-04, PNorm = 47.0149, GNorm = 1.5553, lr_0 = 1.2909e-04
Loss = 1.0491e-03, PNorm = 47.0197, GNorm = 1.3762, lr_0 = 1.2362e-04
Validation rmse = 0.941954
Epoch 26
Loss = 8.0122e-04, PNorm = 47.0255, GNorm = 0.4528, lr_0 = 1.1839e-04
Validation rmse = 0.949664
Epoch 27
Loss = 6.2306e-04, PNorm = 47.0310, GNorm = 0.6465, lr_0 = 1.1288e-04
Loss = 7.4641e-04, PNorm = 47.0344, GNorm = 1.1690, lr_0 = 1.0810e-04
Validation rmse = 0.926837
Epoch 28
Loss = 5.7059e-04, PNorm = 47.0399, GNorm = 1.4708, lr_0 = 1.0352e-04
Loss = 8.3986e-04, PNorm = 47.0440, GNorm = 0.8356, lr_0 = 1.0000e-04
Validation rmse = 0.996426
Epoch 29
Loss = 6.1674e-04, PNorm = 47.0481, GNorm = 0.9990, lr_0 = 1.0000e-04
Loss = 7.9437e-04, PNorm = 47.0526, GNorm = 0.6032, lr_0 = 1.0000e-04
Validation rmse = 0.922839
Model 0 best validation rmse = 0.922839 on epoch 29
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.163225
Ensemble test rmse = 1.163225
Fold 5
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 900,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 900,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.05_ffn_num_layers_1_hidden_size_900/fold_5',
 'save_smiles_splits': True,
 'seed': 5,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 5
Total scaffolds = 195 | train scaffolds = 94 | val scaffolds = 55 | test scaffolds = 46
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=900, bias=False)
      (W_h): Linear(in_features=900, out_features=900, bias=False)
      (W_o): Linear(in_features=1033, out_features=900, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=904, out_features=1, bias=True)
  )
)
Number of parameters = 1,873,805
Moving model to cuda
Epoch 0
Loss = 1.7863e-02, PNorm = 46.0504, GNorm = 3.9817, lr_0 = 3.6053e-04
Validation rmse = 1.752179
Epoch 1
Loss = 4.5511e-03, PNorm = 46.0993, GNorm = 0.9723, lr_0 = 6.2105e-04
Loss = 5.4139e-03, PNorm = 46.1470, GNorm = 1.9726, lr_0 = 8.5789e-04
Validation rmse = 1.579685
Epoch 2
Loss = 4.1567e-03, PNorm = 46.2095, GNorm = 2.3462, lr_0 = 9.8284e-04
Loss = 4.4699e-03, PNorm = 46.2651, GNorm = 5.1435, lr_0 = 9.4120e-04
Validation rmse = 1.830780
Epoch 3
Loss = 6.2654e-03, PNorm = 46.3163, GNorm = 6.0959, lr_0 = 8.9744e-04
Loss = 3.7901e-03, PNorm = 46.3617, GNorm = 3.4076, lr_0 = 8.5943e-04
Validation rmse = 1.492667
Epoch 4
Loss = 2.5098e-03, PNorm = 46.3990, GNorm = 1.1887, lr_0 = 8.2303e-04
Loss = 2.7818e-03, PNorm = 46.4416, GNorm = 3.0180, lr_0 = 7.8816e-04
Validation rmse = 1.384536
Epoch 5
Loss = 2.7689e-03, PNorm = 46.4779, GNorm = 3.7654, lr_0 = 7.5478e-04
Loss = 2.0806e-03, PNorm = 46.5128, GNorm = 0.7655, lr_0 = 7.2281e-04
Validation rmse = 1.294424
Epoch 6
Loss = 2.4239e-03, PNorm = 46.5465, GNorm = 1.6950, lr_0 = 6.8920e-04
Loss = 2.1235e-03, PNorm = 46.5821, GNorm = 3.6739, lr_0 = 6.6001e-04
Validation rmse = 1.308338
Epoch 7
Loss = 1.8976e-03, PNorm = 46.6088, GNorm = 1.4639, lr_0 = 6.3205e-04
Loss = 1.5274e-03, PNorm = 46.6372, GNorm = 0.9095, lr_0 = 6.0528e-04
Validation rmse = 1.228942
Epoch 8
Loss = 1.8705e-03, PNorm = 46.6599, GNorm = 1.8495, lr_0 = 5.7714e-04
Loss = 2.0150e-03, PNorm = 46.6872, GNorm = 1.9482, lr_0 = 5.5269e-04
Validation rmse = 1.255814
Epoch 9
Loss = 1.8899e-03, PNorm = 46.7095, GNorm = 1.3089, lr_0 = 5.2928e-04
Loss = 1.8209e-03, PNorm = 46.7328, GNorm = 1.0931, lr_0 = 5.0686e-04
Validation rmse = 1.170375
Epoch 10
Loss = 1.4025e-03, PNorm = 46.7548, GNorm = 1.0267, lr_0 = 4.8539e-04
Loss = 1.5079e-03, PNorm = 46.7749, GNorm = 1.4089, lr_0 = 4.6483e-04
Validation rmse = 1.239593
Epoch 11
Loss = 1.1768e-03, PNorm = 46.7941, GNorm = 0.6447, lr_0 = 4.4322e-04
Loss = 1.2255e-03, PNorm = 46.8124, GNorm = 1.4164, lr_0 = 4.2444e-04
Validation rmse = 1.149015
Epoch 12
Loss = 9.4278e-04, PNorm = 46.8272, GNorm = 1.0166, lr_0 = 4.0646e-04
Loss = 1.4785e-03, PNorm = 46.8425, GNorm = 0.6690, lr_0 = 3.8925e-04
Validation rmse = 1.148182
Epoch 13
Loss = 1.0513e-03, PNorm = 46.8554, GNorm = 1.6882, lr_0 = 3.7276e-04
Loss = 1.1068e-03, PNorm = 46.8659, GNorm = 0.6719, lr_0 = 3.5697e-04
Validation rmse = 1.141732
Epoch 14
Loss = 1.2780e-03, PNorm = 46.8821, GNorm = 1.2136, lr_0 = 3.4037e-04
Loss = 1.0602e-03, PNorm = 46.8945, GNorm = 1.3636, lr_0 = 3.2596e-04
Validation rmse = 1.126100
Epoch 15
Loss = 1.2066e-03, PNorm = 46.9078, GNorm = 1.7308, lr_0 = 3.1215e-04
Loss = 1.1829e-03, PNorm = 46.9228, GNorm = 0.7890, lr_0 = 2.9893e-04
Validation rmse = 1.116517
Epoch 16
Loss = 9.9799e-04, PNorm = 46.9354, GNorm = 0.3853, lr_0 = 2.8503e-04
Loss = 1.1278e-03, PNorm = 46.9473, GNorm = 1.4598, lr_0 = 2.7295e-04
Validation rmse = 1.218341
Epoch 17
Loss = 1.0346e-03, PNorm = 46.9579, GNorm = 0.7085, lr_0 = 2.6139e-04
Loss = 9.5735e-04, PNorm = 46.9671, GNorm = 0.3923, lr_0 = 2.5032e-04
Validation rmse = 1.110927
Epoch 18
Loss = 8.9885e-04, PNorm = 46.9774, GNorm = 0.7911, lr_0 = 2.3972e-04
Loss = 9.8690e-04, PNorm = 46.9890, GNorm = 1.1438, lr_0 = 2.2956e-04
Validation rmse = 1.138753
Epoch 19
Loss = 8.7999e-04, PNorm = 46.9992, GNorm = 0.9578, lr_0 = 2.1889e-04
Loss = 1.1119e-03, PNorm = 47.0083, GNorm = 0.4654, lr_0 = 2.0962e-04
Validation rmse = 1.197395
Epoch 20
Loss = 9.5166e-04, PNorm = 47.0182, GNorm = 0.4439, lr_0 = 2.0074e-04
Loss = 1.0379e-03, PNorm = 47.0276, GNorm = 0.9293, lr_0 = 1.9224e-04
Validation rmse = 1.088520
Epoch 21
Loss = 7.7140e-04, PNorm = 47.0364, GNorm = 1.5388, lr_0 = 1.8409e-04
Loss = 1.0040e-03, PNorm = 47.0449, GNorm = 1.2157, lr_0 = 1.7630e-04
Validation rmse = 1.076436
Epoch 22
Loss = 8.1139e-04, PNorm = 47.0533, GNorm = 0.5707, lr_0 = 1.6810e-04
Loss = 9.9616e-04, PNorm = 47.0617, GNorm = 1.2813, lr_0 = 1.6098e-04
Validation rmse = 1.118582
Epoch 23
Loss = 9.1533e-04, PNorm = 47.0691, GNorm = 0.5600, lr_0 = 1.5416e-04
Loss = 7.9157e-04, PNorm = 47.0750, GNorm = 0.7539, lr_0 = 1.4763e-04
Loss = 8.0754e-04, PNorm = 47.0756, GNorm = 0.6431, lr_0 = 1.4699e-04
Validation rmse = 1.127130
Epoch 24
Loss = 9.0219e-04, PNorm = 47.0823, GNorm = 0.8953, lr_0 = 1.4077e-04
Loss = 1.0070e-03, PNorm = 47.0888, GNorm = 0.5833, lr_0 = 1.3480e-04
Validation rmse = 1.195486
Epoch 25
Loss = 8.1272e-04, PNorm = 47.0954, GNorm = 1.3717, lr_0 = 1.2909e-04
Loss = 9.5192e-04, PNorm = 47.1011, GNorm = 1.2823, lr_0 = 1.2362e-04
Validation rmse = 1.113382
Epoch 26
Loss = 7.6155e-04, PNorm = 47.1076, GNorm = 0.6642, lr_0 = 1.1839e-04
Validation rmse = 1.108714
Epoch 27
Loss = 1.1438e-03, PNorm = 47.1143, GNorm = 1.1586, lr_0 = 1.1288e-04
Loss = 7.1901e-04, PNorm = 47.1206, GNorm = 0.7026, lr_0 = 1.0810e-04
Validation rmse = 1.045951
Epoch 28
Loss = 6.8080e-04, PNorm = 47.1248, GNorm = 0.6169, lr_0 = 1.0352e-04
Loss = 8.3857e-04, PNorm = 47.1291, GNorm = 1.1967, lr_0 = 1.0000e-04
Validation rmse = 1.065033
Epoch 29
Loss = 7.6609e-04, PNorm = 47.1338, GNorm = 0.4945, lr_0 = 1.0000e-04
Loss = 8.1627e-04, PNorm = 47.1386, GNorm = 0.3186, lr_0 = 1.0000e-04
Validation rmse = 1.065544
Model 0 best validation rmse = 1.045951 on epoch 27
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.145023
Ensemble test rmse = 1.145023
Fold 6
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 900,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 900,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.05_ffn_num_layers_1_hidden_size_900/fold_6',
 'save_smiles_splits': True,
 'seed': 6,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 6
Total scaffolds = 195 | train scaffolds = 64 | val scaffolds = 68 | test scaffolds = 63
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=900, bias=False)
      (W_h): Linear(in_features=900, out_features=900, bias=False)
      (W_o): Linear(in_features=1033, out_features=900, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=904, out_features=1, bias=True)
  )
)
Number of parameters = 1,873,805
Moving model to cuda
Epoch 0
Loss = 1.8458e-02, PNorm = 46.0509, GNorm = 9.6514, lr_0 = 3.6053e-04
Validation rmse = 1.767470
Epoch 1
Loss = 5.6725e-03, PNorm = 46.0943, GNorm = 1.7231, lr_0 = 6.2105e-04
Loss = 5.8999e-03, PNorm = 46.1487, GNorm = 2.7146, lr_0 = 8.5789e-04
Validation rmse = 1.647113
Epoch 2
Loss = 4.9496e-03, PNorm = 46.2083, GNorm = 2.2920, lr_0 = 9.8284e-04
Loss = 4.9191e-03, PNorm = 46.2624, GNorm = 6.2421, lr_0 = 9.4120e-04
Validation rmse = 1.477019
Epoch 3
Loss = 3.7044e-03, PNorm = 46.3122, GNorm = 1.8999, lr_0 = 8.9744e-04
Loss = 3.0599e-03, PNorm = 46.3556, GNorm = 2.5773, lr_0 = 8.5943e-04
Validation rmse = 1.419802
Epoch 4
Loss = 2.2736e-03, PNorm = 46.3985, GNorm = 0.7572, lr_0 = 8.2303e-04
Loss = 3.1927e-03, PNorm = 46.4467, GNorm = 0.8089, lr_0 = 7.8816e-04
Validation rmse = 1.432721
Epoch 5
Loss = 2.2648e-03, PNorm = 46.4798, GNorm = 1.3072, lr_0 = 7.5478e-04
Loss = 2.5995e-03, PNorm = 46.5114, GNorm = 1.3963, lr_0 = 7.2281e-04
Validation rmse = 1.275787
Epoch 6
Loss = 1.6718e-03, PNorm = 46.5462, GNorm = 2.3072, lr_0 = 6.8920e-04
Loss = 1.9834e-03, PNorm = 46.5784, GNorm = 1.2709, lr_0 = 6.6001e-04
Validation rmse = 1.271414
Epoch 7
Loss = 2.1415e-03, PNorm = 46.6042, GNorm = 2.5091, lr_0 = 6.3205e-04
Loss = 1.5894e-03, PNorm = 46.6281, GNorm = 0.6843, lr_0 = 6.0528e-04
Validation rmse = 1.348424
Epoch 8
Loss = 1.7706e-03, PNorm = 46.6535, GNorm = 2.0838, lr_0 = 5.7714e-04
Loss = 1.8638e-03, PNorm = 46.6790, GNorm = 0.5664, lr_0 = 5.5269e-04
Validation rmse = 1.319714
Epoch 9
Loss = 1.5527e-03, PNorm = 46.7012, GNorm = 3.1174, lr_0 = 5.2928e-04
Loss = 1.3785e-03, PNorm = 46.7227, GNorm = 1.3949, lr_0 = 5.0686e-04
Validation rmse = 1.172877
Epoch 10
Loss = 1.5665e-03, PNorm = 46.7473, GNorm = 1.1123, lr_0 = 4.8539e-04
Loss = 1.2265e-03, PNorm = 46.7666, GNorm = 0.5653, lr_0 = 4.6483e-04
Validation rmse = 1.092522
Epoch 11
Loss = 1.5738e-03, PNorm = 46.7860, GNorm = 0.4709, lr_0 = 4.4322e-04
Loss = 1.1729e-03, PNorm = 46.8016, GNorm = 1.9665, lr_0 = 4.2444e-04
Validation rmse = 1.111697
Epoch 12
Loss = 1.0487e-03, PNorm = 46.8167, GNorm = 0.5337, lr_0 = 4.0646e-04
Loss = 1.2972e-03, PNorm = 46.8310, GNorm = 1.5467, lr_0 = 3.8925e-04
Validation rmse = 1.134301
Epoch 13
Loss = 1.0251e-03, PNorm = 46.8466, GNorm = 0.4304, lr_0 = 3.7276e-04
Loss = 1.1827e-03, PNorm = 46.8641, GNorm = 0.9521, lr_0 = 3.5697e-04
Validation rmse = 1.151368
Epoch 14
Loss = 8.4013e-04, PNorm = 46.8794, GNorm = 1.2168, lr_0 = 3.4037e-04
Loss = 1.1470e-03, PNorm = 46.8939, GNorm = 0.8242, lr_0 = 3.2596e-04
Validation rmse = 1.091327
Epoch 15
Loss = 1.0285e-03, PNorm = 46.9058, GNorm = 0.9352, lr_0 = 3.1215e-04
Loss = 9.7387e-04, PNorm = 46.9181, GNorm = 1.0119, lr_0 = 2.9893e-04
Validation rmse = 1.248300
Epoch 16
Loss = 1.2029e-03, PNorm = 46.9323, GNorm = 1.2823, lr_0 = 2.8503e-04
Loss = 9.4782e-04, PNorm = 46.9430, GNorm = 1.2972, lr_0 = 2.7295e-04
Validation rmse = 1.186950
Epoch 17
Loss = 9.0863e-04, PNorm = 46.9542, GNorm = 0.3317, lr_0 = 2.6139e-04
Loss = 9.5504e-04, PNorm = 46.9626, GNorm = 1.5832, lr_0 = 2.5032e-04
Validation rmse = 1.213120
Epoch 18
Loss = 1.2349e-03, PNorm = 46.9727, GNorm = 1.4183, lr_0 = 2.3972e-04
Loss = 8.3549e-04, PNorm = 46.9815, GNorm = 0.8132, lr_0 = 2.2956e-04
Validation rmse = 1.146216
Epoch 19
Loss = 8.9060e-04, PNorm = 46.9927, GNorm = 0.8922, lr_0 = 2.1889e-04
Loss = 9.2315e-04, PNorm = 47.0026, GNorm = 0.8788, lr_0 = 2.0962e-04
Validation rmse = 1.081778
Epoch 20
Loss = 8.8188e-04, PNorm = 47.0109, GNorm = 0.5504, lr_0 = 2.0074e-04
Loss = 8.0724e-04, PNorm = 47.0191, GNorm = 0.4293, lr_0 = 1.9224e-04
Validation rmse = 1.126891
Epoch 21
Loss = 8.2856e-04, PNorm = 47.0284, GNorm = 1.3238, lr_0 = 1.8409e-04
Loss = 9.1708e-04, PNorm = 47.0373, GNorm = 0.7146, lr_0 = 1.7630e-04
Validation rmse = 1.166495
Epoch 22
Loss = 9.4088e-04, PNorm = 47.0455, GNorm = 0.4828, lr_0 = 1.6810e-04
Loss = 7.6463e-04, PNorm = 47.0525, GNorm = 0.9531, lr_0 = 1.6098e-04
Validation rmse = 1.127919
Epoch 23
Loss = 7.8298e-04, PNorm = 47.0595, GNorm = 0.5159, lr_0 = 1.5416e-04
Loss = 7.6158e-04, PNorm = 47.0657, GNorm = 0.6279, lr_0 = 1.4763e-04
Loss = 1.3872e-03, PNorm = 47.0664, GNorm = 0.8280, lr_0 = 1.4699e-04
Validation rmse = 1.063526
Epoch 24
Loss = 8.1745e-04, PNorm = 47.0723, GNorm = 0.3742, lr_0 = 1.4077e-04
Loss = 8.2956e-04, PNorm = 47.0775, GNorm = 0.4261, lr_0 = 1.3480e-04
Validation rmse = 1.075825
Epoch 25
Loss = 7.1329e-04, PNorm = 47.0826, GNorm = 1.0446, lr_0 = 1.2909e-04
Loss = 8.0381e-04, PNorm = 47.0878, GNorm = 0.9764, lr_0 = 1.2362e-04
Validation rmse = 1.056677
Epoch 26
Loss = 7.1582e-04, PNorm = 47.0924, GNorm = 0.5531, lr_0 = 1.1839e-04
Validation rmse = 1.050920
Epoch 27
Loss = 1.1811e-03, PNorm = 47.0986, GNorm = 1.8484, lr_0 = 1.1288e-04
Loss = 6.7065e-04, PNorm = 47.1033, GNorm = 1.0966, lr_0 = 1.0810e-04
Validation rmse = 1.051509
Epoch 28
Loss = 6.4007e-04, PNorm = 47.1084, GNorm = 1.3582, lr_0 = 1.0352e-04
Loss = 7.1636e-04, PNorm = 47.1123, GNorm = 0.4199, lr_0 = 1.0000e-04
Validation rmse = 1.116809
Epoch 29
Loss = 6.4849e-04, PNorm = 47.1174, GNorm = 1.3845, lr_0 = 1.0000e-04
Loss = 7.5161e-04, PNorm = 47.1219, GNorm = 1.4367, lr_0 = 1.0000e-04
Validation rmse = 1.081535
Model 0 best validation rmse = 1.050920 on epoch 26
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 0.940347
Ensemble test rmse = 0.940347
Fold 7
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 900,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 900,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.05_ffn_num_layers_1_hidden_size_900/fold_7',
 'save_smiles_splits': True,
 'seed': 7,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 7
Total scaffolds = 195 | train scaffolds = 69 | val scaffolds = 65 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=900, bias=False)
      (W_h): Linear(in_features=900, out_features=900, bias=False)
      (W_o): Linear(in_features=1033, out_features=900, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=904, out_features=1, bias=True)
  )
)
Number of parameters = 1,873,805
Moving model to cuda
Epoch 0
Loss = 1.6419e-02, PNorm = 46.0522, GNorm = 10.3696, lr_0 = 3.6053e-04
Validation rmse = 1.693506
Epoch 1
Loss = 9.1960e-03, PNorm = 46.0976, GNorm = 6.9555, lr_0 = 6.2105e-04
Loss = 6.3463e-03, PNorm = 46.1494, GNorm = 5.6242, lr_0 = 8.5789e-04
Validation rmse = 1.834487
Epoch 2
Loss = 4.4283e-03, PNorm = 46.2103, GNorm = 3.7113, lr_0 = 9.8284e-04
Loss = 3.9436e-03, PNorm = 46.2645, GNorm = 2.6118, lr_0 = 9.4120e-04
Validation rmse = 1.693786
Epoch 3
Loss = 3.7468e-03, PNorm = 46.3177, GNorm = 5.8984, lr_0 = 8.9744e-04
Loss = 4.5371e-03, PNorm = 46.3717, GNorm = 2.5041, lr_0 = 8.5943e-04
Validation rmse = 1.654777
Epoch 4
Loss = 2.5754e-03, PNorm = 46.4101, GNorm = 1.3448, lr_0 = 8.2303e-04
Loss = 2.7525e-03, PNorm = 46.4491, GNorm = 1.4631, lr_0 = 7.8816e-04
Validation rmse = 1.624450
Epoch 5
Loss = 2.5013e-03, PNorm = 46.4864, GNorm = 2.0673, lr_0 = 7.5478e-04
Loss = 1.9345e-03, PNorm = 46.5178, GNorm = 0.6635, lr_0 = 7.2281e-04
Validation rmse = 1.515199
Epoch 6
Loss = 3.2263e-03, PNorm = 46.5529, GNorm = 5.3414, lr_0 = 6.8920e-04
Loss = 2.4717e-03, PNorm = 46.5840, GNorm = 0.8110, lr_0 = 6.6001e-04
Validation rmse = 1.467659
Epoch 7
Loss = 1.8628e-03, PNorm = 46.6105, GNorm = 4.5604, lr_0 = 6.3205e-04
Loss = 2.4087e-03, PNorm = 46.6353, GNorm = 1.1562, lr_0 = 6.0528e-04
Validation rmse = 1.446239
Epoch 8
Loss = 1.5332e-03, PNorm = 46.6601, GNorm = 1.2854, lr_0 = 5.7714e-04
Loss = 1.6000e-03, PNorm = 46.6799, GNorm = 0.5836, lr_0 = 5.5269e-04
Validation rmse = 1.463188
Epoch 9
Loss = 1.6130e-03, PNorm = 46.6974, GNorm = 1.4412, lr_0 = 5.2928e-04
Loss = 1.5420e-03, PNorm = 46.7146, GNorm = 2.2123, lr_0 = 5.0686e-04
Validation rmse = 1.429468
Epoch 10
Loss = 1.5225e-03, PNorm = 46.7295, GNorm = 1.0755, lr_0 = 4.8539e-04
Loss = 1.4235e-03, PNorm = 46.7464, GNorm = 0.6567, lr_0 = 4.6483e-04
Validation rmse = 1.425357
Epoch 11
Loss = 1.3120e-03, PNorm = 46.7648, GNorm = 0.9280, lr_0 = 4.4322e-04
Loss = 1.2055e-03, PNorm = 46.7781, GNorm = 0.5245, lr_0 = 4.2444e-04
Validation rmse = 1.293197
Epoch 12
Loss = 1.1517e-03, PNorm = 46.7923, GNorm = 0.5988, lr_0 = 4.0646e-04
Loss = 1.1465e-03, PNorm = 46.8060, GNorm = 1.4588, lr_0 = 3.8925e-04
Validation rmse = 1.292088
Epoch 13
Loss = 1.2904e-03, PNorm = 46.8187, GNorm = 1.3011, lr_0 = 3.7276e-04
Loss = 1.5150e-03, PNorm = 46.8332, GNorm = 0.8380, lr_0 = 3.5697e-04
Validation rmse = 1.524245
Epoch 14
Loss = 1.3111e-03, PNorm = 46.8489, GNorm = 2.7410, lr_0 = 3.4037e-04
Loss = 1.1846e-03, PNorm = 46.8622, GNorm = 0.6918, lr_0 = 3.2596e-04
Validation rmse = 1.372430
Epoch 15
Loss = 1.1749e-03, PNorm = 46.8747, GNorm = 1.4141, lr_0 = 3.1215e-04
Loss = 1.1487e-03, PNorm = 46.8883, GNorm = 0.5217, lr_0 = 2.9893e-04
Validation rmse = 1.552635
Epoch 16
Loss = 1.1580e-03, PNorm = 46.9033, GNorm = 0.8216, lr_0 = 2.8503e-04
Loss = 9.7926e-04, PNorm = 46.9114, GNorm = 0.4382, lr_0 = 2.7295e-04
Validation rmse = 1.419412
Epoch 17
Loss = 9.2597e-04, PNorm = 46.9224, GNorm = 0.4252, lr_0 = 2.6139e-04
Loss = 1.1500e-03, PNorm = 46.9315, GNorm = 1.8134, lr_0 = 2.5032e-04
Validation rmse = 1.329309
Epoch 18
Loss = 8.9466e-04, PNorm = 46.9425, GNorm = 0.7006, lr_0 = 2.3972e-04
Loss = 1.0493e-03, PNorm = 46.9533, GNorm = 0.7543, lr_0 = 2.2956e-04
Validation rmse = 1.347275
Epoch 19
Loss = 9.8987e-04, PNorm = 46.9635, GNorm = 0.5651, lr_0 = 2.1889e-04
Loss = 9.0954e-04, PNorm = 46.9731, GNorm = 0.6276, lr_0 = 2.0962e-04
Validation rmse = 1.303145
Epoch 20
Loss = 1.1239e-03, PNorm = 46.9819, GNorm = 1.3485, lr_0 = 2.0074e-04
Loss = 7.8500e-04, PNorm = 46.9892, GNorm = 1.1911, lr_0 = 1.9224e-04
Validation rmse = 1.345785
Epoch 21
Loss = 9.8239e-04, PNorm = 46.9963, GNorm = 2.0155, lr_0 = 1.8409e-04
Loss = 9.4873e-04, PNorm = 47.0046, GNorm = 1.1876, lr_0 = 1.7630e-04
Validation rmse = 1.386416
Epoch 22
Loss = 8.1597e-04, PNorm = 47.0122, GNorm = 0.9256, lr_0 = 1.6810e-04
Loss = 9.2839e-04, PNorm = 47.0201, GNorm = 0.6138, lr_0 = 1.6098e-04
Validation rmse = 1.357942
Epoch 23
Loss = 8.6201e-04, PNorm = 47.0267, GNorm = 0.3781, lr_0 = 1.5416e-04
Loss = 7.8233e-04, PNorm = 47.0331, GNorm = 0.4071, lr_0 = 1.4763e-04
Loss = 1.5424e-03, PNorm = 47.0337, GNorm = 1.9591, lr_0 = 1.4699e-04
Validation rmse = 1.267030
Epoch 24
Loss = 8.1457e-04, PNorm = 47.0390, GNorm = 1.8175, lr_0 = 1.4077e-04
Loss = 9.7093e-04, PNorm = 47.0456, GNorm = 0.6197, lr_0 = 1.3480e-04
Validation rmse = 1.282734
Epoch 25
Loss = 8.7447e-04, PNorm = 47.0513, GNorm = 0.4065, lr_0 = 1.2909e-04
Loss = 1.0218e-03, PNorm = 47.0582, GNorm = 0.9072, lr_0 = 1.2362e-04
Validation rmse = 1.322582
Epoch 26
Loss = 8.0207e-04, PNorm = 47.0621, GNorm = 0.4617, lr_0 = 1.1839e-04
Validation rmse = 1.346694
Epoch 27
Loss = 6.1008e-04, PNorm = 47.0681, GNorm = 1.1621, lr_0 = 1.1288e-04
Loss = 7.0969e-04, PNorm = 47.0730, GNorm = 1.6338, lr_0 = 1.0810e-04
Validation rmse = 1.346187
Epoch 28
Loss = 8.6262e-04, PNorm = 47.0777, GNorm = 0.6650, lr_0 = 1.0352e-04
Loss = 7.1534e-04, PNorm = 47.0826, GNorm = 0.6647, lr_0 = 1.0000e-04
Validation rmse = 1.333709
Epoch 29
Loss = 1.0768e-03, PNorm = 47.0876, GNorm = 1.1361, lr_0 = 1.0000e-04
Loss = 6.3529e-04, PNorm = 47.0916, GNorm = 0.3337, lr_0 = 1.0000e-04
Validation rmse = 1.313617
Model 0 best validation rmse = 1.267030 on epoch 23
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.069090
Ensemble test rmse = 1.069090
Fold 8
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 900,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 900,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.05_ffn_num_layers_1_hidden_size_900/fold_8',
 'save_smiles_splits': True,
 'seed': 8,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 8
Total scaffolds = 195 | train scaffolds = 75 | val scaffolds = 42 | test scaffolds = 78
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=900, bias=False)
      (W_h): Linear(in_features=900, out_features=900, bias=False)
      (W_o): Linear(in_features=1033, out_features=900, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=904, out_features=1, bias=True)
  )
)
Number of parameters = 1,873,805
Moving model to cuda
Epoch 0
Loss = 1.4848e-02, PNorm = 46.0517, GNorm = 6.7853, lr_0 = 3.6053e-04
Validation rmse = 1.806008
Epoch 1
Loss = 6.0621e-03, PNorm = 46.0975, GNorm = 7.5005, lr_0 = 6.2105e-04
Loss = 6.8028e-03, PNorm = 46.1461, GNorm = 1.6198, lr_0 = 8.5789e-04
Validation rmse = 1.538896
Epoch 2
Loss = 4.0136e-03, PNorm = 46.2075, GNorm = 2.8780, lr_0 = 9.8284e-04
Loss = 4.1634e-03, PNorm = 46.2617, GNorm = 4.2916, lr_0 = 9.4120e-04
Validation rmse = 1.483805
Epoch 3
Loss = 3.5107e-03, PNorm = 46.3131, GNorm = 1.4426, lr_0 = 8.9744e-04
Loss = 3.0286e-03, PNorm = 46.3548, GNorm = 7.3139, lr_0 = 8.5943e-04
Validation rmse = 1.575595
Epoch 4
Loss = 3.0775e-03, PNorm = 46.3913, GNorm = 2.3635, lr_0 = 8.2303e-04
Loss = 2.5109e-03, PNorm = 46.4282, GNorm = 1.7790, lr_0 = 7.8816e-04
Validation rmse = 1.260635
Epoch 5
Loss = 1.4646e-03, PNorm = 46.4607, GNorm = 0.9270, lr_0 = 7.5478e-04
Loss = 1.7591e-03, PNorm = 46.4902, GNorm = 0.8980, lr_0 = 7.2281e-04
Validation rmse = 1.227541
Epoch 6
Loss = 1.4138e-03, PNorm = 46.5160, GNorm = 2.3095, lr_0 = 6.8920e-04
Loss = 2.0340e-03, PNorm = 46.5389, GNorm = 3.0554, lr_0 = 6.6001e-04
Validation rmse = 1.287539
Epoch 7
Loss = 1.9363e-03, PNorm = 46.5658, GNorm = 3.4136, lr_0 = 6.3205e-04
Loss = 1.9018e-03, PNorm = 46.5902, GNorm = 1.8476, lr_0 = 6.0528e-04
Validation rmse = 1.256732
Epoch 8
Loss = 2.0651e-03, PNorm = 46.6138, GNorm = 2.6284, lr_0 = 5.7714e-04
Loss = 1.3211e-03, PNorm = 46.6332, GNorm = 2.2663, lr_0 = 5.5269e-04
Validation rmse = 1.219688
Epoch 9
Loss = 1.2047e-03, PNorm = 46.6508, GNorm = 2.0062, lr_0 = 5.2928e-04
Loss = 1.2679e-03, PNorm = 46.6695, GNorm = 0.7121, lr_0 = 5.0686e-04
Validation rmse = 1.149063
Epoch 10
Loss = 1.0302e-03, PNorm = 46.6873, GNorm = 0.7614, lr_0 = 4.8539e-04
Loss = 1.4123e-03, PNorm = 46.7037, GNorm = 0.6993, lr_0 = 4.6483e-04
Validation rmse = 1.125371
Epoch 11
Loss = 1.5102e-03, PNorm = 46.7191, GNorm = 2.7828, lr_0 = 4.4322e-04
Loss = 1.2993e-03, PNorm = 46.7341, GNorm = 0.8464, lr_0 = 4.2444e-04
Validation rmse = 1.151480
Epoch 12
Loss = 1.1242e-03, PNorm = 46.7495, GNorm = 2.4401, lr_0 = 4.0646e-04
Loss = 1.0643e-03, PNorm = 46.7651, GNorm = 0.7686, lr_0 = 3.8925e-04
Validation rmse = 1.145382
Epoch 13
Loss = 1.1016e-03, PNorm = 46.7781, GNorm = 1.2998, lr_0 = 3.7276e-04
Loss = 1.0092e-03, PNorm = 46.7912, GNorm = 0.5346, lr_0 = 3.5697e-04
Validation rmse = 1.074480
Epoch 14
Loss = 9.8179e-04, PNorm = 46.8053, GNorm = 0.8406, lr_0 = 3.4037e-04
Loss = 1.1512e-03, PNorm = 46.8164, GNorm = 2.2746, lr_0 = 3.2596e-04
Validation rmse = 1.076718
Epoch 15
Loss = 1.0619e-03, PNorm = 46.8280, GNorm = 1.9635, lr_0 = 3.1215e-04
Loss = 1.1915e-03, PNorm = 46.8407, GNorm = 0.7059, lr_0 = 2.9893e-04
Validation rmse = 1.117316
Epoch 16
Loss = 9.0559e-04, PNorm = 46.8566, GNorm = 0.7477, lr_0 = 2.8503e-04
Loss = 1.0504e-03, PNorm = 46.8691, GNorm = 0.5740, lr_0 = 2.7295e-04
Validation rmse = 1.080477
Epoch 17
Loss = 9.3039e-04, PNorm = 46.8767, GNorm = 0.3344, lr_0 = 2.6139e-04
Loss = 1.0440e-03, PNorm = 46.8876, GNorm = 0.7511, lr_0 = 2.5032e-04
Validation rmse = 1.091378
Epoch 18
Loss = 9.9978e-04, PNorm = 46.8959, GNorm = 1.0531, lr_0 = 2.3972e-04
Loss = 9.0826e-04, PNorm = 46.9047, GNorm = 0.9347, lr_0 = 2.2956e-04
Validation rmse = 1.168198
Epoch 19
Loss = 9.2604e-04, PNorm = 46.9141, GNorm = 0.6713, lr_0 = 2.1889e-04
Loss = 9.4443e-04, PNorm = 46.9221, GNorm = 0.7454, lr_0 = 2.0962e-04
Validation rmse = 1.100380
Epoch 20
Loss = 8.0382e-04, PNorm = 46.9325, GNorm = 0.9565, lr_0 = 2.0074e-04
Loss = 1.0058e-03, PNorm = 46.9396, GNorm = 0.8538, lr_0 = 1.9224e-04
Validation rmse = 1.058617
Epoch 21
Loss = 7.2545e-04, PNorm = 46.9485, GNorm = 0.9097, lr_0 = 1.8409e-04
Loss = 9.6978e-04, PNorm = 46.9568, GNorm = 0.7855, lr_0 = 1.7630e-04
Validation rmse = 1.126820
Epoch 22
Loss = 9.6028e-04, PNorm = 46.9662, GNorm = 1.4474, lr_0 = 1.6810e-04
Loss = 8.3493e-04, PNorm = 46.9733, GNorm = 0.5890, lr_0 = 1.6098e-04
Validation rmse = 1.082694
Epoch 23
Loss = 8.7386e-04, PNorm = 46.9798, GNorm = 0.6286, lr_0 = 1.5416e-04
Loss = 7.8243e-04, PNorm = 46.9865, GNorm = 1.0530, lr_0 = 1.4763e-04
Loss = 8.3843e-04, PNorm = 46.9871, GNorm = 0.8965, lr_0 = 1.4699e-04
Validation rmse = 1.072322
Epoch 24
Loss = 7.3637e-04, PNorm = 46.9930, GNorm = 0.4326, lr_0 = 1.4077e-04
Loss = 7.6933e-04, PNorm = 46.9996, GNorm = 0.4778, lr_0 = 1.3480e-04
Validation rmse = 1.066682
Epoch 25
Loss = 7.7288e-04, PNorm = 47.0046, GNorm = 0.9407, lr_0 = 1.2909e-04
Loss = 6.8448e-04, PNorm = 47.0098, GNorm = 1.2997, lr_0 = 1.2362e-04
Validation rmse = 1.071030
Epoch 26
Loss = 8.8446e-04, PNorm = 47.0153, GNorm = 1.1354, lr_0 = 1.1839e-04
Validation rmse = 1.041427
Epoch 27
Loss = 1.2742e-03, PNorm = 47.0198, GNorm = 1.3791, lr_0 = 1.1288e-04
Loss = 6.1652e-04, PNorm = 47.0242, GNorm = 1.1946, lr_0 = 1.0810e-04
Validation rmse = 1.080097
Epoch 28
Loss = 6.8429e-04, PNorm = 47.0282, GNorm = 1.2767, lr_0 = 1.0352e-04
Loss = 7.6153e-04, PNorm = 47.0316, GNorm = 0.5289, lr_0 = 1.0000e-04
Validation rmse = 1.076026
Epoch 29
Loss = 5.6525e-04, PNorm = 47.0370, GNorm = 0.7544, lr_0 = 1.0000e-04
Loss = 6.7665e-04, PNorm = 47.0412, GNorm = 0.8341, lr_0 = 1.0000e-04
Validation rmse = 1.082845
Model 0 best validation rmse = 1.041427 on epoch 26
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.120592
Ensemble test rmse = 1.120592
Fold 9
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'device': device(type='cuda'),
 'dropout': 0.05,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 900,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 900,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_5_dropout_0.05_ffn_num_layers_1_hidden_size_900/fold_9',
 'save_smiles_splits': True,
 'seed': 9,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 9
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 58 | test scaffolds = 53
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.05, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=900, bias=False)
      (W_h): Linear(in_features=900, out_features=900, bias=False)
      (W_o): Linear(in_features=1033, out_features=900, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.05, inplace=False)
    (1): Linear(in_features=904, out_features=1, bias=True)
  )
)
Number of parameters = 1,873,805
Moving model to cuda
Epoch 0
Loss = 1.7726e-02, PNorm = 46.0499, GNorm = 9.9532, lr_0 = 3.6053e-04
Validation rmse = 1.651478
Epoch 1
Loss = 5.1351e-03, PNorm = 46.0975, GNorm = 2.9021, lr_0 = 6.2105e-04
Loss = 6.4275e-03, PNorm = 46.1552, GNorm = 5.3399, lr_0 = 8.5789e-04
Validation rmse = 1.805185
Epoch 2
Loss = 8.4776e-03, PNorm = 46.2173, GNorm = 5.9790, lr_0 = 9.8284e-04
Loss = 7.0427e-03, PNorm = 46.2810, GNorm = 0.8481, lr_0 = 9.4120e-04
Validation rmse = 1.368593
Epoch 3
Loss = 3.9669e-03, PNorm = 46.3400, GNorm = 2.7511, lr_0 = 8.9744e-04
Loss = 3.6736e-03, PNorm = 46.3812, GNorm = 1.3791, lr_0 = 8.5943e-04
Validation rmse = 1.437526
Epoch 4
Loss = 4.2632e-03, PNorm = 46.4161, GNorm = 6.6223, lr_0 = 8.2303e-04
Loss = 2.7895e-03, PNorm = 46.4520, GNorm = 1.5051, lr_0 = 7.8816e-04
Validation rmse = 1.212375
Epoch 5
Loss = 1.7765e-03, PNorm = 46.4863, GNorm = 0.8707, lr_0 = 7.5478e-04
Loss = 2.5446e-03, PNorm = 46.5165, GNorm = 2.0427, lr_0 = 7.2281e-04
Validation rmse = 1.116493
Epoch 6
Loss = 2.6101e-03, PNorm = 46.5506, GNorm = 1.3806, lr_0 = 6.8920e-04
Loss = 2.1780e-03, PNorm = 46.5788, GNorm = 2.3497, lr_0 = 6.6001e-04
Validation rmse = 1.503630
Epoch 7
Loss = 2.6234e-03, PNorm = 46.6020, GNorm = 1.7538, lr_0 = 6.3205e-04
Loss = 2.0778e-03, PNorm = 46.6281, GNorm = 1.4178, lr_0 = 6.0528e-04
Validation rmse = 1.094263
Epoch 8
Loss = 1.6084e-03, PNorm = 46.6526, GNorm = 1.0628, lr_0 = 5.7714e-04
Loss = 1.6503e-03, PNorm = 46.6735, GNorm = 1.3044, lr_0 = 5.5269e-04
Validation rmse = 1.029825
Epoch 9
Loss = 1.7950e-03, PNorm = 46.6959, GNorm = 1.9454, lr_0 = 5.2928e-04
Loss = 1.6397e-03, PNorm = 46.7196, GNorm = 0.8600, lr_0 = 5.0686e-04
Validation rmse = 1.131878
Epoch 10
Loss = 1.4075e-03, PNorm = 46.7353, GNorm = 0.9289, lr_0 = 4.8539e-04
Loss = 1.5184e-03, PNorm = 46.7516, GNorm = 1.1317, lr_0 = 4.6483e-04
Validation rmse = 1.067256
Epoch 11
Loss = 1.5581e-03, PNorm = 46.7736, GNorm = 1.4188, lr_0 = 4.4322e-04
Loss = 1.6439e-03, PNorm = 46.7915, GNorm = 2.0766, lr_0 = 4.2444e-04
Validation rmse = 1.116347
Epoch 12
Loss = 1.3180e-03, PNorm = 46.8076, GNorm = 1.3397, lr_0 = 4.0646e-04
Loss = 1.5398e-03, PNorm = 46.8254, GNorm = 1.2020, lr_0 = 3.8925e-04
Validation rmse = 1.009275
Epoch 13
Loss = 1.1106e-03, PNorm = 46.8383, GNorm = 0.7730, lr_0 = 3.7276e-04
Loss = 1.2773e-03, PNorm = 46.8530, GNorm = 1.0109, lr_0 = 3.5697e-04
Validation rmse = 1.108481
Epoch 14
Loss = 1.3383e-03, PNorm = 46.8728, GNorm = 1.0550, lr_0 = 3.4037e-04
Loss = 1.3804e-03, PNorm = 46.8882, GNorm = 0.8070, lr_0 = 3.2596e-04
Validation rmse = 0.983426
Epoch 15
Loss = 1.0618e-03, PNorm = 46.9006, GNorm = 1.0306, lr_0 = 3.1215e-04
Loss = 1.3145e-03, PNorm = 46.9156, GNorm = 2.5129, lr_0 = 2.9893e-04
Validation rmse = 0.984438
Epoch 16
Loss = 1.2444e-03, PNorm = 46.9319, GNorm = 1.9395, lr_0 = 2.8503e-04
Loss = 1.3361e-03, PNorm = 46.9434, GNorm = 1.0235, lr_0 = 2.7295e-04
Validation rmse = 1.004436
Epoch 17
Loss = 1.2211e-03, PNorm = 46.9547, GNorm = 1.7134, lr_0 = 2.6139e-04
Loss = 1.2739e-03, PNorm = 46.9642, GNorm = 1.1541, lr_0 = 2.5032e-04
Validation rmse = 0.963342
Epoch 18
Loss = 9.6787e-04, PNorm = 46.9753, GNorm = 0.6105, lr_0 = 2.3972e-04
Loss = 1.3046e-03, PNorm = 46.9854, GNorm = 0.6468, lr_0 = 2.2956e-04
Validation rmse = 0.928601
Epoch 19
Loss = 1.1094e-03, PNorm = 46.9943, GNorm = 1.5337, lr_0 = 2.1889e-04
Loss = 1.1731e-03, PNorm = 47.0051, GNorm = 0.4877, lr_0 = 2.0962e-04
Validation rmse = 0.982094
Epoch 20
Loss = 1.2207e-03, PNorm = 47.0149, GNorm = 0.8535, lr_0 = 2.0074e-04
Loss = 1.0170e-03, PNorm = 47.0225, GNorm = 0.9031, lr_0 = 1.9224e-04
Validation rmse = 0.936480
Epoch 21
Loss = 8.4655e-04, PNorm = 47.0292, GNorm = 1.5033, lr_0 = 1.8409e-04
Loss = 1.0269e-03, PNorm = 47.0371, GNorm = 0.5426, lr_0 = 1.7630e-04
Validation rmse = 0.936587
Epoch 22
Loss = 1.0638e-03, PNorm = 47.0445, GNorm = 1.6670, lr_0 = 1.6810e-04
Loss = 9.8276e-04, PNorm = 47.0522, GNorm = 1.5014, lr_0 = 1.6098e-04
Validation rmse = 0.938214
Epoch 23
Loss = 8.2677e-04, PNorm = 47.0588, GNorm = 1.1502, lr_0 = 1.5416e-04
Loss = 9.7809e-04, PNorm = 47.0655, GNorm = 0.6749, lr_0 = 1.4763e-04
Loss = 1.6805e-03, PNorm = 47.0662, GNorm = 0.5182, lr_0 = 1.4699e-04
Validation rmse = 0.924119
Epoch 24
Loss = 8.4956e-04, PNorm = 47.0719, GNorm = 0.5903, lr_0 = 1.4077e-04
Loss = 8.9216e-04, PNorm = 47.0776, GNorm = 0.4762, lr_0 = 1.3480e-04
Validation rmse = 0.931365
Epoch 25
Loss = 9.2442e-04, PNorm = 47.0838, GNorm = 0.5167, lr_0 = 1.2909e-04
Loss = 8.1228e-04, PNorm = 47.0890, GNorm = 0.5150, lr_0 = 1.2362e-04
Validation rmse = 0.960182
Epoch 26
Loss = 8.5787e-04, PNorm = 47.0951, GNorm = 0.4733, lr_0 = 1.1839e-04
Validation rmse = 0.900102
Epoch 27
Loss = 6.7112e-04, PNorm = 47.1012, GNorm = 0.5683, lr_0 = 1.1288e-04
Loss = 9.2907e-04, PNorm = 47.1057, GNorm = 1.9248, lr_0 = 1.0810e-04
Validation rmse = 0.911412
Epoch 28
Loss = 7.4609e-04, PNorm = 47.1106, GNorm = 0.4007, lr_0 = 1.0352e-04
Loss = 8.1746e-04, PNorm = 47.1159, GNorm = 0.5159, lr_0 = 1.0000e-04
Validation rmse = 0.934962
Epoch 29
Loss = 9.5823e-04, PNorm = 47.1211, GNorm = 0.8935, lr_0 = 1.0000e-04
Loss = 7.1655e-04, PNorm = 47.1251, GNorm = 0.6335, lr_0 = 1.0000e-04
Validation rmse = 0.943867
Model 0 best validation rmse = 0.900102 on epoch 26
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Moving model to cuda
Model 0 test rmse = 1.246063
Ensemble test rmse = 1.246063
10-fold cross validation
	Seed 0 ==> test rmse = 0.881515
	Seed 1 ==> test rmse = 1.041063
	Seed 2 ==> test rmse = 1.084966
	Seed 3 ==> test rmse = 1.149219
	Seed 4 ==> test rmse = 1.163225
	Seed 5 ==> test rmse = 1.145023
	Seed 6 ==> test rmse = 0.940347
	Seed 7 ==> test rmse = 1.069090
	Seed 8 ==> test rmse = 1.120592
	Seed 9 ==> test rmse = 1.246063
Overall test rmse = 1.084110 +/- 0.102743
Elapsed time = 0:06:46
Fold 0
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 1300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_3_dropout_0.1_ffn_num_layers_2_hidden_size_1300/fold_0',
 'save_smiles_splits': True,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total scaffolds = 195 | train scaffolds = 91 | val scaffolds = 66 | test scaffolds = 38
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1300, bias=False)
      (W_h): Linear(in_features=1300, out_features=1300, bias=False)
      (W_o): Linear(in_features=1433, out_features=1300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=1304, out_features=1300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1300, out_features=1, bias=True)
  )
)
Number of parameters = 5,443,101
Moving model to cuda
Epoch 0
Loss = 1.4046e-02, PNorm = 65.0506, GNorm = 10.4619, lr_0 = 3.6053e-04
Validation rmse = 1.236774
Epoch 1
Loss = 4.5048e-03, PNorm = 65.1122, GNorm = 2.1521, lr_0 = 6.2105e-04
Loss = 4.9230e-03, PNorm = 65.1948, GNorm = 0.8839, lr_0 = 8.5789e-04
Validation rmse = 0.972923
Epoch 2
Loss = 5.5338e-03, PNorm = 65.2796, GNorm = 1.4107, lr_0 = 9.8284e-04
Loss = 4.0596e-03, PNorm = 65.3566, GNorm = 1.1835, lr_0 = 9.4120e-04
Validation rmse = 0.973139
Epoch 3
Loss = 2.2864e-03, PNorm = 65.4297, GNorm = 0.5171, lr_0 = 8.9744e-04
Loss = 2.5689e-03, PNorm = 65.4806, GNorm = 0.9176, lr_0 = 8.5943e-04
Validation rmse = 1.095040
Epoch 4
Loss = 3.8158e-03, PNorm = 65.5308, GNorm = 1.3607, lr_0 = 8.2303e-04
Loss = 2.1949e-03, PNorm = 65.5755, GNorm = 1.1978, lr_0 = 7.8816e-04
Validation rmse = 1.023948
Epoch 5
Loss = 1.5357e-03, PNorm = 65.6164, GNorm = 0.6308, lr_0 = 7.5478e-04
Loss = 2.2517e-03, PNorm = 65.6527, GNorm = 0.9978, lr_0 = 7.2281e-04
Validation rmse = 0.854865
Epoch 6
Loss = 1.4996e-03, PNorm = 65.6974, GNorm = 0.3380, lr_0 = 6.8920e-04
Loss = 2.1239e-03, PNorm = 65.7325, GNorm = 0.7350, lr_0 = 6.6001e-04
Validation rmse = 1.187153
Epoch 7
Loss = 2.3930e-03, PNorm = 65.7658, GNorm = 2.3232, lr_0 = 6.3205e-04
Loss = 1.8597e-03, PNorm = 65.8029, GNorm = 0.4204, lr_0 = 6.0528e-04
Validation rmse = 1.039405
Epoch 8
Loss = 1.8822e-03, PNorm = 65.8437, GNorm = 0.7927, lr_0 = 5.7714e-04
Loss = 1.8031e-03, PNorm = 65.8742, GNorm = 0.8137, lr_0 = 5.5269e-04
Validation rmse = 0.917912
Epoch 9
Loss = 2.2977e-03, PNorm = 65.9065, GNorm = 3.3503, lr_0 = 5.2928e-04
Loss = 2.6960e-03, PNorm = 65.9461, GNorm = 0.8831, lr_0 = 5.0686e-04
Validation rmse = 0.976314
Epoch 10
Loss = 1.8132e-03, PNorm = 65.9751, GNorm = 1.3627, lr_0 = 4.8539e-04
Loss = 1.6644e-03, PNorm = 66.0051, GNorm = 0.4486, lr_0 = 4.6483e-04
Validation rmse = 1.138326
Epoch 11
Loss = 1.4664e-03, PNorm = 66.0335, GNorm = 0.8726, lr_0 = 4.4322e-04
Loss = 1.3661e-03, PNorm = 66.0526, GNorm = 0.8145, lr_0 = 4.2444e-04
Validation rmse = 1.087327
Epoch 12
Loss = 1.4515e-03, PNorm = 66.0752, GNorm = 0.5922, lr_0 = 4.0646e-04
Loss = 1.6485e-03, PNorm = 66.0937, GNorm = 0.4727, lr_0 = 3.8925e-04
Validation rmse = 0.952974
Epoch 13
Loss = 1.1947e-03, PNorm = 66.1163, GNorm = 0.4119, lr_0 = 3.7276e-04
Loss = 1.3521e-03, PNorm = 66.1389, GNorm = 0.5811, lr_0 = 3.5697e-04
Validation rmse = 0.963031
Epoch 14
Loss = 1.3451e-03, PNorm = 66.1570, GNorm = 0.3200, lr_0 = 3.4037e-04
Loss = 1.3905e-03, PNorm = 66.1771, GNorm = 1.1451, lr_0 = 3.2596e-04
Validation rmse = 0.894910
Epoch 15
Loss = 1.2205e-03, PNorm = 66.1943, GNorm = 0.3566, lr_0 = 3.1215e-04
Loss = 1.3157e-03, PNorm = 66.2129, GNorm = 0.4189, lr_0 = 2.9893e-04
Validation rmse = 0.899728
Epoch 16
Loss = 1.4068e-03, PNorm = 66.2300, GNorm = 0.3439, lr_0 = 2.8503e-04
Loss = 1.1865e-03, PNorm = 66.2450, GNorm = 0.4476, lr_0 = 2.7295e-04
Validation rmse = 0.900439
Epoch 17
Loss = 1.3409e-03, PNorm = 66.2617, GNorm = 0.9539, lr_0 = 2.6139e-04
Loss = 1.3907e-03, PNorm = 66.2764, GNorm = 1.4285, lr_0 = 2.5032e-04
Validation rmse = 0.917647
Epoch 18
Loss = 1.1095e-03, PNorm = 66.2891, GNorm = 0.7615, lr_0 = 2.3972e-04
Loss = 1.0636e-03, PNorm = 66.3038, GNorm = 0.4082, lr_0 = 2.2956e-04
Validation rmse = 0.990948
Epoch 19
Loss = 1.1394e-03, PNorm = 66.3221, GNorm = 0.6661, lr_0 = 2.1889e-04
Loss = 1.1883e-03, PNorm = 66.3368, GNorm = 0.5780, lr_0 = 2.0962e-04
Validation rmse = 1.012919
Epoch 20
Loss = 1.0100e-03, PNorm = 66.3478, GNorm = 0.3538, lr_0 = 2.0074e-04
Loss = 1.1106e-03, PNorm = 66.3589, GNorm = 0.4313, lr_0 = 1.9224e-04
Validation rmse = 1.066350
Epoch 21
Loss = 1.0074e-03, PNorm = 66.3708, GNorm = 0.6475, lr_0 = 1.8409e-04
Loss = 1.0670e-03, PNorm = 66.3811, GNorm = 0.4969, lr_0 = 1.7630e-04
Validation rmse = 0.882460
Epoch 22
Loss = 9.4201e-04, PNorm = 66.3942, GNorm = 0.9897, lr_0 = 1.6810e-04
Loss = 1.2219e-03, PNorm = 66.4023, GNorm = 0.7546, lr_0 = 1.6098e-04
Validation rmse = 0.906798
Epoch 23
Loss = 9.0900e-04, PNorm = 66.4115, GNorm = 0.5932, lr_0 = 1.5416e-04
Loss = 9.0186e-04, PNorm = 66.4205, GNorm = 0.3061, lr_0 = 1.4763e-04
Loss = 9.8680e-04, PNorm = 66.4216, GNorm = 0.3491, lr_0 = 1.4699e-04
Validation rmse = 0.945472
Epoch 24
Loss = 1.0435e-03, PNorm = 66.4294, GNorm = 0.5739, lr_0 = 1.4077e-04
Loss = 1.0771e-03, PNorm = 66.4382, GNorm = 0.9083, lr_0 = 1.3480e-04
Validation rmse = 0.953776
Epoch 25
Loss = 9.5117e-04, PNorm = 66.4466, GNorm = 0.5432, lr_0 = 1.2909e-04
Loss = 1.0973e-03, PNorm = 66.4534, GNorm = 0.8839, lr_0 = 1.2362e-04
Validation rmse = 0.999251
Epoch 26
Loss = 9.3513e-04, PNorm = 66.4603, GNorm = 0.7132, lr_0 = 1.1839e-04
Validation rmse = 0.923207
Epoch 27
Loss = 7.9098e-04, PNorm = 66.4693, GNorm = 1.0888, lr_0 = 1.1288e-04
Loss = 9.1423e-04, PNorm = 66.4756, GNorm = 0.6596, lr_0 = 1.0810e-04
Validation rmse = 0.960452
Epoch 28
Loss = 1.2848e-03, PNorm = 66.4820, GNorm = 0.8484, lr_0 = 1.0352e-04
Loss = 7.4610e-04, PNorm = 66.4879, GNorm = 0.2633, lr_0 = 1.0000e-04
Validation rmse = 0.908698
Epoch 29
Loss = 9.8903e-04, PNorm = 66.4936, GNorm = 1.2807, lr_0 = 1.0000e-04
Loss = 7.9588e-04, PNorm = 66.5003, GNorm = 0.4175, lr_0 = 1.0000e-04
Validation rmse = 0.938802
Model 0 best validation rmse = 0.854865 on epoch 5
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.938806
Ensemble test rmse = 0.938806
Fold 1
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_3_dropout_0.1_ffn_num_layers_2_hidden_size_1300/fold_1',
 'save_smiles_splits': True,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total scaffolds = 195 | train scaffolds = 76 | val scaffolds = 60 | test scaffolds = 59
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1300, bias=False)
      (W_h): Linear(in_features=1300, out_features=1300, bias=False)
      (W_o): Linear(in_features=1433, out_features=1300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=1304, out_features=1300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1300, out_features=1, bias=True)
  )
)
Number of parameters = 5,443,101
Moving model to cuda
Epoch 0
Loss = 1.4086e-02, PNorm = 65.0520, GNorm = 7.4548, lr_0 = 3.6053e-04
Validation rmse = 1.673531
Epoch 1
Loss = 7.6826e-03, PNorm = 65.1091, GNorm = 6.2058, lr_0 = 6.2105e-04
Loss = 5.1416e-03, PNorm = 65.1802, GNorm = 3.2926, lr_0 = 8.5789e-04
Validation rmse = 1.127420
Epoch 2
Loss = 4.8832e-03, PNorm = 65.2525, GNorm = 2.3399, lr_0 = 9.8284e-04
Loss = 3.2655e-03, PNorm = 65.3171, GNorm = 1.8787, lr_0 = 9.4120e-04
Validation rmse = 1.012037
Epoch 3
Loss = 3.0541e-03, PNorm = 65.3719, GNorm = 1.9776, lr_0 = 8.9744e-04
Loss = 2.6882e-03, PNorm = 65.4208, GNorm = 0.6855, lr_0 = 8.5943e-04
Validation rmse = 0.975969
Epoch 4
Loss = 1.7372e-03, PNorm = 65.4619, GNorm = 0.4247, lr_0 = 8.2303e-04
Loss = 2.5632e-03, PNorm = 65.5035, GNorm = 1.1677, lr_0 = 7.8816e-04
Validation rmse = 1.024334
Epoch 5
Loss = 2.1009e-03, PNorm = 65.5473, GNorm = 0.5163, lr_0 = 7.5478e-04
Loss = 2.5961e-03, PNorm = 65.5947, GNorm = 1.4961, lr_0 = 7.2281e-04
Validation rmse = 1.044765
Epoch 6
Loss = 2.4588e-03, PNorm = 65.6411, GNorm = 1.1210, lr_0 = 6.8920e-04
Loss = 2.1457e-03, PNorm = 65.6838, GNorm = 1.1588, lr_0 = 6.6001e-04
Validation rmse = 0.963846
Epoch 7
Loss = 1.7701e-03, PNorm = 65.7156, GNorm = 0.5659, lr_0 = 6.3205e-04
Loss = 1.9743e-03, PNorm = 65.7517, GNorm = 2.1343, lr_0 = 6.0528e-04
Validation rmse = 0.898700
Epoch 8
Loss = 2.1378e-03, PNorm = 65.7853, GNorm = 1.1753, lr_0 = 5.7714e-04
Loss = 1.5041e-03, PNorm = 65.8135, GNorm = 1.2017, lr_0 = 5.5269e-04
Validation rmse = 0.824358
Epoch 9
Loss = 1.5658e-03, PNorm = 65.8426, GNorm = 0.8173, lr_0 = 5.2928e-04
Loss = 1.6220e-03, PNorm = 65.8667, GNorm = 1.0375, lr_0 = 5.0686e-04
Validation rmse = 1.072817
Epoch 10
Loss = 1.7858e-03, PNorm = 65.8936, GNorm = 0.7461, lr_0 = 4.8539e-04
Loss = 1.3352e-03, PNorm = 65.9203, GNorm = 1.2418, lr_0 = 4.6483e-04
Validation rmse = 0.859428
Epoch 11
Loss = 1.6448e-03, PNorm = 65.9471, GNorm = 1.1916, lr_0 = 4.4322e-04
Loss = 1.4723e-03, PNorm = 65.9712, GNorm = 1.0430, lr_0 = 4.2444e-04
Validation rmse = 0.841673
Epoch 12
Loss = 1.3316e-03, PNorm = 65.9970, GNorm = 0.8530, lr_0 = 4.0646e-04
Loss = 1.4464e-03, PNorm = 66.0191, GNorm = 0.4445, lr_0 = 3.8925e-04
Validation rmse = 0.882284
Epoch 13
Loss = 1.7092e-03, PNorm = 66.0404, GNorm = 1.3642, lr_0 = 3.7276e-04
Loss = 1.4065e-03, PNorm = 66.0632, GNorm = 1.3635, lr_0 = 3.5697e-04
Validation rmse = 0.859652
Epoch 14
Loss = 1.2433e-03, PNorm = 66.0896, GNorm = 1.1375, lr_0 = 3.4037e-04
Loss = 1.2910e-03, PNorm = 66.1091, GNorm = 0.7478, lr_0 = 3.2596e-04
Validation rmse = 0.908764
Epoch 15
Loss = 1.1909e-03, PNorm = 66.1253, GNorm = 0.6091, lr_0 = 3.1215e-04
Loss = 1.0166e-03, PNorm = 66.1459, GNorm = 0.3915, lr_0 = 2.9893e-04
Validation rmse = 0.864359
Epoch 16
Loss = 1.0243e-03, PNorm = 66.1617, GNorm = 0.4655, lr_0 = 2.8503e-04
Loss = 1.1200e-03, PNorm = 66.1762, GNorm = 0.7082, lr_0 = 2.7295e-04
Validation rmse = 0.845403
Epoch 17
Loss = 1.0147e-03, PNorm = 66.1929, GNorm = 0.5450, lr_0 = 2.6139e-04
Loss = 1.0927e-03, PNorm = 66.2071, GNorm = 0.8487, lr_0 = 2.5032e-04
Validation rmse = 0.844973
Epoch 18
Loss = 1.0586e-03, PNorm = 66.2211, GNorm = 0.7007, lr_0 = 2.3972e-04
Loss = 1.0763e-03, PNorm = 66.2371, GNorm = 0.9087, lr_0 = 2.2956e-04
Validation rmse = 0.889542
Epoch 19
Loss = 8.7197e-04, PNorm = 66.2512, GNorm = 0.5961, lr_0 = 2.1889e-04
Loss = 1.3636e-03, PNorm = 66.2620, GNorm = 0.6994, lr_0 = 2.0962e-04
Validation rmse = 0.912542
Epoch 20
Loss = 9.6741e-04, PNorm = 66.2762, GNorm = 0.7025, lr_0 = 2.0074e-04
Loss = 9.8516e-04, PNorm = 66.2907, GNorm = 0.4041, lr_0 = 1.9224e-04
Validation rmse = 0.870183
Epoch 21
Loss = 9.7038e-04, PNorm = 66.3045, GNorm = 1.2626, lr_0 = 1.8409e-04
Loss = 1.2218e-03, PNorm = 66.3158, GNorm = 1.4297, lr_0 = 1.7630e-04
Validation rmse = 0.888618
Epoch 22
Loss = 9.6211e-04, PNorm = 66.3282, GNorm = 0.6069, lr_0 = 1.6810e-04
Loss = 9.0344e-04, PNorm = 66.3378, GNorm = 0.6832, lr_0 = 1.6098e-04
Validation rmse = 0.917041
Epoch 23
Loss = 9.4013e-04, PNorm = 66.3475, GNorm = 0.4433, lr_0 = 1.5416e-04
Loss = 9.4020e-04, PNorm = 66.3550, GNorm = 0.5029, lr_0 = 1.4763e-04
Loss = 1.3441e-03, PNorm = 66.3558, GNorm = 0.6098, lr_0 = 1.4699e-04
Validation rmse = 0.887175
Epoch 24
Loss = 9.2356e-04, PNorm = 66.3662, GNorm = 0.4520, lr_0 = 1.4077e-04
Loss = 8.3599e-04, PNorm = 66.3730, GNorm = 0.5557, lr_0 = 1.3480e-04
Validation rmse = 0.888185
Epoch 25
Loss = 7.4615e-04, PNorm = 66.3811, GNorm = 0.3029, lr_0 = 1.2909e-04
Loss = 9.5195e-04, PNorm = 66.3885, GNorm = 1.2127, lr_0 = 1.2362e-04
Validation rmse = 0.902026
Epoch 26
Loss = 9.0651e-04, PNorm = 66.3962, GNorm = 1.0300, lr_0 = 1.1839e-04
Validation rmse = 0.915962
Epoch 27
Loss = 1.1561e-03, PNorm = 66.4024, GNorm = 1.4915, lr_0 = 1.1288e-04
Loss = 9.5632e-04, PNorm = 66.4095, GNorm = 1.0950, lr_0 = 1.0810e-04
Validation rmse = 0.936538
Epoch 28
Loss = 7.0688e-04, PNorm = 66.4152, GNorm = 0.7758, lr_0 = 1.0352e-04
Loss = 8.6289e-04, PNorm = 66.4231, GNorm = 0.8554, lr_0 = 1.0000e-04
Validation rmse = 0.944349
Epoch 29
Loss = 6.9031e-04, PNorm = 66.4303, GNorm = 0.3704, lr_0 = 1.0000e-04
Loss = 8.9187e-04, PNorm = 66.4386, GNorm = 1.0216, lr_0 = 1.0000e-04
Validation rmse = 0.907449
Model 0 best validation rmse = 0.824358 on epoch 8
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.935002
Ensemble test rmse = 0.935002
Fold 2
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_3_dropout_0.1_ffn_num_layers_2_hidden_size_1300/fold_2',
 'save_smiles_splits': True,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total scaffolds = 195 | train scaffolds = 55 | val scaffolds = 64 | test scaffolds = 76
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1300, bias=False)
      (W_h): Linear(in_features=1300, out_features=1300, bias=False)
      (W_o): Linear(in_features=1433, out_features=1300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=1304, out_features=1300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1300, out_features=1, bias=True)
  )
)
Number of parameters = 5,443,101
Moving model to cuda
Epoch 0
Loss = 1.3978e-02, PNorm = 65.0516, GNorm = 3.0481, lr_0 = 3.6053e-04
Validation rmse = 1.305302
Epoch 1
Loss = 6.0158e-03, PNorm = 65.1110, GNorm = 1.5839, lr_0 = 6.2105e-04
Loss = 5.9294e-03, PNorm = 65.1855, GNorm = 4.2438, lr_0 = 8.5789e-04
Validation rmse = 1.279193
Epoch 2
Loss = 5.7676e-03, PNorm = 65.2677, GNorm = 2.4407, lr_0 = 9.8284e-04
Loss = 3.1804e-03, PNorm = 65.3324, GNorm = 0.7840, lr_0 = 9.4120e-04
Validation rmse = 1.121898
Epoch 3
Loss = 2.2433e-03, PNorm = 65.3901, GNorm = 0.4321, lr_0 = 8.9744e-04
Loss = 2.5671e-03, PNorm = 65.4371, GNorm = 1.0295, lr_0 = 8.5943e-04
Validation rmse = 1.072079
Epoch 4
Loss = 1.3139e-03, PNorm = 65.4802, GNorm = 0.4065, lr_0 = 8.2303e-04
Loss = 2.4428e-03, PNorm = 65.5258, GNorm = 0.9566, lr_0 = 7.8816e-04
Validation rmse = 1.080155
Epoch 5
Loss = 1.3652e-03, PNorm = 65.5672, GNorm = 0.6949, lr_0 = 7.5478e-04
Loss = 2.4341e-03, PNorm = 65.6064, GNorm = 0.6130, lr_0 = 7.2281e-04
Validation rmse = 0.950317
Epoch 6
Loss = 1.8722e-03, PNorm = 65.6532, GNorm = 0.6100, lr_0 = 6.8920e-04
Loss = 2.1492e-03, PNorm = 65.6883, GNorm = 0.4591, lr_0 = 6.6001e-04
Validation rmse = 1.024531
Epoch 7
Loss = 2.3211e-03, PNorm = 65.7240, GNorm = 0.4122, lr_0 = 6.3205e-04
Loss = 2.0203e-03, PNorm = 65.7591, GNorm = 0.6619, lr_0 = 6.0528e-04
Validation rmse = 0.920821
Epoch 8
Loss = 2.1329e-03, PNorm = 65.7954, GNorm = 0.3922, lr_0 = 5.7714e-04
Loss = 1.7031e-03, PNorm = 65.8254, GNorm = 0.6339, lr_0 = 5.5269e-04
Validation rmse = 0.933979
Epoch 9
Loss = 1.6303e-03, PNorm = 65.8521, GNorm = 1.0723, lr_0 = 5.2928e-04
Loss = 1.8211e-03, PNorm = 65.8787, GNorm = 1.2246, lr_0 = 5.0686e-04
Validation rmse = 0.916546
Epoch 10
Loss = 1.8847e-03, PNorm = 65.9028, GNorm = 0.7633, lr_0 = 4.8539e-04
Loss = 1.6812e-03, PNorm = 65.9272, GNorm = 0.4510, lr_0 = 4.6483e-04
Validation rmse = 0.905531
Epoch 11
Loss = 2.1861e-03, PNorm = 65.9589, GNorm = 1.9011, lr_0 = 4.4322e-04
Loss = 1.6631e-03, PNorm = 65.9889, GNorm = 0.2869, lr_0 = 4.2444e-04
Validation rmse = 0.921471
Epoch 12
Loss = 1.2518e-03, PNorm = 66.0148, GNorm = 0.3779, lr_0 = 4.0646e-04
Loss = 1.3034e-03, PNorm = 66.0352, GNorm = 0.4568, lr_0 = 3.8925e-04
Validation rmse = 0.907522
Epoch 13
Loss = 1.5446e-03, PNorm = 66.0553, GNorm = 0.8689, lr_0 = 3.7276e-04
Loss = 1.6193e-03, PNorm = 66.0749, GNorm = 0.3197, lr_0 = 3.5697e-04
Validation rmse = 0.945652
Epoch 14
Loss = 1.5289e-03, PNorm = 66.0981, GNorm = 1.4289, lr_0 = 3.4037e-04
Loss = 1.4781e-03, PNorm = 66.1225, GNorm = 0.8752, lr_0 = 3.2596e-04
Validation rmse = 0.965222
Epoch 15
Loss = 1.4887e-03, PNorm = 66.1396, GNorm = 0.9485, lr_0 = 3.1215e-04
Loss = 1.3455e-03, PNorm = 66.1580, GNorm = 0.4613, lr_0 = 2.9893e-04
Validation rmse = 0.991385
Epoch 16
Loss = 1.3148e-03, PNorm = 66.1793, GNorm = 0.3286, lr_0 = 2.8503e-04
Loss = 1.2460e-03, PNorm = 66.1968, GNorm = 0.8144, lr_0 = 2.7295e-04
Validation rmse = 0.891333
Epoch 17
Loss = 1.4340e-03, PNorm = 66.2134, GNorm = 1.3896, lr_0 = 2.6139e-04
Loss = 1.2543e-03, PNorm = 66.2301, GNorm = 1.0535, lr_0 = 2.5032e-04
Validation rmse = 1.054002
Epoch 18
Loss = 1.1899e-03, PNorm = 66.2449, GNorm = 0.2858, lr_0 = 2.3972e-04
Loss = 1.3757e-03, PNorm = 66.2613, GNorm = 0.5941, lr_0 = 2.2956e-04
Validation rmse = 0.971507
Epoch 19
Loss = 1.1427e-03, PNorm = 66.2775, GNorm = 0.9845, lr_0 = 2.1889e-04
Loss = 1.2217e-03, PNorm = 66.2905, GNorm = 1.0577, lr_0 = 2.0962e-04
Validation rmse = 0.933935
Epoch 20
Loss = 9.4806e-04, PNorm = 66.3014, GNorm = 0.7356, lr_0 = 2.0074e-04
Loss = 1.1879e-03, PNorm = 66.3148, GNorm = 0.6000, lr_0 = 1.9224e-04
Validation rmse = 0.971529
Epoch 21
Loss = 1.0979e-03, PNorm = 66.3260, GNorm = 0.7903, lr_0 = 1.8409e-04
Loss = 9.7446e-04, PNorm = 66.3382, GNorm = 0.3835, lr_0 = 1.7630e-04
Validation rmse = 1.021053
Epoch 22
Loss = 1.0810e-03, PNorm = 66.3503, GNorm = 0.4464, lr_0 = 1.6810e-04
Loss = 1.0826e-03, PNorm = 66.3626, GNorm = 0.8626, lr_0 = 1.6098e-04
Validation rmse = 0.934593
Epoch 23
Loss = 8.6464e-04, PNorm = 66.3718, GNorm = 1.2316, lr_0 = 1.5416e-04
Loss = 1.0651e-03, PNorm = 66.3806, GNorm = 0.7296, lr_0 = 1.4763e-04
Loss = 2.4368e-03, PNorm = 66.3810, GNorm = 1.1427, lr_0 = 1.4699e-04
Validation rmse = 0.968261
Epoch 24
Loss = 1.0653e-03, PNorm = 66.3910, GNorm = 1.0030, lr_0 = 1.4077e-04
Loss = 1.1116e-03, PNorm = 66.4013, GNorm = 0.3195, lr_0 = 1.3480e-04
Validation rmse = 0.987952
Epoch 25
Loss = 1.2403e-03, PNorm = 66.4131, GNorm = 0.2896, lr_0 = 1.2909e-04
Loss = 7.7122e-04, PNorm = 66.4219, GNorm = 0.4849, lr_0 = 1.2362e-04
Validation rmse = 0.959727
Epoch 26
Loss = 9.5301e-04, PNorm = 66.4321, GNorm = 0.5783, lr_0 = 1.1839e-04
Validation rmse = 0.976430
Epoch 27
Loss = 6.5147e-04, PNorm = 66.4400, GNorm = 0.3896, lr_0 = 1.1288e-04
Loss = 9.0601e-04, PNorm = 66.4476, GNorm = 0.7182, lr_0 = 1.0810e-04
Validation rmse = 0.947610
Epoch 28
Loss = 1.0613e-03, PNorm = 66.4553, GNorm = 0.5959, lr_0 = 1.0352e-04
Loss = 8.0839e-04, PNorm = 66.4627, GNorm = 0.6796, lr_0 = 1.0000e-04
Validation rmse = 0.956191
Epoch 29
Loss = 8.5284e-04, PNorm = 66.4694, GNorm = 0.4161, lr_0 = 1.0000e-04
Loss = 7.6836e-04, PNorm = 66.4762, GNorm = 0.6868, lr_0 = 1.0000e-04
Validation rmse = 0.974714
Model 0 best validation rmse = 0.891333 on epoch 16
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.000727
Ensemble test rmse = 1.000727
Fold 3
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_3_dropout_0.1_ffn_num_layers_2_hidden_size_1300/fold_3',
 'save_smiles_splits': True,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total scaffolds = 195 | train scaffolds = 80 | val scaffolds = 54 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1300, bias=False)
      (W_h): Linear(in_features=1300, out_features=1300, bias=False)
      (W_o): Linear(in_features=1433, out_features=1300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=1304, out_features=1300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1300, out_features=1, bias=True)
  )
)
Number of parameters = 5,443,101
Moving model to cuda
Epoch 0
Loss = 1.3696e-02, PNorm = 65.0546, GNorm = 18.7609, lr_0 = 3.6053e-04
Validation rmse = 1.289204
Epoch 1
Loss = 4.9046e-03, PNorm = 65.1143, GNorm = 0.8347, lr_0 = 6.2105e-04
Loss = 4.2108e-03, PNorm = 65.1900, GNorm = 1.8764, lr_0 = 8.5789e-04
Validation rmse = 1.131003
Epoch 2
Loss = 3.5140e-03, PNorm = 65.2672, GNorm = 1.3854, lr_0 = 9.8284e-04
Loss = 2.8809e-03, PNorm = 65.3380, GNorm = 2.6000, lr_0 = 9.4120e-04
Validation rmse = 1.025945
Epoch 3
Loss = 2.1425e-03, PNorm = 65.4074, GNorm = 0.4930, lr_0 = 8.9744e-04
Loss = 2.2224e-03, PNorm = 65.4608, GNorm = 0.9406, lr_0 = 8.5943e-04
Validation rmse = 1.058007
Epoch 4
Loss = 2.4356e-03, PNorm = 65.5093, GNorm = 1.5540, lr_0 = 8.2303e-04
Loss = 2.1180e-03, PNorm = 65.5581, GNorm = 0.6828, lr_0 = 7.8816e-04
Validation rmse = 1.335031
Epoch 5
Loss = 1.6650e-03, PNorm = 65.6010, GNorm = 0.6076, lr_0 = 7.5478e-04
Loss = 1.9667e-03, PNorm = 65.6438, GNorm = 1.3473, lr_0 = 7.2281e-04
Validation rmse = 1.038728
Epoch 6
Loss = 1.9552e-03, PNorm = 65.6873, GNorm = 0.9179, lr_0 = 6.8920e-04
Loss = 1.8985e-03, PNorm = 65.7260, GNorm = 0.6563, lr_0 = 6.6001e-04
Validation rmse = 1.023916
Epoch 7
Loss = 1.7030e-03, PNorm = 65.7620, GNorm = 1.1131, lr_0 = 6.3205e-04
Loss = 1.6231e-03, PNorm = 65.7943, GNorm = 0.6226, lr_0 = 6.0528e-04
Validation rmse = 1.212863
Epoch 8
Loss = 2.6040e-03, PNorm = 65.8313, GNorm = 1.8265, lr_0 = 5.7714e-04
Loss = 1.8280e-03, PNorm = 65.8698, GNorm = 0.5609, lr_0 = 5.5269e-04
Validation rmse = 1.075890
Epoch 9
Loss = 1.6851e-03, PNorm = 65.9034, GNorm = 1.6380, lr_0 = 5.2928e-04
Loss = 1.6227e-03, PNorm = 65.9360, GNorm = 1.1673, lr_0 = 5.0686e-04
Validation rmse = 0.974167
Epoch 10
Loss = 1.2732e-03, PNorm = 65.9633, GNorm = 0.6938, lr_0 = 4.8539e-04
Loss = 1.3986e-03, PNorm = 65.9892, GNorm = 0.7495, lr_0 = 4.6483e-04
Validation rmse = 1.022354
Epoch 11
Loss = 1.2853e-03, PNorm = 66.0201, GNorm = 0.5872, lr_0 = 4.4322e-04
Loss = 1.4387e-03, PNorm = 66.0473, GNorm = 0.6048, lr_0 = 4.2444e-04
Validation rmse = 1.006744
Epoch 12
Loss = 1.1391e-03, PNorm = 66.0718, GNorm = 0.2754, lr_0 = 4.0646e-04
Loss = 1.1080e-03, PNorm = 66.0930, GNorm = 0.7817, lr_0 = 3.8925e-04
Validation rmse = 0.972638
Epoch 13
Loss = 1.1591e-03, PNorm = 66.1124, GNorm = 1.2943, lr_0 = 3.7276e-04
Loss = 1.2752e-03, PNorm = 66.1356, GNorm = 0.8081, lr_0 = 3.5697e-04
Validation rmse = 1.009303
Epoch 14
Loss = 1.1484e-03, PNorm = 66.1573, GNorm = 0.7552, lr_0 = 3.4037e-04
Loss = 1.0488e-03, PNorm = 66.1733, GNorm = 0.7739, lr_0 = 3.2596e-04
Validation rmse = 1.043199
Epoch 15
Loss = 1.3515e-03, PNorm = 66.1904, GNorm = 0.9087, lr_0 = 3.1215e-04
Loss = 1.3241e-03, PNorm = 66.2085, GNorm = 0.6049, lr_0 = 2.9893e-04
Validation rmse = 1.019295
Epoch 16
Loss = 9.2150e-04, PNorm = 66.2279, GNorm = 0.7410, lr_0 = 2.8503e-04
Loss = 1.1571e-03, PNorm = 66.2438, GNorm = 0.9371, lr_0 = 2.7295e-04
Validation rmse = 1.089564
Epoch 17
Loss = 1.0509e-03, PNorm = 66.2583, GNorm = 0.5127, lr_0 = 2.6139e-04
Loss = 9.7225e-04, PNorm = 66.2725, GNorm = 0.3938, lr_0 = 2.5032e-04
Validation rmse = 1.010610
Epoch 18
Loss = 8.2497e-04, PNorm = 66.2849, GNorm = 0.3723, lr_0 = 2.3972e-04
Loss = 1.0086e-03, PNorm = 66.2994, GNorm = 0.4528, lr_0 = 2.2956e-04
Validation rmse = 1.030039
Epoch 19
Loss = 9.4069e-04, PNorm = 66.3146, GNorm = 0.2393, lr_0 = 2.1889e-04
Loss = 8.7378e-04, PNorm = 66.3254, GNorm = 0.5847, lr_0 = 2.0962e-04
Validation rmse = 0.994054
Epoch 20
Loss = 8.3127e-04, PNorm = 66.3347, GNorm = 0.4853, lr_0 = 2.0074e-04
Loss = 9.7819e-04, PNorm = 66.3471, GNorm = 0.4029, lr_0 = 1.9224e-04
Validation rmse = 1.042402
Epoch 21
Loss = 7.6334e-04, PNorm = 66.3589, GNorm = 0.4220, lr_0 = 1.8409e-04
Loss = 8.2975e-04, PNorm = 66.3670, GNorm = 1.0168, lr_0 = 1.7630e-04
Validation rmse = 1.098010
Epoch 22
Loss = 1.0988e-03, PNorm = 66.3791, GNorm = 0.6654, lr_0 = 1.6810e-04
Loss = 9.2771e-04, PNorm = 66.3887, GNorm = 0.5035, lr_0 = 1.6098e-04
Validation rmse = 1.038703
Epoch 23
Loss = 8.8874e-04, PNorm = 66.3988, GNorm = 0.6427, lr_0 = 1.5416e-04
Loss = 8.4491e-04, PNorm = 66.4066, GNorm = 1.0667, lr_0 = 1.4763e-04
Loss = 1.4222e-03, PNorm = 66.4076, GNorm = 0.5525, lr_0 = 1.4699e-04
Validation rmse = 1.033018
Epoch 24
Loss = 7.3853e-04, PNorm = 66.4157, GNorm = 0.5162, lr_0 = 1.4077e-04
Loss = 9.2624e-04, PNorm = 66.4245, GNorm = 0.6480, lr_0 = 1.3480e-04
Validation rmse = 1.077691
Epoch 25
Loss = 7.4129e-04, PNorm = 66.4308, GNorm = 0.4419, lr_0 = 1.2909e-04
Loss = 8.1850e-04, PNorm = 66.4364, GNorm = 0.8770, lr_0 = 1.2362e-04
Validation rmse = 1.007033
Epoch 26
Loss = 8.8123e-04, PNorm = 66.4438, GNorm = 0.8018, lr_0 = 1.1839e-04
Validation rmse = 1.052807
Epoch 27
Loss = 7.5479e-04, PNorm = 66.4503, GNorm = 0.2830, lr_0 = 1.1288e-04
Loss = 7.4872e-04, PNorm = 66.4576, GNorm = 0.7114, lr_0 = 1.0810e-04
Validation rmse = 1.026298
Epoch 28
Loss = 4.7692e-04, PNorm = 66.4618, GNorm = 0.2970, lr_0 = 1.0352e-04
Loss = 7.2533e-04, PNorm = 66.4671, GNorm = 0.6798, lr_0 = 1.0000e-04
Validation rmse = 1.026901
Epoch 29
Loss = 6.0470e-04, PNorm = 66.4739, GNorm = 0.2476, lr_0 = 1.0000e-04
Loss = 6.8206e-04, PNorm = 66.4790, GNorm = 0.6142, lr_0 = 1.0000e-04
Validation rmse = 1.021551
Model 0 best validation rmse = 0.972638 on epoch 12
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.844331
Ensemble test rmse = 0.844331
Fold 4
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_3_dropout_0.1_ffn_num_layers_2_hidden_size_1300/fold_4',
 'save_smiles_splits': True,
 'seed': 4,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 4
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 49 | test scaffolds = 62
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1300, bias=False)
      (W_h): Linear(in_features=1300, out_features=1300, bias=False)
      (W_o): Linear(in_features=1433, out_features=1300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=1304, out_features=1300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1300, out_features=1, bias=True)
  )
)
Number of parameters = 5,443,101
Moving model to cuda
Epoch 0
Loss = 1.4946e-02, PNorm = 65.0499, GNorm = 2.5699, lr_0 = 3.6053e-04
Validation rmse = 1.093168
Epoch 1
Loss = 6.3487e-03, PNorm = 65.1210, GNorm = 3.1432, lr_0 = 6.2105e-04
Loss = 4.3542e-03, PNorm = 65.1983, GNorm = 2.5541, lr_0 = 8.5789e-04
Validation rmse = 1.099967
Epoch 2
Loss = 3.5007e-03, PNorm = 65.2797, GNorm = 2.4476, lr_0 = 9.8284e-04
Loss = 4.2075e-03, PNorm = 65.3570, GNorm = 1.6238, lr_0 = 9.4120e-04
Validation rmse = 1.103953
Epoch 3
Loss = 2.5187e-03, PNorm = 65.4249, GNorm = 0.5753, lr_0 = 8.9744e-04
Loss = 2.7144e-03, PNorm = 65.4793, GNorm = 0.8276, lr_0 = 8.5943e-04
Validation rmse = 0.909662
Epoch 4
Loss = 1.7420e-03, PNorm = 65.5261, GNorm = 0.5954, lr_0 = 8.2303e-04
Loss = 2.1279e-03, PNorm = 65.5694, GNorm = 0.6833, lr_0 = 7.8816e-04
Validation rmse = 0.882753
Epoch 5
Loss = 1.8050e-03, PNorm = 65.6081, GNorm = 0.9203, lr_0 = 7.5478e-04
Loss = 2.0470e-03, PNorm = 65.6483, GNorm = 0.7743, lr_0 = 7.2281e-04
Validation rmse = 0.893989
Epoch 6
Loss = 1.9696e-03, PNorm = 65.6929, GNorm = 0.8501, lr_0 = 6.8920e-04
Loss = 2.3432e-03, PNorm = 65.7311, GNorm = 0.7784, lr_0 = 6.6001e-04
Validation rmse = 0.823308
Epoch 7
Loss = 1.6028e-03, PNorm = 65.7682, GNorm = 0.6806, lr_0 = 6.3205e-04
Loss = 2.3643e-03, PNorm = 65.8048, GNorm = 0.9875, lr_0 = 6.0528e-04
Validation rmse = 0.916438
Epoch 8
Loss = 2.0118e-03, PNorm = 65.8418, GNorm = 1.1019, lr_0 = 5.7714e-04
Loss = 1.7004e-03, PNorm = 65.8698, GNorm = 1.0175, lr_0 = 5.5269e-04
Validation rmse = 0.895599
Epoch 9
Loss = 1.3705e-03, PNorm = 65.9012, GNorm = 0.6852, lr_0 = 5.2928e-04
Loss = 1.8113e-03, PNorm = 65.9333, GNorm = 0.2963, lr_0 = 5.0686e-04
Validation rmse = 0.777248
Epoch 10
Loss = 1.6224e-03, PNorm = 65.9618, GNorm = 0.9981, lr_0 = 4.8539e-04
Loss = 2.1041e-03, PNorm = 65.9910, GNorm = 1.1787, lr_0 = 4.6483e-04
Validation rmse = 0.843924
Epoch 11
Loss = 1.2889e-03, PNorm = 66.0210, GNorm = 0.5560, lr_0 = 4.4322e-04
Loss = 1.5161e-03, PNorm = 66.0426, GNorm = 0.3960, lr_0 = 4.2444e-04
Validation rmse = 0.814209
Epoch 12
Loss = 1.1283e-03, PNorm = 66.0630, GNorm = 0.7243, lr_0 = 4.0646e-04
Loss = 1.4465e-03, PNorm = 66.0873, GNorm = 0.3409, lr_0 = 3.8925e-04
Validation rmse = 0.833461
Epoch 13
Loss = 1.1545e-03, PNorm = 66.1083, GNorm = 1.0406, lr_0 = 3.7276e-04
Loss = 1.5261e-03, PNorm = 66.1317, GNorm = 0.7522, lr_0 = 3.5697e-04
Validation rmse = 0.819226
Epoch 14
Loss = 1.0841e-03, PNorm = 66.1544, GNorm = 0.5805, lr_0 = 3.4037e-04
Loss = 1.5246e-03, PNorm = 66.1762, GNorm = 0.4551, lr_0 = 3.2596e-04
Validation rmse = 0.764098
Epoch 15
Loss = 1.1921e-03, PNorm = 66.1949, GNorm = 0.8537, lr_0 = 3.1215e-04
Loss = 1.3360e-03, PNorm = 66.2152, GNorm = 0.5833, lr_0 = 2.9893e-04
Validation rmse = 0.776747
Epoch 16
Loss = 9.4341e-04, PNorm = 66.2343, GNorm = 0.5855, lr_0 = 2.8503e-04
Loss = 1.4619e-03, PNorm = 66.2503, GNorm = 0.6092, lr_0 = 2.7295e-04
Validation rmse = 0.786809
Epoch 17
Loss = 1.2122e-03, PNorm = 66.2653, GNorm = 0.6916, lr_0 = 2.6139e-04
Loss = 1.2954e-03, PNorm = 66.2795, GNorm = 0.9914, lr_0 = 2.5032e-04
Validation rmse = 0.788100
Epoch 18
Loss = 1.6921e-03, PNorm = 66.2968, GNorm = 1.0084, lr_0 = 2.3972e-04
Loss = 1.1503e-03, PNorm = 66.3154, GNorm = 0.4559, lr_0 = 2.2956e-04
Validation rmse = 0.773073
Epoch 19
Loss = 9.6551e-04, PNorm = 66.3300, GNorm = 0.2788, lr_0 = 2.1889e-04
Loss = 1.1052e-03, PNorm = 66.3456, GNorm = 0.4676, lr_0 = 2.0962e-04
Validation rmse = 0.754093
Epoch 20
Loss = 1.0359e-03, PNorm = 66.3582, GNorm = 0.5133, lr_0 = 2.0074e-04
Loss = 9.8395e-04, PNorm = 66.3704, GNorm = 0.9070, lr_0 = 1.9224e-04
Validation rmse = 0.798934
Epoch 21
Loss = 1.0078e-03, PNorm = 66.3832, GNorm = 0.7986, lr_0 = 1.8409e-04
Loss = 1.0368e-03, PNorm = 66.3951, GNorm = 0.8258, lr_0 = 1.7630e-04
Validation rmse = 0.848473
Epoch 22
Loss = 8.9775e-04, PNorm = 66.4068, GNorm = 0.5999, lr_0 = 1.6810e-04
Loss = 1.0218e-03, PNorm = 66.4185, GNorm = 0.4141, lr_0 = 1.6098e-04
Validation rmse = 0.774228
Epoch 23
Loss = 9.0474e-04, PNorm = 66.4271, GNorm = 0.5905, lr_0 = 1.5416e-04
Loss = 7.6979e-04, PNorm = 66.4366, GNorm = 0.4251, lr_0 = 1.4763e-04
Loss = 1.7505e-03, PNorm = 66.4374, GNorm = 0.6480, lr_0 = 1.4699e-04
Validation rmse = 0.747375
Epoch 24
Loss = 9.4717e-04, PNorm = 66.4449, GNorm = 0.5703, lr_0 = 1.4077e-04
Loss = 9.6310e-04, PNorm = 66.4531, GNorm = 0.6719, lr_0 = 1.3480e-04
Validation rmse = 0.797632
Epoch 25
Loss = 8.3947e-04, PNorm = 66.4614, GNorm = 0.6469, lr_0 = 1.2909e-04
Loss = 1.0497e-03, PNorm = 66.4695, GNorm = 0.9522, lr_0 = 1.2362e-04
Validation rmse = 0.775391
Epoch 26
Loss = 7.1467e-04, PNorm = 66.4783, GNorm = 0.2764, lr_0 = 1.1839e-04
Validation rmse = 0.771150
Epoch 27
Loss = 7.2864e-04, PNorm = 66.4866, GNorm = 0.4553, lr_0 = 1.1288e-04
Loss = 7.6518e-04, PNorm = 66.4925, GNorm = 1.0983, lr_0 = 1.0810e-04
Validation rmse = 0.764903
Epoch 28
Loss = 4.6257e-04, PNorm = 66.4999, GNorm = 0.6599, lr_0 = 1.0352e-04
Loss = 8.3808e-04, PNorm = 66.5052, GNorm = 0.6255, lr_0 = 1.0000e-04
Validation rmse = 0.786403
Epoch 29
Loss = 7.5902e-04, PNorm = 66.5123, GNorm = 0.4381, lr_0 = 1.0000e-04
Loss = 9.3355e-04, PNorm = 66.5193, GNorm = 0.4565, lr_0 = 1.0000e-04
Validation rmse = 0.761434
Model 0 best validation rmse = 0.747375 on epoch 23
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.907345
Ensemble test rmse = 0.907345
Fold 5
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_3_dropout_0.1_ffn_num_layers_2_hidden_size_1300/fold_5',
 'save_smiles_splits': True,
 'seed': 5,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 5
Total scaffolds = 195 | train scaffolds = 94 | val scaffolds = 55 | test scaffolds = 46
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1300, bias=False)
      (W_h): Linear(in_features=1300, out_features=1300, bias=False)
      (W_o): Linear(in_features=1433, out_features=1300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=1304, out_features=1300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1300, out_features=1, bias=True)
  )
)
Number of parameters = 5,443,101
Moving model to cuda
Epoch 0
Loss = 1.4536e-02, PNorm = 65.0517, GNorm = 11.7434, lr_0 = 3.6053e-04
Validation rmse = 1.608901
Epoch 1
Loss = 5.0094e-03, PNorm = 65.1165, GNorm = 1.8501, lr_0 = 6.2105e-04
Loss = 4.7825e-03, PNorm = 65.1930, GNorm = 2.8684, lr_0 = 8.5789e-04
Validation rmse = 1.537414
Epoch 2
Loss = 4.0580e-03, PNorm = 65.2809, GNorm = 1.1443, lr_0 = 9.8284e-04
Loss = 3.5530e-03, PNorm = 65.3616, GNorm = 0.8808, lr_0 = 9.4120e-04
Validation rmse = 1.112581
Epoch 3
Loss = 3.0657e-03, PNorm = 65.4287, GNorm = 1.1548, lr_0 = 8.9744e-04
Loss = 2.9906e-03, PNorm = 65.4828, GNorm = 0.6811, lr_0 = 8.5943e-04
Validation rmse = 1.054031
Epoch 4
Loss = 2.0438e-03, PNorm = 65.5273, GNorm = 0.9490, lr_0 = 8.2303e-04
Loss = 2.1101e-03, PNorm = 65.5742, GNorm = 0.8717, lr_0 = 7.8816e-04
Validation rmse = 1.115361
Epoch 5
Loss = 1.8591e-03, PNorm = 65.6086, GNorm = 0.4403, lr_0 = 7.5478e-04
Loss = 2.5332e-03, PNorm = 65.6446, GNorm = 1.3929, lr_0 = 7.2281e-04
Validation rmse = 1.017965
Epoch 6
Loss = 2.9160e-03, PNorm = 65.6919, GNorm = 1.0013, lr_0 = 6.8920e-04
Loss = 2.5414e-03, PNorm = 65.7391, GNorm = 0.9739, lr_0 = 6.6001e-04
Validation rmse = 1.129991
Epoch 7
Loss = 1.6234e-03, PNorm = 65.7764, GNorm = 0.5134, lr_0 = 6.3205e-04
Loss = 1.9112e-03, PNorm = 65.8155, GNorm = 1.2305, lr_0 = 6.0528e-04
Validation rmse = 1.024980
Epoch 8
Loss = 1.6161e-03, PNorm = 65.8486, GNorm = 0.7306, lr_0 = 5.7714e-04
Loss = 1.8081e-03, PNorm = 65.8799, GNorm = 0.7365, lr_0 = 5.5269e-04
Validation rmse = 0.963413
Epoch 9
Loss = 1.9511e-03, PNorm = 65.9093, GNorm = 0.7134, lr_0 = 5.2928e-04
Loss = 1.7820e-03, PNorm = 65.9418, GNorm = 0.5627, lr_0 = 5.0686e-04
Validation rmse = 1.058893
Epoch 10
Loss = 1.7594e-03, PNorm = 65.9716, GNorm = 0.8530, lr_0 = 4.8539e-04
Loss = 2.1306e-03, PNorm = 65.9956, GNorm = 1.0336, lr_0 = 4.6483e-04
Validation rmse = 0.926397
Epoch 11
Loss = 1.6322e-03, PNorm = 66.0277, GNorm = 0.3939, lr_0 = 4.4322e-04
Loss = 1.4739e-03, PNorm = 66.0543, GNorm = 0.6381, lr_0 = 4.2444e-04
Validation rmse = 0.971405
Epoch 12
Loss = 1.3211e-03, PNorm = 66.0791, GNorm = 0.7700, lr_0 = 4.0646e-04
Loss = 1.5348e-03, PNorm = 66.1014, GNorm = 0.9358, lr_0 = 3.8925e-04
Validation rmse = 0.967485
Epoch 13
Loss = 1.3845e-03, PNorm = 66.1229, GNorm = 0.4550, lr_0 = 3.7276e-04
Loss = 1.6803e-03, PNorm = 66.1438, GNorm = 0.5290, lr_0 = 3.5697e-04
Validation rmse = 1.119697
Epoch 14
Loss = 1.4177e-03, PNorm = 66.1718, GNorm = 0.7936, lr_0 = 3.4037e-04
Loss = 1.3229e-03, PNorm = 66.1888, GNorm = 0.8237, lr_0 = 3.2596e-04
Validation rmse = 1.050643
Epoch 15
Loss = 1.3336e-03, PNorm = 66.2104, GNorm = 0.5221, lr_0 = 3.1215e-04
Loss = 1.4789e-03, PNorm = 66.2324, GNorm = 0.7227, lr_0 = 2.9893e-04
Validation rmse = 1.050835
Epoch 16
Loss = 1.1464e-03, PNorm = 66.2525, GNorm = 0.4080, lr_0 = 2.8503e-04
Loss = 1.5419e-03, PNorm = 66.2706, GNorm = 0.6196, lr_0 = 2.7295e-04
Validation rmse = 1.031127
Epoch 17
Loss = 1.1944e-03, PNorm = 66.2920, GNorm = 0.5908, lr_0 = 2.6139e-04
Loss = 1.1891e-03, PNorm = 66.3061, GNorm = 0.4193, lr_0 = 2.5032e-04
Validation rmse = 1.004007
Epoch 18
Loss = 1.2473e-03, PNorm = 66.3219, GNorm = 0.3796, lr_0 = 2.3972e-04
Loss = 1.1047e-03, PNorm = 66.3372, GNorm = 0.3855, lr_0 = 2.2956e-04
Validation rmse = 0.998194
Epoch 19
Loss = 1.0138e-03, PNorm = 66.3541, GNorm = 0.4124, lr_0 = 2.1889e-04
Loss = 1.1799e-03, PNorm = 66.3663, GNorm = 0.5460, lr_0 = 2.0962e-04
Validation rmse = 1.009359
Epoch 20
Loss = 1.1532e-03, PNorm = 66.3806, GNorm = 0.3493, lr_0 = 2.0074e-04
Loss = 1.0710e-03, PNorm = 66.3934, GNorm = 0.6082, lr_0 = 1.9224e-04
Validation rmse = 0.989223
Epoch 21
Loss = 1.0025e-03, PNorm = 66.4033, GNorm = 0.7041, lr_0 = 1.8409e-04
Loss = 1.0956e-03, PNorm = 66.4159, GNorm = 0.7895, lr_0 = 1.7630e-04
Validation rmse = 0.990153
Epoch 22
Loss = 8.8072e-04, PNorm = 66.4268, GNorm = 0.3763, lr_0 = 1.6810e-04
Loss = 9.6313e-04, PNorm = 66.4366, GNorm = 0.3489, lr_0 = 1.6098e-04
Validation rmse = 0.971415
Epoch 23
Loss = 1.1744e-03, PNorm = 66.4475, GNorm = 0.5089, lr_0 = 1.5416e-04
Loss = 1.0496e-03, PNorm = 66.4573, GNorm = 0.4907, lr_0 = 1.4763e-04
Loss = 9.0159e-04, PNorm = 66.4585, GNorm = 0.3263, lr_0 = 1.4699e-04
Validation rmse = 1.041443
Epoch 24
Loss = 8.6216e-04, PNorm = 66.4669, GNorm = 0.4181, lr_0 = 1.4077e-04
Loss = 1.1196e-03, PNorm = 66.4748, GNorm = 0.4312, lr_0 = 1.3480e-04
Validation rmse = 1.031420
Epoch 25
Loss = 8.8352e-04, PNorm = 66.4842, GNorm = 0.5617, lr_0 = 1.2909e-04
Loss = 9.6205e-04, PNorm = 66.4925, GNorm = 1.0406, lr_0 = 1.2362e-04
Validation rmse = 1.021840
Epoch 26
Loss = 8.7822e-04, PNorm = 66.4998, GNorm = 0.7533, lr_0 = 1.1839e-04
Validation rmse = 0.998750
Epoch 27
Loss = 8.3692e-04, PNorm = 66.5094, GNorm = 0.5364, lr_0 = 1.1288e-04
Loss = 9.9970e-04, PNorm = 66.5176, GNorm = 0.8740, lr_0 = 1.0810e-04
Validation rmse = 0.952378
Epoch 28
Loss = 8.8202e-04, PNorm = 66.5245, GNorm = 0.3443, lr_0 = 1.0352e-04
Loss = 8.9526e-04, PNorm = 66.5308, GNorm = 0.9886, lr_0 = 1.0000e-04
Validation rmse = 0.980603
Epoch 29
Loss = 9.1374e-04, PNorm = 66.5364, GNorm = 0.5989, lr_0 = 1.0000e-04
Loss = 8.8540e-04, PNorm = 66.5438, GNorm = 0.4424, lr_0 = 1.0000e-04
Validation rmse = 1.005611
Model 0 best validation rmse = 0.926397 on epoch 10
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.985085
Ensemble test rmse = 0.985085
Fold 6
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_3_dropout_0.1_ffn_num_layers_2_hidden_size_1300/fold_6',
 'save_smiles_splits': True,
 'seed': 6,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 6
Total scaffolds = 195 | train scaffolds = 64 | val scaffolds = 68 | test scaffolds = 63
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -6.399748


Scaffold 7
Task 0: count = 14 | target average = -5.140965


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1300, bias=False)
      (W_h): Linear(in_features=1300, out_features=1300, bias=False)
      (W_o): Linear(in_features=1433, out_features=1300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=1304, out_features=1300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1300, out_features=1, bias=True)
  )
)
Number of parameters = 5,443,101
Moving model to cuda
Epoch 0
Loss = 1.4480e-02, PNorm = 65.0521, GNorm = 1.7550, lr_0 = 3.6053e-04
Validation rmse = 1.659282
Epoch 1
Loss = 5.6340e-03, PNorm = 65.1162, GNorm = 4.2251, lr_0 = 6.2105e-04
Loss = 4.3068e-03, PNorm = 65.1921, GNorm = 2.9961, lr_0 = 8.5789e-04
Validation rmse = 1.363748
Epoch 2
Loss = 3.2682e-03, PNorm = 65.2659, GNorm = 1.2140, lr_0 = 9.8284e-04
Loss = 3.1818e-03, PNorm = 65.3348, GNorm = 0.6825, lr_0 = 9.4120e-04
Validation rmse = 1.166554
Epoch 3
Loss = 1.7285e-03, PNorm = 65.3979, GNorm = 1.5113, lr_0 = 8.9744e-04
Loss = 2.3133e-03, PNorm = 65.4444, GNorm = 0.7762, lr_0 = 8.5943e-04
Validation rmse = 1.210140
Epoch 4
Loss = 2.6397e-03, PNorm = 65.4938, GNorm = 1.3329, lr_0 = 8.2303e-04
Loss = 2.8200e-03, PNorm = 65.5395, GNorm = 1.0283, lr_0 = 7.8816e-04
Validation rmse = 1.264857
Epoch 5
Loss = 2.1242e-03, PNorm = 65.5848, GNorm = 1.3436, lr_0 = 7.5478e-04
Loss = 2.3558e-03, PNorm = 65.6240, GNorm = 0.4142, lr_0 = 7.2281e-04
Validation rmse = 1.213478
Epoch 6
Loss = 2.1149e-03, PNorm = 65.6681, GNorm = 0.3806, lr_0 = 6.8920e-04
Loss = 2.0972e-03, PNorm = 65.7117, GNorm = 0.7140, lr_0 = 6.6001e-04
Validation rmse = 1.008539
Epoch 7
Loss = 1.8999e-03, PNorm = 65.7452, GNorm = 0.7853, lr_0 = 6.3205e-04
Loss = 1.6083e-03, PNorm = 65.7796, GNorm = 1.1680, lr_0 = 6.0528e-04
Validation rmse = 0.975356
Epoch 8
Loss = 1.6741e-03, PNorm = 65.8159, GNorm = 0.4927, lr_0 = 5.7714e-04
Loss = 1.9444e-03, PNorm = 65.8491, GNorm = 0.6082, lr_0 = 5.5269e-04
Validation rmse = 1.173957
Epoch 9
Loss = 1.9321e-03, PNorm = 65.8862, GNorm = 0.9358, lr_0 = 5.2928e-04
Loss = 1.4108e-03, PNorm = 65.9170, GNorm = 0.4002, lr_0 = 5.0686e-04
Validation rmse = 0.977470
Epoch 10
Loss = 1.6691e-03, PNorm = 65.9468, GNorm = 0.9559, lr_0 = 4.8539e-04
Loss = 1.3778e-03, PNorm = 65.9812, GNorm = 0.5001, lr_0 = 4.6483e-04
Validation rmse = 1.056888
Epoch 11
Loss = 1.5473e-03, PNorm = 66.0061, GNorm = 0.5226, lr_0 = 4.4322e-04
Loss = 1.6664e-03, PNorm = 66.0330, GNorm = 1.2580, lr_0 = 4.2444e-04
Validation rmse = 0.982309
Epoch 12
Loss = 1.3180e-03, PNorm = 66.0523, GNorm = 0.4590, lr_0 = 4.0646e-04
Loss = 1.6809e-03, PNorm = 66.0763, GNorm = 1.0820, lr_0 = 3.8925e-04
Validation rmse = 0.967779
Epoch 13
Loss = 1.3354e-03, PNorm = 66.1022, GNorm = 0.7188, lr_0 = 3.7276e-04
Loss = 1.3117e-03, PNorm = 66.1289, GNorm = 0.5686, lr_0 = 3.5697e-04
Validation rmse = 1.008208
Epoch 14
Loss = 1.1848e-03, PNorm = 66.1511, GNorm = 0.3437, lr_0 = 3.4037e-04
Loss = 1.5008e-03, PNorm = 66.1737, GNorm = 1.1035, lr_0 = 3.2596e-04
Validation rmse = 1.013294
Epoch 15
Loss = 1.1050e-03, PNorm = 66.1952, GNorm = 0.3727, lr_0 = 3.1215e-04
Loss = 1.0614e-03, PNorm = 66.2168, GNorm = 0.9403, lr_0 = 2.9893e-04
Validation rmse = 0.983608
Epoch 16
Loss = 1.0181e-03, PNorm = 66.2395, GNorm = 0.3178, lr_0 = 2.8503e-04
Loss = 1.1604e-03, PNorm = 66.2596, GNorm = 0.7031, lr_0 = 2.7295e-04
Validation rmse = 1.107701
Epoch 17
Loss = 1.4287e-03, PNorm = 66.2776, GNorm = 0.5445, lr_0 = 2.6139e-04
Loss = 1.1563e-03, PNorm = 66.2920, GNorm = 0.9727, lr_0 = 2.5032e-04
Validation rmse = 1.045150
Epoch 18
Loss = 1.3273e-03, PNorm = 66.3089, GNorm = 1.1142, lr_0 = 2.3972e-04
Loss = 1.0460e-03, PNorm = 66.3254, GNorm = 0.3847, lr_0 = 2.2956e-04
Validation rmse = 1.023975
Epoch 19
Loss = 9.3823e-04, PNorm = 66.3437, GNorm = 0.1985, lr_0 = 2.1889e-04
Loss = 9.3253e-04, PNorm = 66.3566, GNorm = 0.5653, lr_0 = 2.0962e-04
Validation rmse = 1.050670
Epoch 20
Loss = 8.9419e-04, PNorm = 66.3707, GNorm = 0.4071, lr_0 = 2.0074e-04
Loss = 9.9886e-04, PNorm = 66.3823, GNorm = 0.3385, lr_0 = 1.9224e-04
Validation rmse = 1.018976
Epoch 21
Loss = 9.9034e-04, PNorm = 66.3984, GNorm = 0.4075, lr_0 = 1.8409e-04
Loss = 9.8249e-04, PNorm = 66.4097, GNorm = 0.3670, lr_0 = 1.7630e-04
Validation rmse = 1.078537
Epoch 22
Loss = 9.5330e-04, PNorm = 66.4184, GNorm = 0.8427, lr_0 = 1.6810e-04
Loss = 1.0054e-03, PNorm = 66.4275, GNorm = 0.6147, lr_0 = 1.6098e-04
Validation rmse = 1.016857
Epoch 23
Loss = 8.9751e-04, PNorm = 66.4378, GNorm = 0.4604, lr_0 = 1.5416e-04
Loss = 8.4274e-04, PNorm = 66.4480, GNorm = 0.6712, lr_0 = 1.4763e-04
Loss = 1.3462e-03, PNorm = 66.4487, GNorm = 0.6029, lr_0 = 1.4699e-04
Validation rmse = 1.004368
Epoch 24
Loss = 9.1027e-04, PNorm = 66.4581, GNorm = 0.3658, lr_0 = 1.4077e-04
Loss = 9.4000e-04, PNorm = 66.4678, GNorm = 0.5219, lr_0 = 1.3480e-04
Validation rmse = 1.021900
Epoch 25
Loss = 9.0910e-04, PNorm = 66.4730, GNorm = 1.0185, lr_0 = 1.2909e-04
Loss = 9.8120e-04, PNorm = 66.4807, GNorm = 0.7321, lr_0 = 1.2362e-04
Validation rmse = 0.998147
Epoch 26
Loss = 7.9773e-04, PNorm = 66.4862, GNorm = 0.4409, lr_0 = 1.1839e-04
Validation rmse = 1.001951
Epoch 27
Loss = 1.0428e-03, PNorm = 66.4942, GNorm = 1.0564, lr_0 = 1.1288e-04
Loss = 6.8847e-04, PNorm = 66.5009, GNorm = 0.4739, lr_0 = 1.0810e-04
Validation rmse = 1.000324
Epoch 28
Loss = 7.8835e-04, PNorm = 66.5087, GNorm = 0.8135, lr_0 = 1.0352e-04
Loss = 7.3848e-04, PNorm = 66.5138, GNorm = 0.7334, lr_0 = 1.0000e-04
Validation rmse = 1.020266
Epoch 29
Loss = 7.3995e-04, PNorm = 66.5205, GNorm = 0.8344, lr_0 = 1.0000e-04
Loss = 7.9047e-04, PNorm = 66.5275, GNorm = 0.5657, lr_0 = 1.0000e-04
Validation rmse = 1.042279
Model 0 best validation rmse = 0.967779 on epoch 12
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.789242
Ensemble test rmse = 0.789242
Fold 7
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_3_dropout_0.1_ffn_num_layers_2_hidden_size_1300/fold_7',
 'save_smiles_splits': True,
 'seed': 7,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 7
Total scaffolds = 195 | train scaffolds = 69 | val scaffolds = 65 | test scaffolds = 61
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1300, bias=False)
      (W_h): Linear(in_features=1300, out_features=1300, bias=False)
      (W_o): Linear(in_features=1433, out_features=1300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=1304, out_features=1300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1300, out_features=1, bias=True)
  )
)
Number of parameters = 5,443,101
Moving model to cuda
Epoch 0
Loss = 1.3950e-02, PNorm = 65.0521, GNorm = 5.5435, lr_0 = 3.6053e-04
Validation rmse = 1.460903
Epoch 1
Loss = 3.5113e-03, PNorm = 65.1141, GNorm = 1.4740, lr_0 = 6.2105e-04
Loss = 4.6310e-03, PNorm = 65.1878, GNorm = 2.4699, lr_0 = 8.5789e-04
Validation rmse = 1.299727
Epoch 2
Loss = 2.6679e-03, PNorm = 65.2662, GNorm = 0.9599, lr_0 = 9.8284e-04
Loss = 3.6035e-03, PNorm = 65.3421, GNorm = 2.1788, lr_0 = 9.4120e-04
Validation rmse = 1.536631
Epoch 3
Loss = 2.8229e-03, PNorm = 65.4110, GNorm = 0.5774, lr_0 = 8.9744e-04
Loss = 2.6615e-03, PNorm = 65.4654, GNorm = 1.7632, lr_0 = 8.5943e-04
Validation rmse = 1.307311
Epoch 4
Loss = 2.5856e-03, PNorm = 65.5113, GNorm = 1.2313, lr_0 = 8.2303e-04
Loss = 2.7512e-03, PNorm = 65.5620, GNorm = 1.8019, lr_0 = 7.8816e-04
Validation rmse = 1.303573
Epoch 5
Loss = 1.3890e-03, PNorm = 65.6080, GNorm = 0.6499, lr_0 = 7.5478e-04
Loss = 1.8273e-03, PNorm = 65.6526, GNorm = 0.3789, lr_0 = 7.2281e-04
Validation rmse = 1.180990
Epoch 6
Loss = 2.1940e-03, PNorm = 65.6974, GNorm = 0.4910, lr_0 = 6.8920e-04
Loss = 1.9266e-03, PNorm = 65.7404, GNorm = 1.3034, lr_0 = 6.6001e-04
Validation rmse = 1.357182
Epoch 7
Loss = 1.9299e-03, PNorm = 65.7759, GNorm = 1.0244, lr_0 = 6.3205e-04
Loss = 2.3878e-03, PNorm = 65.8147, GNorm = 0.7117, lr_0 = 6.0528e-04
Validation rmse = 1.280542
Epoch 8
Loss = 1.6779e-03, PNorm = 65.8547, GNorm = 0.7332, lr_0 = 5.7714e-04
Loss = 1.6054e-03, PNorm = 65.8829, GNorm = 0.3474, lr_0 = 5.5269e-04
Validation rmse = 1.590065
Epoch 9
Loss = 2.0539e-03, PNorm = 65.9097, GNorm = 0.6039, lr_0 = 5.2928e-04
Loss = 1.7585e-03, PNorm = 65.9408, GNorm = 0.7567, lr_0 = 5.0686e-04
Validation rmse = 1.436801
Epoch 10
Loss = 1.4717e-03, PNorm = 65.9701, GNorm = 0.7508, lr_0 = 4.8539e-04
Loss = 1.4634e-03, PNorm = 66.0024, GNorm = 0.3535, lr_0 = 4.6483e-04
Validation rmse = 1.345671
Epoch 11
Loss = 1.1320e-03, PNorm = 66.0348, GNorm = 0.3489, lr_0 = 4.4322e-04
Loss = 1.2692e-03, PNorm = 66.0610, GNorm = 0.4416, lr_0 = 4.2444e-04
Validation rmse = 1.294705
Epoch 12
Loss = 1.1916e-03, PNorm = 66.0837, GNorm = 0.3740, lr_0 = 4.0646e-04
Loss = 1.1329e-03, PNorm = 66.1032, GNorm = 0.3936, lr_0 = 3.8925e-04
Validation rmse = 1.169346
Epoch 13
Loss = 1.5597e-03, PNorm = 66.1245, GNorm = 0.8810, lr_0 = 3.7276e-04
Loss = 1.6238e-03, PNorm = 66.1510, GNorm = 0.8137, lr_0 = 3.5697e-04
Validation rmse = 1.246050
Epoch 14
Loss = 1.1741e-03, PNorm = 66.1743, GNorm = 0.5777, lr_0 = 3.4037e-04
Loss = 1.3465e-03, PNorm = 66.1928, GNorm = 1.6715, lr_0 = 3.2596e-04
Validation rmse = 1.266858
Epoch 15
Loss = 1.4888e-03, PNorm = 66.2119, GNorm = 1.1471, lr_0 = 3.1215e-04
Loss = 1.4517e-03, PNorm = 66.2329, GNorm = 0.3970, lr_0 = 2.9893e-04
Validation rmse = 1.394731
Epoch 16
Loss = 1.1195e-03, PNorm = 66.2545, GNorm = 0.5791, lr_0 = 2.8503e-04
Loss = 1.1841e-03, PNorm = 66.2682, GNorm = 0.4084, lr_0 = 2.7295e-04
Validation rmse = 1.437188
Epoch 17
Loss = 1.1365e-03, PNorm = 66.2869, GNorm = 0.4286, lr_0 = 2.6139e-04
Loss = 1.0988e-03, PNorm = 66.3005, GNorm = 0.4185, lr_0 = 2.5032e-04
Validation rmse = 1.255548
Epoch 18
Loss = 1.0843e-03, PNorm = 66.3166, GNorm = 0.6710, lr_0 = 2.3972e-04
Loss = 1.2896e-03, PNorm = 66.3306, GNorm = 0.3175, lr_0 = 2.2956e-04
Validation rmse = 1.297436
Epoch 19
Loss = 1.3783e-03, PNorm = 66.3437, GNorm = 0.6949, lr_0 = 2.1889e-04
Loss = 1.0593e-03, PNorm = 66.3601, GNorm = 0.4761, lr_0 = 2.0962e-04
Validation rmse = 1.255613
Epoch 20
Loss = 1.1693e-03, PNorm = 66.3747, GNorm = 0.7295, lr_0 = 2.0074e-04
Loss = 8.1570e-04, PNorm = 66.3877, GNorm = 0.3870, lr_0 = 1.9224e-04
Validation rmse = 1.300210
Epoch 21
Loss = 1.1166e-03, PNorm = 66.3988, GNorm = 0.7828, lr_0 = 1.8409e-04
Loss = 1.0529e-03, PNorm = 66.4121, GNorm = 0.6336, lr_0 = 1.7630e-04
Validation rmse = 1.451481
Epoch 22
Loss = 8.9349e-04, PNorm = 66.4226, GNorm = 0.8385, lr_0 = 1.6810e-04
Loss = 1.0892e-03, PNorm = 66.4311, GNorm = 0.8143, lr_0 = 1.6098e-04
Validation rmse = 1.248413
Epoch 23
Loss = 1.0440e-03, PNorm = 66.4410, GNorm = 0.3452, lr_0 = 1.5416e-04
Loss = 8.8582e-04, PNorm = 66.4499, GNorm = 0.4270, lr_0 = 1.4763e-04
Loss = 1.3583e-03, PNorm = 66.4507, GNorm = 1.5446, lr_0 = 1.4699e-04
Validation rmse = 1.262246
Epoch 24
Loss = 1.1093e-03, PNorm = 66.4583, GNorm = 0.6984, lr_0 = 1.4077e-04
Loss = 8.7230e-04, PNorm = 66.4687, GNorm = 0.4375, lr_0 = 1.3480e-04
Validation rmse = 1.311695
Epoch 25
Loss = 7.6973e-04, PNorm = 66.4761, GNorm = 0.3381, lr_0 = 1.2909e-04
Loss = 9.5680e-04, PNorm = 66.4858, GNorm = 0.9667, lr_0 = 1.2362e-04
Validation rmse = 1.312199
Epoch 26
Loss = 7.8408e-04, PNorm = 66.4912, GNorm = 0.4765, lr_0 = 1.1839e-04
Validation rmse = 1.299081
Epoch 27
Loss = 5.8892e-04, PNorm = 66.4991, GNorm = 0.7945, lr_0 = 1.1288e-04
Loss = 8.5813e-04, PNorm = 66.5051, GNorm = 0.5044, lr_0 = 1.0810e-04
Validation rmse = 1.394123
Epoch 28
Loss = 4.4908e-04, PNorm = 66.5121, GNorm = 0.3217, lr_0 = 1.0352e-04
Loss = 7.9917e-04, PNorm = 66.5190, GNorm = 0.4701, lr_0 = 1.0000e-04
Validation rmse = 1.355035
Epoch 29
Loss = 9.1297e-04, PNorm = 66.5278, GNorm = 0.4097, lr_0 = 1.0000e-04
Loss = 6.7600e-04, PNorm = 66.5338, GNorm = 0.6561, lr_0 = 1.0000e-04
Validation rmse = 1.388872
Model 0 best validation rmse = 1.169346 on epoch 12
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.841676
Ensemble test rmse = 0.841676
Fold 8
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_3_dropout_0.1_ffn_num_layers_2_hidden_size_1300/fold_8',
 'save_smiles_splits': True,
 'seed': 8,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 8
Total scaffolds = 195 | train scaffolds = 75 | val scaffolds = 42 | test scaffolds = 78
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1300, bias=False)
      (W_h): Linear(in_features=1300, out_features=1300, bias=False)
      (W_o): Linear(in_features=1433, out_features=1300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=1304, out_features=1300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1300, out_features=1, bias=True)
  )
)
Number of parameters = 5,443,101
Moving model to cuda
Epoch 0
Loss = 1.3302e-02, PNorm = 65.0515, GNorm = 6.7026, lr_0 = 3.6053e-04
Validation rmse = 1.278119
Epoch 1
Loss = 2.7343e-03, PNorm = 65.1159, GNorm = 1.0675, lr_0 = 6.2105e-04
Loss = 4.1314e-03, PNorm = 65.1889, GNorm = 2.8785, lr_0 = 8.5789e-04
Validation rmse = 1.267437
Epoch 2
Loss = 6.1695e-03, PNorm = 65.2667, GNorm = 2.8933, lr_0 = 9.8284e-04
Loss = 3.6545e-03, PNorm = 65.3380, GNorm = 2.0287, lr_0 = 9.4120e-04
Validation rmse = 1.179396
Epoch 3
Loss = 2.1218e-03, PNorm = 65.4038, GNorm = 0.7910, lr_0 = 8.9744e-04
Loss = 2.8762e-03, PNorm = 65.4587, GNorm = 0.7091, lr_0 = 8.5943e-04
Validation rmse = 1.055793
Epoch 4
Loss = 2.4578e-03, PNorm = 65.5104, GNorm = 2.0379, lr_0 = 8.2303e-04
Loss = 2.2232e-03, PNorm = 65.5539, GNorm = 0.7355, lr_0 = 7.8816e-04
Validation rmse = 0.998673
Epoch 5
Loss = 1.7652e-03, PNorm = 65.5859, GNorm = 0.7386, lr_0 = 7.5478e-04
Loss = 2.0023e-03, PNorm = 65.6183, GNorm = 0.9080, lr_0 = 7.2281e-04
Validation rmse = 0.956496
Epoch 6
Loss = 1.3621e-03, PNorm = 65.6547, GNorm = 0.5399, lr_0 = 6.8920e-04
Loss = 2.0201e-03, PNorm = 65.6902, GNorm = 1.5436, lr_0 = 6.6001e-04
Validation rmse = 1.026433
Epoch 7
Loss = 1.8057e-03, PNorm = 65.7241, GNorm = 1.4529, lr_0 = 6.3205e-04
Loss = 1.9221e-03, PNorm = 65.7588, GNorm = 0.6934, lr_0 = 6.0528e-04
Validation rmse = 0.951294
Epoch 8
Loss = 2.7251e-03, PNorm = 65.7942, GNorm = 1.5708, lr_0 = 5.7714e-04
Loss = 1.5517e-03, PNorm = 65.8288, GNorm = 0.7249, lr_0 = 5.5269e-04
Validation rmse = 0.906467
Epoch 9
Loss = 1.2932e-03, PNorm = 65.8592, GNorm = 0.3180, lr_0 = 5.2928e-04
Loss = 1.5886e-03, PNorm = 65.8855, GNorm = 1.0892, lr_0 = 5.0686e-04
Validation rmse = 0.888927
Epoch 10
Loss = 1.3165e-03, PNorm = 65.9120, GNorm = 0.6008, lr_0 = 4.8539e-04
Loss = 1.3270e-03, PNorm = 65.9412, GNorm = 0.4357, lr_0 = 4.6483e-04
Validation rmse = 0.887159
Epoch 11
Loss = 1.4464e-03, PNorm = 65.9647, GNorm = 0.4811, lr_0 = 4.4322e-04
Loss = 1.2505e-03, PNorm = 65.9885, GNorm = 0.5959, lr_0 = 4.2444e-04
Validation rmse = 0.929187
Epoch 12
Loss = 1.0427e-03, PNorm = 66.0139, GNorm = 0.3681, lr_0 = 4.0646e-04
Loss = 1.2160e-03, PNorm = 66.0366, GNorm = 0.5658, lr_0 = 3.8925e-04
Validation rmse = 0.882550
Epoch 13
Loss = 1.1680e-03, PNorm = 66.0621, GNorm = 0.4485, lr_0 = 3.7276e-04
Loss = 1.1466e-03, PNorm = 66.0857, GNorm = 0.5504, lr_0 = 3.5697e-04
Validation rmse = 0.869964
Epoch 14
Loss = 1.2350e-03, PNorm = 66.1123, GNorm = 0.4644, lr_0 = 3.4037e-04
Loss = 1.1100e-03, PNorm = 66.1326, GNorm = 0.9044, lr_0 = 3.2596e-04
Validation rmse = 0.870464
Epoch 15
Loss = 1.3540e-03, PNorm = 66.1503, GNorm = 2.1108, lr_0 = 3.1215e-04
Loss = 1.5992e-03, PNorm = 66.1701, GNorm = 0.6356, lr_0 = 2.9893e-04
Validation rmse = 0.979191
Epoch 16
Loss = 1.1328e-03, PNorm = 66.1904, GNorm = 0.9738, lr_0 = 2.8503e-04
Loss = 1.3704e-03, PNorm = 66.2083, GNorm = 0.5588, lr_0 = 2.7295e-04
Validation rmse = 0.929258
Epoch 17
Loss = 1.0350e-03, PNorm = 66.2209, GNorm = 0.4817, lr_0 = 2.6139e-04
Loss = 1.2893e-03, PNorm = 66.2409, GNorm = 0.3557, lr_0 = 2.5032e-04
Validation rmse = 0.960986
Epoch 18
Loss = 1.2158e-03, PNorm = 66.2565, GNorm = 0.6867, lr_0 = 2.3972e-04
Loss = 9.2386e-04, PNorm = 66.2692, GNorm = 0.2994, lr_0 = 2.2956e-04
Validation rmse = 0.923136
Epoch 19
Loss = 8.9894e-04, PNorm = 66.2834, GNorm = 0.4630, lr_0 = 2.1889e-04
Loss = 9.6926e-04, PNorm = 66.2934, GNorm = 0.3857, lr_0 = 2.0962e-04
Validation rmse = 0.910674
Epoch 20
Loss = 1.0167e-03, PNorm = 66.3067, GNorm = 0.4009, lr_0 = 2.0074e-04
Loss = 1.1101e-03, PNorm = 66.3174, GNorm = 0.3107, lr_0 = 1.9224e-04
Validation rmse = 0.975841
Epoch 21
Loss = 8.4918e-04, PNorm = 66.3318, GNorm = 0.9560, lr_0 = 1.8409e-04
Loss = 9.9193e-04, PNorm = 66.3426, GNorm = 0.7977, lr_0 = 1.7630e-04
Validation rmse = 1.053268
Epoch 22
Loss = 9.8907e-04, PNorm = 66.3538, GNorm = 0.4779, lr_0 = 1.6810e-04
Loss = 9.2892e-04, PNorm = 66.3649, GNorm = 0.4569, lr_0 = 1.6098e-04
Validation rmse = 0.883914
Epoch 23
Loss = 8.6989e-04, PNorm = 66.3733, GNorm = 1.1113, lr_0 = 1.5416e-04
Loss = 8.5013e-04, PNorm = 66.3815, GNorm = 0.4277, lr_0 = 1.4763e-04
Loss = 7.0705e-04, PNorm = 66.3823, GNorm = 0.5448, lr_0 = 1.4699e-04
Validation rmse = 0.872299
Epoch 24
Loss = 7.8742e-04, PNorm = 66.3889, GNorm = 0.5247, lr_0 = 1.4077e-04
Loss = 8.5739e-04, PNorm = 66.3993, GNorm = 0.6237, lr_0 = 1.3480e-04
Validation rmse = 0.898449
Epoch 25
Loss = 8.7112e-04, PNorm = 66.4057, GNorm = 0.6446, lr_0 = 1.2909e-04
Loss = 7.9015e-04, PNorm = 66.4123, GNorm = 0.4818, lr_0 = 1.2362e-04
Validation rmse = 0.920861
Epoch 26
Loss = 9.3814e-04, PNorm = 66.4197, GNorm = 1.0072, lr_0 = 1.1839e-04
Validation rmse = 0.901917
Epoch 27
Loss = 1.9249e-03, PNorm = 66.4273, GNorm = 1.0526, lr_0 = 1.1288e-04
Loss = 7.0504e-04, PNorm = 66.4319, GNorm = 0.8276, lr_0 = 1.0810e-04
Validation rmse = 0.921014
Epoch 28
Loss = 5.8671e-04, PNorm = 66.4372, GNorm = 0.5201, lr_0 = 1.0352e-04
Loss = 7.7262e-04, PNorm = 66.4430, GNorm = 0.4635, lr_0 = 1.0000e-04
Validation rmse = 0.925661
Epoch 29
Loss = 1.0796e-03, PNorm = 66.4496, GNorm = 0.5343, lr_0 = 1.0000e-04
Loss = 6.3712e-04, PNorm = 66.4540, GNorm = 0.9019, lr_0 = 1.0000e-04
Validation rmse = 0.948242
Model 0 best validation rmse = 0.869964 on epoch 13
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.101637
Ensemble test rmse = 1.101637
Fold 9
Command line
python hyperparameter_optimization.py --data_path data/DowData/solubility/Hansen_G3_G5/data.csv --dataset_type regression --save_dir checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982 --split_type scaffold_balanced --num_iters 20 --num_folds 10 --ensemble_size 1 --save_smiles_splits --config_save_path /config.json --features_path data/DowData/solubility/Hansen_G3_G5/features.csv
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_save_path': '/config.json',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': 'data/DowData/solubility/Hansen_G3_G5/data.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': ['data/DowData/solubility/Hansen_G3_G5/features.csv'],
 'features_scaling': True,
 'features_size': 4,
 'ffn_hidden_size': 1300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 1300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_dir': None,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_iters': 20,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': 'checkpoints/Hansen_G3_G5/sol_hyperopt-1597340982/depth_3_dropout_0.1_ffn_num_layers_2_hidden_size_1300/fold_9',
 'save_smiles_splits': True,
 'seed': 9,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'task_names': ['Solubility'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 981,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 9
Total scaffolds = 195 | train scaffolds = 84 | val scaffolds = 58 | test scaffolds = 53
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 440 | target average = -1.583489


Scaffold 1
Task 0: count = 336 | target average = -2.369214


Scaffold 2
Task 0: count = 67 | target average = -7.011628


Scaffold 3
Task 0: count = 23 | target average = -4.171274


Scaffold 4
Task 0: count = 17 | target average = -3.224341


Scaffold 5
Task 0: count = 16 | target average = -4.464013


Scaffold 6
Task 0: count = 14 | target average = -5.140965


Scaffold 7
Task 0: count = 14 | target average = -6.399748


Scaffold 8
Task 0: count = 13 | target average = -2.054289


Scaffold 9
Task 0: count = 11 | target average = -2.998033


Total size = 1,227 | train size = 981 | val size = 122 | test size = 124
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=1300, bias=False)
      (W_h): Linear(in_features=1300, out_features=1300, bias=False)
      (W_o): Linear(in_features=1433, out_features=1300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=1304, out_features=1300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1300, out_features=1, bias=True)
  )
)
Number of parameters = 5,443,101
Moving model to cuda
Epoch 0
Loss = 1.5370e-02, PNorm = 65.0514, GNorm = 2.4746, lr_0 = 3.6053e-04
Validation rmse = 1.345697
Epoch 1
Loss = 5.1519e-03, PNorm = 65.1126, GNorm = 1.3245, lr_0 = 6.2105e-04
Loss = 5.8084e-03, PNorm = 65.1954, GNorm = 1.9351, lr_0 = 8.5789e-04
Validation rmse = 1.022469
Epoch 2
Loss = 3.5742e-03, PNorm = 65.2878, GNorm = 0.7517, lr_0 = 9.8284e-04
Loss = 4.3180e-03, PNorm = 65.3632, GNorm = 1.5799, lr_0 = 9.4120e-04
Validation rmse = 1.087962
Epoch 3
Loss = 3.2952e-03, PNorm = 65.4289, GNorm = 1.4273, lr_0 = 8.9744e-04
Loss = 2.8504e-03, PNorm = 65.4800, GNorm = 0.4642, lr_0 = 8.5943e-04
Validation rmse = 0.995022
Epoch 4
Loss = 3.9860e-03, PNorm = 65.5255, GNorm = 2.7003, lr_0 = 8.2303e-04
Loss = 2.2191e-03, PNorm = 65.5707, GNorm = 1.1025, lr_0 = 7.8816e-04
Validation rmse = 0.948545
Epoch 5
Loss = 2.8052e-03, PNorm = 65.6068, GNorm = 0.7865, lr_0 = 7.5478e-04
Loss = 2.3856e-03, PNorm = 65.6455, GNorm = 0.8575, lr_0 = 7.2281e-04
Validation rmse = 0.913232
Epoch 6
Loss = 2.0250e-03, PNorm = 65.6849, GNorm = 1.7412, lr_0 = 6.8920e-04
Loss = 2.4035e-03, PNorm = 65.7202, GNorm = 0.7068, lr_0 = 6.6001e-04
Validation rmse = 0.958712
Epoch 7
Loss = 2.2346e-03, PNorm = 65.7578, GNorm = 1.0546, lr_0 = 6.3205e-04
Loss = 2.1720e-03, PNorm = 65.7885, GNorm = 1.6927, lr_0 = 6.0528e-04
Validation rmse = 0.877092
Epoch 8
Loss = 1.8841e-03, PNorm = 65.8233, GNorm = 1.2587, lr_0 = 5.7714e-04
Loss = 1.9951e-03, PNorm = 65.8542, GNorm = 0.9362, lr_0 = 5.5269e-04
Validation rmse = 0.818508
Epoch 9
Loss = 1.5963e-03, PNorm = 65.8796, GNorm = 0.5429, lr_0 = 5.2928e-04
Loss = 1.4962e-03, PNorm = 65.9037, GNorm = 0.7806, lr_0 = 5.0686e-04
Validation rmse = 0.816080
Epoch 10
Loss = 1.1808e-03, PNorm = 65.9258, GNorm = 0.3893, lr_0 = 4.8539e-04
Loss = 1.3545e-03, PNorm = 65.9493, GNorm = 0.4817, lr_0 = 4.6483e-04
Validation rmse = 0.811860
Epoch 11
Loss = 1.4312e-03, PNorm = 65.9765, GNorm = 0.6266, lr_0 = 4.4322e-04
Loss = 1.4564e-03, PNorm = 66.0015, GNorm = 0.6384, lr_0 = 4.2444e-04
Validation rmse = 0.801631
Epoch 12
Loss = 1.2229e-03, PNorm = 66.0254, GNorm = 0.7313, lr_0 = 4.0646e-04
Loss = 1.6763e-03, PNorm = 66.0491, GNorm = 0.4706, lr_0 = 3.8925e-04
Validation rmse = 0.838133
Epoch 13
Loss = 1.1142e-03, PNorm = 66.0660, GNorm = 0.5859, lr_0 = 3.7276e-04
Loss = 1.3571e-03, PNorm = 66.0843, GNorm = 1.0031, lr_0 = 3.5697e-04
Validation rmse = 0.848549
Epoch 14
Loss = 1.2784e-03, PNorm = 66.1090, GNorm = 0.4210, lr_0 = 3.4037e-04
Loss = 1.4027e-03, PNorm = 66.1283, GNorm = 0.6950, lr_0 = 3.2596e-04
Validation rmse = 0.806061
Epoch 15
Loss = 1.2672e-03, PNorm = 66.1447, GNorm = 1.0873, lr_0 = 3.1215e-04
Loss = 1.4108e-03, PNorm = 66.1639, GNorm = 1.0773, lr_0 = 2.9893e-04
Validation rmse = 0.880696
Epoch 16
Loss = 1.3170e-03, PNorm = 66.1817, GNorm = 1.2845, lr_0 = 2.8503e-04
Loss = 1.0254e-03, PNorm = 66.1964, GNorm = 0.4525, lr_0 = 2.7295e-04
Validation rmse = 0.817814
Epoch 17
Loss = 1.0854e-03, PNorm = 66.2129, GNorm = 0.4148, lr_0 = 2.6139e-04
Loss = 1.2537e-03, PNorm = 66.2315, GNorm = 0.6360, lr_0 = 2.5032e-04
Validation rmse = 0.786777
Epoch 18
Loss = 9.4998e-04, PNorm = 66.2475, GNorm = 0.2367, lr_0 = 2.3972e-04
Loss = 1.3769e-03, PNorm = 66.2601, GNorm = 0.6261, lr_0 = 2.2956e-04
Validation rmse = 0.759720
Epoch 19
Loss = 1.0652e-03, PNorm = 66.2696, GNorm = 0.7042, lr_0 = 2.1889e-04
Loss = 1.2901e-03, PNorm = 66.2835, GNorm = 0.5606, lr_0 = 2.0962e-04
Validation rmse = 0.796857
Epoch 20
Loss = 1.0982e-03, PNorm = 66.2958, GNorm = 0.3903, lr_0 = 2.0074e-04
Loss = 8.5237e-04, PNorm = 66.3062, GNorm = 0.5404, lr_0 = 1.9224e-04
Validation rmse = 0.763477
Epoch 21
Loss = 7.9970e-04, PNorm = 66.3144, GNorm = 0.7727, lr_0 = 1.8409e-04
Loss = 1.2874e-03, PNorm = 66.3258, GNorm = 1.7620, lr_0 = 1.7630e-04
Validation rmse = 0.844184
Epoch 22
Loss = 1.1398e-03, PNorm = 66.3384, GNorm = 1.1707, lr_0 = 1.6810e-04
Loss = 9.3412e-04, PNorm = 66.3500, GNorm = 1.2870, lr_0 = 1.6098e-04
Validation rmse = 0.784876
Epoch 23
Loss = 8.8277e-04, PNorm = 66.3597, GNorm = 0.6001, lr_0 = 1.5416e-04
Loss = 1.0696e-03, PNorm = 66.3684, GNorm = 0.6337, lr_0 = 1.4763e-04
Loss = 2.5838e-03, PNorm = 66.3693, GNorm = 0.8788, lr_0 = 1.4699e-04
Validation rmse = 0.764808
Epoch 24
Loss = 9.2973e-04, PNorm = 66.3773, GNorm = 0.3932, lr_0 = 1.4077e-04
Loss = 1.1138e-03, PNorm = 66.3854, GNorm = 0.5596, lr_0 = 1.3480e-04
Validation rmse = 0.782289
Epoch 25
Loss = 9.2357e-04, PNorm = 66.3946, GNorm = 0.3481, lr_0 = 1.2909e-04
Loss = 9.0869e-04, PNorm = 66.4025, GNorm = 0.4557, lr_0 = 1.2362e-04
Validation rmse = 0.810181
Epoch 26
Loss = 1.0539e-03, PNorm = 66.4100, GNorm = 0.6800, lr_0 = 1.1839e-04
Validation rmse = 0.789679
Epoch 27
Loss = 1.0447e-03, PNorm = 66.4180, GNorm = 1.1301, lr_0 = 1.1288e-04
Loss = 9.0749e-04, PNorm = 66.4244, GNorm = 0.6993, lr_0 = 1.0810e-04
Validation rmse = 0.821487
Epoch 28
Loss = 1.0319e-03, PNorm = 66.4300, GNorm = 0.3973, lr_0 = 1.0352e-04
Loss = 8.6206e-04, PNorm = 66.4378, GNorm = 0.3780, lr_0 = 1.0000e-04
Validation rmse = 0.803880
Epoch 29
Loss = 9.0545e-04, PNorm = 66.4446, GNorm = 0.5689, lr_0 = 1.0000e-04
Loss = 7.8817e-04, PNorm = 66.4499, GNorm = 0.4581, lr_0 = 1.0000e-04
Validation rmse = 0.779407
Model 0 best validation rmse = 0.759720 on epoch 18
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.235727
Ensemble test rmse = 1.235727
10-fold cross validation
	Seed 0 ==> test rmse = 0.938806
	Seed 1 ==> test rmse = 0.935002
	Seed 2 ==> test rmse = 1.000727
	Seed 3 ==> test rmse = 0.844331
	Seed 4 ==> test rmse = 0.907345
	Seed 5 ==> test rmse = 0.985085
	Seed 6 ==> test rmse = 0.789242
	Seed 7 ==> test rmse = 0.841676
	Seed 8 ==> test rmse = 1.101637
	Seed 9 ==> test rmse = 1.235727
Overall test rmse = 0.957958 +/- 0.125983
Elapsed time = 0:07:03
